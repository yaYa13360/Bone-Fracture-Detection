{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, f1_score, precision_score, recall_score\n",
    "import os\n",
    "\n",
    "# label\n",
    "# =========================\n",
    "def class_2_type(root):\n",
    "    label = \"\"\n",
    "    if \"正常\" in root:\n",
    "        label = \"0\"\n",
    "    else:\n",
    "        label = \"1\"\n",
    "    return label\n",
    "\n",
    "def class_3_type(root):\n",
    "    label = \"\"\n",
    "    if \"正常\" in root:\n",
    "        label = \"0\"\n",
    "    elif \"雙踝\" in root:\n",
    "        label = \"1\"\n",
    "    elif \"三踝\" in root:\n",
    "        label = \"2\"\n",
    "    return label\n",
    "# =========================\n",
    "\n",
    "def load_path(path, class_count):\n",
    "    dataset = []\n",
    "    class_type = ''\n",
    "    if class_count == 2:\n",
    "        class_type = class_2_type\n",
    "    elif class_count == 3:\n",
    "        class_type = class_3_type   \n",
    "\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            label = class_type(root)\n",
    "            if label != \"\":\n",
    "                dataset.append(\n",
    "                                {   \n",
    "                                    'uuid': root.split(\"\\\\\")[-1],\n",
    "                                    'label': label,\n",
    "                                    'image_path': os.path.join(root, file)\n",
    "                                }\n",
    "                            )\n",
    "\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 參數設置\n",
    "image_dir = \"E:\\\\data_bone\\\\9-a+b_swift_cut_正確_V2\\\\front\"\n",
    "concat_type = \"channel\"\n",
    "class_count = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## image spatail\n",
    "# =========================\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "def resize_and_merge_images(image_a_path, image_b_path, output_path):\n",
    "    try:\n",
    "        with Image.open(image_a_path) as img_a, Image.open(image_b_path) as img_b:\n",
    "            img_a = img_a.resize((224, 224))\n",
    "            img_b = img_b.resize((224, 224))\n",
    "\n",
    "            # Convert images to numpy arrays\n",
    "            img_a_array = np.array(img_a)\n",
    "            img_b_array = np.array(img_b)\n",
    "\n",
    "            # Extract first layers of A and B\n",
    "            c_layer_1 = img_a_array[:, :, 0]  # First channel of A\n",
    "            c_layer_3 = img_b_array[:, :, 0]  # First channel of B\n",
    "\n",
    "            # 確定三層長一樣\n",
    "            # print(np.array_equal(img_a_array[:, :, 0], img_a_array[:, :, 1]))\n",
    "            # print(np.array_equal(img_b_array[:, :, 0], img_b_array[:, :, 1]))\n",
    "            \n",
    "            # Compute second layer as (A first layer + B first layer) / 2\n",
    "            c_layer_2 = ((img_a_array[:, :, 0].astype(np.float32) + img_b_array[:, :, 0].astype(np.float32)) / 2).astype(np.uint8)\n",
    "            \n",
    "            # Stack layers to create new image\n",
    "            merged_image_array = np.stack([c_layer_1, c_layer_2, c_layer_3], axis=2)\n",
    "            merged_image = Image.fromarray(merged_image_array, mode='RGB')\n",
    "            \n",
    "            # Save the merged image\n",
    "            merged_image.save(output_path)\n",
    "            # print(f\"Merged image saved at {output_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing images: {e}\")\n",
    "\n",
    "# Example usage\n",
    "# a_image_path = \"path/to/a_image.jpg\"\n",
    "# b_image_path = \"path/to/b_image.jpg\"\n",
    "# output_image_path = \"path/to/output.jpg\"\n",
    "\n",
    "# resize_and_merge_images(a_image_path, b_image_path, output_image_path)\n",
    "\n",
    "# ========================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load data and  labels\n",
    "# =========================\n",
    "data = load_path(image_dir, class_count)\n",
    "labels = []\n",
    "filepaths = []\n",
    "for row in data:\n",
    "    labels.append(row['label'])\n",
    "    filepaths.append(row['image_path'])\n",
    "\n",
    "filepaths = pd.Series(filepaths, name='Filepath').astype(str)\n",
    "labels = pd.Series(labels, name='Label')\n",
    "\n",
    "images_front = pd.concat([filepaths, labels], axis=1)\n",
    "# =========================\n",
    "\n",
    "## merge and save image\n",
    "# =========================\n",
    "images_side = images_front.copy()\n",
    "images_side.loc[:, \"Filepath\"] = images_front[\"Filepath\"].str.replace(\"front\", \"side\")\n",
    "images_side.loc[:, \"Filepath\"] = images_front[\"Filepath\"].str.replace(\"front\", \"side\")\n",
    "for i in range(len(images_front)):\n",
    "    resize_and_merge_images(images_front.loc[i][\"Filepath\"], images_side.loc[i][\"Filepath\"], images_front.loc[i][\"Filepath\"].replace(\"front\", \"channel\"))\n",
    "# ========================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set label distribution:\n",
      " 0    128\n",
      "2     95\n",
      "1     93\n",
      "Name: Label, dtype: int64\n",
      "Test set label distribution:\n",
      " 0    32\n",
      "1    24\n",
      "2    24\n",
      "Name: Label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## load channel and split\n",
    "image_dir2 = \"E:\\\\data_bone\\\\9-a+b_swift_cut_正確_V2\\\\channel\"\n",
    "data = load_path(image_dir2, class_count)\n",
    "labels = []\n",
    "filepaths = []\n",
    "for row in data:\n",
    "    labels.append(row['label'])\n",
    "    filepaths.append(row['image_path'])\n",
    "\n",
    "filepaths = pd.Series(filepaths, name='Filepath').astype(str)\n",
    "labels = pd.Series(labels, name='Label')\n",
    "\n",
    "images_channel = pd.concat([filepaths, labels], axis=1)\n",
    "train_df, test_df = train_test_split(images_channel, train_size=0.8, shuffle=True, random_state=44, stratify=images_channel['Label'])\n",
    "\n",
    "print(\"Training set label distribution:\\n\", train_df['Label'].value_counts(normalize=False))\n",
    "print(\"Test set label distribution:\\n\", test_df['Label'].value_counts(normalize=False))\n",
    "\n",
    "# 關閉翻轉\n",
    "train_generator = tf.keras.preprocessing.image.ImageDataGenerator(horizontal_flip=False,\n",
    "                                                                    preprocessing_function=tf.keras.applications.resnet50.preprocess_input,\n",
    "                                                                    validation_split=0.2)\n",
    "test_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    preprocessing_function=tf.keras.applications.resnet50.preprocess_input)\n",
    "# ========================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channel\n",
      "Found 253 validated image filenames belonging to 3 classes.\n",
      "Found 63 validated image filenames belonging to 3 classes.\n",
      "Found 80 validated image filenames belonging to 3 classes.\n",
      "-------Training _channel-------\n",
      "Epoch 1/30\n",
      "4/4 [==============================] - 6s 741ms/step - loss: 1.2768 - accuracy: 0.3123 - val_loss: 1.0983 - val_accuracy: 0.4127\n",
      "Epoch 2/30\n",
      "4/4 [==============================] - 1s 124ms/step - loss: 1.0751 - accuracy: 0.4150 - val_loss: 1.0565 - val_accuracy: 0.4762\n",
      "Epoch 3/30\n",
      "4/4 [==============================] - 0s 120ms/step - loss: 1.0452 - accuracy: 0.4743 - val_loss: 1.0169 - val_accuracy: 0.4762\n",
      "Epoch 4/30\n",
      "4/4 [==============================] - 0s 119ms/step - loss: 0.9812 - accuracy: 0.5020 - val_loss: 0.9475 - val_accuracy: 0.5873\n",
      "Epoch 5/30\n",
      "4/4 [==============================] - 1s 124ms/step - loss: 0.9101 - accuracy: 0.6126 - val_loss: 0.8793 - val_accuracy: 0.6349\n",
      "Epoch 6/30\n",
      "4/4 [==============================] - 1s 134ms/step - loss: 0.8550 - accuracy: 0.6917 - val_loss: 0.8392 - val_accuracy: 0.6667\n",
      "Epoch 7/30\n",
      "4/4 [==============================] - 1s 132ms/step - loss: 0.8112 - accuracy: 0.7194 - val_loss: 0.8002 - val_accuracy: 0.6825\n",
      "Epoch 8/30\n",
      "4/4 [==============================] - 1s 141ms/step - loss: 0.7625 - accuracy: 0.7312 - val_loss: 0.7667 - val_accuracy: 0.6825\n",
      "Epoch 9/30\n",
      "4/4 [==============================] - 1s 140ms/step - loss: 0.7215 - accuracy: 0.7352 - val_loss: 0.7321 - val_accuracy: 0.6825\n",
      "Epoch 10/30\n",
      "4/4 [==============================] - 1s 140ms/step - loss: 0.6840 - accuracy: 0.7589 - val_loss: 0.6996 - val_accuracy: 0.7143\n",
      "Epoch 11/30\n",
      "4/4 [==============================] - 1s 131ms/step - loss: 0.6488 - accuracy: 0.7787 - val_loss: 0.6765 - val_accuracy: 0.7143\n",
      "Epoch 12/30\n",
      "4/4 [==============================] - 1s 137ms/step - loss: 0.6182 - accuracy: 0.7826 - val_loss: 0.6633 - val_accuracy: 0.6984\n",
      "Epoch 13/30\n",
      "4/4 [==============================] - 1s 140ms/step - loss: 0.5935 - accuracy: 0.7826 - val_loss: 0.6489 - val_accuracy: 0.6984\n",
      "Epoch 14/30\n",
      "4/4 [==============================] - 1s 157ms/step - loss: 0.5705 - accuracy: 0.7945 - val_loss: 0.6313 - val_accuracy: 0.6984\n",
      "Epoch 15/30\n",
      "4/4 [==============================] - 1s 150ms/step - loss: 0.5483 - accuracy: 0.8063 - val_loss: 0.6219 - val_accuracy: 0.6984\n",
      "Epoch 16/30\n",
      "4/4 [==============================] - 1s 135ms/step - loss: 0.5323 - accuracy: 0.8103 - val_loss: 0.6122 - val_accuracy: 0.6825\n",
      "Epoch 17/30\n",
      "4/4 [==============================] - 1s 142ms/step - loss: 0.5147 - accuracy: 0.8182 - val_loss: 0.6039 - val_accuracy: 0.6984\n",
      "Epoch 18/30\n",
      "4/4 [==============================] - 1s 142ms/step - loss: 0.5020 - accuracy: 0.8182 - val_loss: 0.5900 - val_accuracy: 0.7302\n",
      "Epoch 19/30\n",
      "4/4 [==============================] - 1s 140ms/step - loss: 0.4833 - accuracy: 0.8221 - val_loss: 0.5907 - val_accuracy: 0.6984\n",
      "Epoch 20/30\n",
      "4/4 [==============================] - 1s 150ms/step - loss: 0.4710 - accuracy: 0.8261 - val_loss: 0.5883 - val_accuracy: 0.7143\n",
      "Epoch 21/30\n",
      "4/4 [==============================] - 1s 137ms/step - loss: 0.4543 - accuracy: 0.8379 - val_loss: 0.5732 - val_accuracy: 0.7302\n",
      "Epoch 22/30\n",
      "4/4 [==============================] - 1s 134ms/step - loss: 0.4447 - accuracy: 0.8340 - val_loss: 0.5685 - val_accuracy: 0.7460\n",
      "Epoch 23/30\n",
      "4/4 [==============================] - 1s 143ms/step - loss: 0.4319 - accuracy: 0.8458 - val_loss: 0.5672 - val_accuracy: 0.7143\n",
      "Epoch 24/30\n",
      "4/4 [==============================] - 1s 137ms/step - loss: 0.4203 - accuracy: 0.8498 - val_loss: 0.5637 - val_accuracy: 0.7143\n",
      "Epoch 25/30\n",
      "4/4 [==============================] - 1s 137ms/step - loss: 0.4080 - accuracy: 0.8538 - val_loss: 0.5576 - val_accuracy: 0.7302\n",
      "Epoch 26/30\n",
      "4/4 [==============================] - 1s 138ms/step - loss: 0.3975 - accuracy: 0.8735 - val_loss: 0.5510 - val_accuracy: 0.7302\n",
      "Epoch 27/30\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.3880 - accuracy: 0.8735 - val_loss: 0.5481 - val_accuracy: 0.7302\n",
      "Epoch 28/30\n",
      "4/4 [==============================] - 1s 130ms/step - loss: 0.3809 - accuracy: 0.8735 - val_loss: 0.5512 - val_accuracy: 0.7143\n",
      "Epoch 29/30\n",
      "4/4 [==============================] - 0s 119ms/step - loss: 0.3684 - accuracy: 0.8775 - val_loss: 0.5441 - val_accuracy: 0.7302\n",
      "Epoch 30/30\n",
      "4/4 [==============================] - 0s 116ms/step - loss: 0.3606 - accuracy: 0.8972 - val_loss: 0.5367 - val_accuracy: 0.7460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\bone_20240719\\lib\\site-packages\\keras\\utils\\generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# load model\n",
    "# =========================\n",
    "pretrained_model = tf.keras.applications.resnet50.ResNet50(\n",
    "    input_shape=(224, 224, 3),\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    pooling='avg')\n",
    "\n",
    "pretrained_model.trainable = False\n",
    "\n",
    "inputs = pretrained_model.input\n",
    "x = tf.keras.layers.Dense(128, activation='relu', name='dense_128')(pretrained_model.output)\n",
    "x = tf.keras.layers.Dense(50, activation='relu', name='dense_50')(x)\n",
    "\n",
    "outputs = tf.keras.layers.Dense(class_count, activation='softmax', name='output_layer')(x)\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "# print(model.summary())\n",
    "# =========================\n",
    "\n",
    "## 分資料\n",
    "# =========================\n",
    "\n",
    "# 確認\n",
    "print(train_df.iloc[0]['Filepath'].split(\"\\\\\")[-3])\n",
    "\n",
    "train_images = train_generator.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col='Filepath',\n",
    "    y_col='Label',\n",
    "    target_size=(224, 224),\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "val_images = train_generator.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col='Filepath',\n",
    "    y_col='Label',\n",
    "    target_size=(224, 224),\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "test_images = test_generator.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    x_col='Filepath',\n",
    "    y_col='Label',\n",
    "    target_size=(224, 224),\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")\n",
    "# =========================\n",
    "\n",
    "\n",
    "## compile and evaluate\n",
    "# =========================\n",
    "\n",
    "print(\"-------Training \" + \"_\" + concat_type + \"-------\")\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "## early stop \n",
    "# early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)\n",
    "# history=model.fit(train_images, validation_data=val_images, callbacks=[early_stopping], epochs=30)\n",
    "## no early stop\n",
    "history = model.fit(train_images, validation_data=val_images, epochs=30)\n",
    "\n",
    "results = model.evaluate(test_images, verbose=0)\n",
    "# =========================\n",
    "\n",
    "\n",
    "## save model to this path\n",
    "# =========================\n",
    "model.save(\"./weights/\"+concat_type+\"_\" + \"_frac.h5\")\n",
    "# =========================\n",
    "\n",
    "\n",
    "## print results\n",
    "# =========================\n",
    "# print(save_path + \"_\" + concat_type + \"_Results:\")\n",
    "pred = model.predict(test_images)\n",
    "predicted_labels = np.argmax(pred, axis=1)\n",
    "\n",
    "# f1 = f1_score(test_images.labels, predicted_labels, average='macro')\n",
    "# precision = precision_score(test_images.labels, predicted_labels, average='macro')\n",
    "# recall = recall_score(test_images.labels, predicted_labels, average='macro')\n",
    "\n",
    "# print(results)\n",
    "# print(f\"Test Accuracy: {np.round(results[1], 2)}\")\n",
    "# print(f\"f1 score: {np.round(f1, 2)}\")\n",
    "# print(f\"precision: {np.round(precision, 2)}\")\n",
    "# print(f\"recall: {np.round(recall, 2)}\")\n",
    "# =========================\n",
    "\n",
    "\n",
    "# create plots for accuracy and save it\n",
    "# =========================\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "figAcc = plt.gcf()\n",
    "my_file = os.path.join(\"./plots/\"+concat_type+\"_Accuracy.jpeg\")\n",
    "figAcc.savefig(my_file)\n",
    "plt.clf()\n",
    "# =========================\n",
    "\n",
    "\n",
    "## create plots for loss and save it\n",
    "# =========================\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "figAcc = plt.gcf()\n",
    "my_file = os.path.join(\"./plots/\"+concat_type+\"_\"+\"_Loss.jpeg\")\n",
    "figAcc.savefig(my_file)\n",
    "plt.clf()\n",
    "# =========================\n",
    "\n",
    "\n",
    "## plot confusion matrix\n",
    "# =========================\n",
    "if class_count == 2:\n",
    "    display_labels = [0, 1]\n",
    "elif class_count == 3:\n",
    "    display_labels = [0, 1, 2]\n",
    "elif class_count == 4:\n",
    "    display_labels = [0, 1, 2, 3]\n",
    "\n",
    "\n",
    "cm = confusion_matrix(test_images.labels, predicted_labels)\n",
    "cm_display = ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = display_labels)\n",
    "cm_display.plot()\n",
    "plt.title('Confusion Matrix')\n",
    "figAcc = plt.gcf()\n",
    "my_file = os.path.join(\"./plots/\"+concat_type+\"_\"+\"_Confusion Matrix.jpeg\")\n",
    "figAcc.savefig(my_file)\n",
    "plt.clf()\n",
    "# ========================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.72\n",
      "f1 score: 0.69\n",
      "precision: 0.69\n",
      "recall: 0.69\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(test_images.labels, predicted_labels)\n",
    "f1 = f1_score(test_images.labels, predicted_labels, average='macro')\n",
    "precision = precision_score(test_images.labels, predicted_labels, average='macro')\n",
    "recall = recall_score(test_images.labels, predicted_labels, average='macro')\n",
    "\n",
    "print(f\"Test Accuracy: {np.round(acc, 2)}\")\n",
    "print(f\"f1 score: {np.round(f1, 2)}\")\n",
    "print(f\"precision: {np.round(precision, 2)}\")\n",
    "print(f\"recall: {np.round(recall, 2)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bone_20240719",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
