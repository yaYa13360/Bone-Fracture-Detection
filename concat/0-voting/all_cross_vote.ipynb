{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path\n",
    "# import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from scipy.stats import mode\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "## label\n",
    "# =========================\n",
    "def class_2_type(root):\n",
    "    label = \"\"\n",
    "    if \"正常\" in root:\n",
    "        label = \"0\"\n",
    "    else:\n",
    "        label = \"1\"\n",
    "    return label\n",
    "\n",
    "def class_3_type(root):\n",
    "    label = \"\"\n",
    "    if \"正常\" in root:\n",
    "        label = \"0\"\n",
    "    elif \"雙踝\" in root:\n",
    "        label = \"1\"\n",
    "    elif \"三踝\" in root:\n",
    "        label = \"2\"\n",
    "    return label\n",
    "# =========================\n",
    "\n",
    "\n",
    "def load_path(path, class_count):\n",
    "    dataset = []\n",
    "    class_type = ''\n",
    "    if class_count == 2:\n",
    "        class_type = class_2_type\n",
    "    elif class_count == 3:\n",
    "        class_type = class_3_type  \n",
    "\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            label = class_type(root)\n",
    "            # if label != \"\":\n",
    "            dataset.append(\n",
    "                            {   \n",
    "                                'uuid': root.split(\"\\\\\")[-1],\n",
    "                                'label': label,\n",
    "                                'image_path': os.path.join(root, file)\n",
    "                            }\n",
    "                        )\n",
    "\n",
    "    return dataset\n",
    "\n",
    "# def train_cross_validation(image_dir, n_splits=5, class_count=2, maru_part=None,  chosen_model='resnet50'):\n",
    "def train_cross_validation(image_dir, n_splits=5, class_count=2):\n",
    "\n",
    "\n",
    "    ## load data and  labels\n",
    "    # =========================\n",
    "    labels = []\n",
    "    filepaths = []\n",
    "    data = load_path(image_dir, class_count)\n",
    "    for row in data:\n",
    "        labels.append(row['label'])\n",
    "        filepaths.append(row['image_path'])\n",
    "\n",
    "    filepaths = pd.Series(filepaths, name='Filepath').astype(str)\n",
    "    labels = pd.Series(labels, name='Label')\n",
    "\n",
    "    images = pd.concat([filepaths, labels], axis=1)\n",
    "    # =========================\n",
    "\n",
    "\n",
    "    # ## load chosen model\n",
    "    # # =========================\n",
    "    # if chosen_model == 'resnet50':\n",
    "    #     preprocessing_function_chosen = tf.keras.applications.resnet50.preprocess_input\n",
    "    #     pretrained_model_chosen = tf.keras.applications.resnet50.ResNet50\n",
    "    # # elif chosen_model == 'resnet152':\n",
    "    # #     preprocessing_function_chosen = tf.keras.applications.resnet152.preprocess_input\n",
    "    # #     pretrained_model_chosen = tf.keras.applications.resnet152.ResNet152\n",
    "    # elif chosen_model == 'vgg16':\n",
    "    #     preprocessing_function_chosen = tf.keras.applications.vgg16.preprocess_input\n",
    "    #     pretrained_model_chosen = tf.keras.applications.vgg16.VGG16\n",
    "    # elif chosen_model == 'vgg19':\n",
    "    #     preprocessing_function_chosen = tf.keras.applications.vgg19.preprocess_input\n",
    "    #     pretrained_model_chosen = tf.keras.applications.vgg19.VGG19\n",
    "    # elif chosen_model == 'mobilenet':\n",
    "    #     preprocessing_function_chosen = tf.keras.applications.mobilenet.preprocess_input\n",
    "    #     pretrained_model_chosen = tf.keras.applications.mobilenet.MobileNet\n",
    "    # elif chosen_model == 'mobilenet_v2':\n",
    "    #     preprocessing_function_chosen = tf.keras.applications.mobilenet_v2.preprocess_input\n",
    "    #     pretrained_model_chosen = tf.keras.applications.mobilenet_v2.MobileNetV2\n",
    "    # elif chosen_model == 'efficientnet':\n",
    "    #     preprocessing_function_chosen = tf.keras.applications.efficientnet.preprocess_input\n",
    "    #     pretrained_model_chosen = tf.keras.applications.efficientnet.EfficientNetB0\n",
    "    # elif chosen_model == 'inception_v3':\n",
    "    #     preprocessing_function_chosen = tf.keras.applications.inception_v3.preprocess_input\n",
    "    #     pretrained_model_chosen = tf.keras.applications.inception_v3.InceptionV3\n",
    "    # else:\n",
    "    #     raise ValueError(\"Model name not recognized. Please choose a valid model.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # =========================\n",
    "\n",
    "    ## to do: loss function\n",
    "    # =========================\n",
    "    # =========================\n",
    "\n",
    "\n",
    "    train_df, test_df = train_test_split(images, train_size=0.8, shuffle=True, random_state=1, stratify=images['Label'])\n",
    "\n",
    "\n",
    "    ## train model, k fold cross validation\n",
    "    # ==================================================\n",
    "    fold_no = 1\n",
    "    # test_acc = []\n",
    "    # test_f1 = []\n",
    "    front_test_acc = []\n",
    "    side_test_acc = []\n",
    "    soft_test_acc = []\n",
    "    hard_test_acc = []\n",
    "\n",
    "    front_test_f1 = []\n",
    "    side_test_f1 = []\n",
    "    soft_test_f1 = []\n",
    "    hard_test_f1 = []\n",
    "    \n",
    "    vote_type_arr_acc = [front_test_acc, side_test_acc, soft_test_acc, hard_test_acc]\n",
    "    vote_type_arr_f1 = [front_test_f1, side_test_f1, soft_test_f1, hard_test_f1]\n",
    "    # vote_type_arr = [\"front\", \"side\", \"soft\", \"hard\", \"product\"]\n",
    "    vote_type_arr = [\"front\", \"side\", \"soft\", \"hard\"]\n",
    "\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=1)\n",
    "    for train_index, val_index in kfold.split(train_df, train_df['Label']):\n",
    "        k_fold_train = train_df.iloc[train_index]\n",
    "        k_fold_val = train_df.iloc[val_index]\n",
    "\n",
    "\n",
    "        ## train, validation image\n",
    "        # =========================\n",
    "        ## train front and side\n",
    "        save_path_arr = [\"front\", \"side\"]\n",
    "        for save_path in save_path_arr:\n",
    "            ## 分資料\n",
    "            # =========================\n",
    "            if save_path == \"side\":\n",
    "                k_fold_train.loc[:, \"Filepath\"] = k_fold_train[\"Filepath\"].str.replace(\"front\", \"side\")\n",
    "                k_fold_val.loc[:, \"Filepath\"] = k_fold_val[\"Filepath\"].str.replace(\"front\", \"side\")\n",
    "                test_df.loc[:, \"Filepath\"] = test_df[\"Filepath\"].str.replace(\"front\", \"side\")\n",
    "                preprocessing_function_chosen = tf.keras.applications.efficientnet.preprocess_input\n",
    "                pretrained_model_chosen = tf.keras.applications.efficientnet.EfficientNetB0\n",
    "\n",
    "            if save_path == \"front\":\n",
    "                k_fold_train.loc[:, \"Filepath\"] = k_fold_train[\"Filepath\"].str.replace(\"side\", \"front\")\n",
    "                k_fold_val.loc[:, \"Filepath\"] = k_fold_val[\"Filepath\"].str.replace(\"side\", \"front\")\n",
    "                test_df.loc[:, \"Filepath\"] = test_df[\"Filepath\"].str.replace(\"side\", \"front\")\n",
    "                preprocessing_function_chosen = tf.keras.applications.resnet50.preprocess_input\n",
    "                pretrained_model_chosen = tf.keras.applications.resnet50.ResNet50\n",
    "\n",
    "            print(len(k_fold_train))\n",
    "            print(len(k_fold_val))\n",
    "\n",
    "\n",
    "            # 確認\n",
    "            print(k_fold_train.iloc[0]['Filepath'].split(\"\\\\\")[-3])\n",
    "            print(test_df.iloc[0]['Filepath'].split(\"\\\\\")[-3])\n",
    "            \n",
    "            ## 讀資料\n",
    "            # =========================\n",
    "            train_generator = tf.keras.preprocessing.image.ImageDataGenerator(horizontal_flip=False,preprocessing_function=preprocessing_function_chosen)\n",
    "            train_images = train_generator.flow_from_dataframe(\n",
    "                dataframe=k_fold_train,\n",
    "                x_col='Filepath',\n",
    "                y_col='Label',\n",
    "                target_size=(224, 224),\n",
    "                color_mode='rgb',\n",
    "                class_mode='categorical',\n",
    "                batch_size=64,\n",
    "                shuffle=True,\n",
    "                seed=42,\n",
    "            )\n",
    "            val_images = train_generator.flow_from_dataframe(\n",
    "                dataframe=k_fold_val,\n",
    "                x_col='Filepath',\n",
    "                y_col='Label',\n",
    "                target_size=(224, 224),\n",
    "                color_mode='rgb',\n",
    "                class_mode='categorical',\n",
    "                batch_size=64,\n",
    "                shuffle=True,\n",
    "                seed=42,\n",
    "            )\n",
    "            test_generator = tf.keras.preprocessing.image.ImageDataGenerator(preprocessing_function=preprocessing_function_chosen)\n",
    "            test_images = test_generator.flow_from_dataframe(\n",
    "                dataframe=test_df,\n",
    "                x_col='Filepath',\n",
    "                y_col='Label',\n",
    "                target_size=(224, 224),\n",
    "                color_mode='rgb',\n",
    "                class_mode='categorical',\n",
    "                batch_size=32,\n",
    "                shuffle=False\n",
    "            )\n",
    "            # =========================\n",
    "            \n",
    "            # load model\n",
    "            # =========================\n",
    "            pretrained_model = pretrained_model_chosen(\n",
    "                input_shape=(224, 224, 3),\n",
    "                include_top=False,\n",
    "                weights='imagenet',\n",
    "                pooling='avg')\n",
    "\n",
    "            pretrained_model.trainable = False\n",
    "\n",
    "            inputs = pretrained_model.input\n",
    "            x = tf.keras.layers.Dense(128, activation='relu', name='dense_128')(pretrained_model.output)\n",
    "            x = tf.keras.layers.Dense(50, activation='relu', name='dense_50')(x)\n",
    "\n",
    "            outputs = tf.keras.layers.Dense(class_count, activation='softmax', name='output_layer')(x)\n",
    "            model = tf.keras.Model(inputs, outputs)\n",
    "            # print(model.summary())\n",
    "            # =========================\n",
    "\n",
    "\n",
    "            \n",
    "            ## compile and evaluate\n",
    "            # =========================\n",
    "\n",
    "            print(\"-------Training \" + save_path + \"_\" + concat_type + \"-------\")\n",
    "            model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "            ## early stop \n",
    "            early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)\n",
    "            model.fit(train_images, validation_data=val_images, callbacks=[early_stopping], epochs=30, verbose=0)\n",
    "            ## no early stop\n",
    "            # history = model.fit(train_images, validation_data=val_images, epochs=30)\n",
    "\n",
    "            model.evaluate(test_images, verbose=0)\n",
    "            # =========================\n",
    "\n",
    "            pred = model.predict(test_images)\n",
    "\n",
    "            ## 把pred分開存\n",
    "            if save_path == \"front\":\n",
    "                front_pred = pred\n",
    "            else:\n",
    "                side_pred = pred\n",
    "            predicted_labels = np.argmax(pred, axis=1)\n",
    "        # =========================\n",
    "            \n",
    "        ## print each fold results\n",
    "        # =========================\n",
    "        ## 做voting\n",
    "        for i in range(len(vote_type_arr)):\n",
    "            print(\"------- \"+vote_type_arr[i]+\" -------\")\n",
    "            if vote_type_arr[i] == \"front\":\n",
    "                predicted_labels = np.argmax(front_pred, axis=1)\n",
    "            if vote_type_arr[i] == \"side\":\n",
    "                predicted_labels = np.argmax(side_pred, axis=1)\n",
    "            if vote_type_arr[i] == \"soft\":\n",
    "                soft_pred = np.argmax((front_pred + side_pred) / 2 , axis=1)\n",
    "                predicted_labels = soft_pred\n",
    "            if vote_type_arr[i] == \"hard\":\n",
    "                hard_front_pred = np.argmax(front_pred, axis=1)  \n",
    "                hard_side_pred = np.argmax(side_pred, axis=1)  \n",
    "                hard_pred = mode([hard_front_pred, hard_side_pred], axis=0).mode[0]  \n",
    "                predicted_labels = hard_pred\n",
    "            # if vote_type_arr[i] == \"product\":\n",
    "            #     product_pred = [[a * b for a, b in zip(sublist1, sublist2)] for sublist1, sublist2 in zip(front_pred, side_pred)]\n",
    "            #     predicted_labels = product_pred\n",
    "\n",
    "            acc = accuracy_score(test_images.labels, predicted_labels)\n",
    "            f1 = f1_score(test_images.labels, predicted_labels, average='macro')\n",
    "            # precision = precision_score(test_images.labels, predicted_labels, average='macro')\n",
    "            # recall = recall_score(test_images.labels, predicted_labels, average='macro')\n",
    "\n",
    "            print(f\"Test Accuracy: {np.round(acc, 2)}\")\n",
    "            print(f\"f1 score: {np.round(f1, 2)}\")\n",
    "            # print(f\"precision: {np.round(precision, 2)}\")\n",
    "            # print(f\"recall: {np.round(recall, 2)}\")\n",
    "\n",
    "            ## 存起來要做統計\n",
    "            vote_type_arr_acc[i].append(np.round(acc, 2))\n",
    "            vote_type_arr_f1[i].append(np.round(f1, 2))\n",
    "\n",
    "            # print(vote_type_arr_acc)\n",
    "            # print(vote_type_arr_f1)\n",
    "\n",
    "        fold_no += 1\n",
    "        # =========================\n",
    "    # ==================================================\n",
    "        \n",
    "    ## print  mean results\n",
    "    acc_mean = []\n",
    "    acc_std = []\n",
    "    f1_mean = []\n",
    "    f1_std = []\n",
    "    # =========================\n",
    "    for i in range(len(vote_type_arr)):\n",
    "        acc_mean.append(np.round(np.mean(vote_type_arr_acc[i]), 2))\n",
    "        acc_std.append(np.round(np.std(vote_type_arr_acc[i]), 2))\n",
    "        f1_mean.append(np.round(np.mean(vote_type_arr_f1[i]), 2))\n",
    "        f1_std.append(np.round(np.std(vote_type_arr_f1[i]), 2))\n",
    "    # print(f\"acc mean = {acc_mean}, std = {acc_std}\")\n",
    "    # print(test_acc)\n",
    "    # print(f\"f1  mean = {f1_mean}, std = {f1_std}\")\n",
    "    # print(test_f1)\n",
    "    # =========================\n",
    "\n",
    "    return {'acc_mean':acc_mean, 'acc_std':acc_std, 'test_acc':vote_type_arr_acc, 'f1_mean':f1_mean, 'f1_std':f1_std, 'test_f1':vote_type_arr_f1}\n",
    "\n",
    "\n",
    "path = \"E:\\\\data_bone\\\\9-a+b_swift_cut_正確_V2\\\\front\"\n",
    "\n",
    "concat_type = \"voting\"\n",
    "side_pred = \"\"\n",
    "front_pred = \"\"\n",
    "\n",
    "# =========================\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "results = train_cross_validation(image_dir=path, class_count=3)\n",
    "\n",
    "\n",
    "print(f\"acc mean = {results['acc_mean']}, std = {results['acc_std']}, test_acc = {results['test_acc']}\")\n",
    "print(f\"f1  mean = {results['f1_mean']}, std = {results['f1_std']}, test_f1 = {results['test_f1']}\")\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path\n",
    "# import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from scipy.stats import mode\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "## label\n",
    "# =========================\n",
    "def class_2_type(root):\n",
    "    label = \"\"\n",
    "    if \"正常\" in root:\n",
    "        label = \"0\"\n",
    "    else:\n",
    "        label = \"1\"\n",
    "    return label\n",
    "\n",
    "def class_3_type(root):\n",
    "    label = \"\"\n",
    "    if \"正常\" in root:\n",
    "        label = \"0\"\n",
    "    elif \"雙踝\" in root:\n",
    "        label = \"1\"\n",
    "    elif \"三踝\" in root:\n",
    "        label = \"2\"\n",
    "    return label\n",
    "# =========================\n",
    "\n",
    "\n",
    "def load_path(path, class_count):\n",
    "    dataset = []\n",
    "    class_type = ''\n",
    "    if class_count == 2:\n",
    "        class_type = class_2_type\n",
    "    elif class_count == 3:\n",
    "        class_type = class_3_type  \n",
    "\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            label = class_type(root)\n",
    "            # if label != \"\":\n",
    "            dataset.append(\n",
    "                            {   \n",
    "                                'uuid': root.split(\"\\\\\")[-1],\n",
    "                                'label': label,\n",
    "                                'image_path': os.path.join(root, file)\n",
    "                            }\n",
    "                        )\n",
    "\n",
    "    return dataset\n",
    "\n",
    "# def train_cross_validation(image_dir, n_splits=5, class_count=2, maru_part=None,  chosen_model='resnet50'):\n",
    "def train_cross_validation(image_dir, n_splits=5, class_count=2):\n",
    "\n",
    "\n",
    "    ## load data and  labels\n",
    "    # =========================\n",
    "    labels = []\n",
    "    filepaths = []\n",
    "    data = load_path(image_dir, class_count)\n",
    "    for row in data:\n",
    "        labels.append(row['label'])\n",
    "        filepaths.append(row['image_path'])\n",
    "\n",
    "    filepaths = pd.Series(filepaths, name='Filepath').astype(str)\n",
    "    labels = pd.Series(labels, name='Label')\n",
    "\n",
    "    images = pd.concat([filepaths, labels], axis=1)\n",
    "    # =========================\n",
    "\n",
    "\n",
    "    # ## load chosen model\n",
    "    # # =========================\n",
    "    # if chosen_model == 'resnet50':\n",
    "    #     preprocessing_function_chosen = tf.keras.applications.resnet50.preprocess_input\n",
    "    #     pretrained_model_chosen = tf.keras.applications.resnet50.ResNet50\n",
    "    # # elif chosen_model == 'resnet152':\n",
    "    # #     preprocessing_function_chosen = tf.keras.applications.resnet152.preprocess_input\n",
    "    # #     pretrained_model_chosen = tf.keras.applications.resnet152.ResNet152\n",
    "    # elif chosen_model == 'vgg16':\n",
    "    #     preprocessing_function_chosen = tf.keras.applications.vgg16.preprocess_input\n",
    "    #     pretrained_model_chosen = tf.keras.applications.vgg16.VGG16\n",
    "    # elif chosen_model == 'vgg19':\n",
    "    #     preprocessing_function_chosen = tf.keras.applications.vgg19.preprocess_input\n",
    "    #     pretrained_model_chosen = tf.keras.applications.vgg19.VGG19\n",
    "    # elif chosen_model == 'mobilenet':\n",
    "    #     preprocessing_function_chosen = tf.keras.applications.mobilenet.preprocess_input\n",
    "    #     pretrained_model_chosen = tf.keras.applications.mobilenet.MobileNet\n",
    "    # elif chosen_model == 'mobilenet_v2':\n",
    "    #     preprocessing_function_chosen = tf.keras.applications.mobilenet_v2.preprocess_input\n",
    "    #     pretrained_model_chosen = tf.keras.applications.mobilenet_v2.MobileNetV2\n",
    "    # elif chosen_model == 'efficientnet':\n",
    "    #     preprocessing_function_chosen = tf.keras.applications.efficientnet.preprocess_input\n",
    "    #     pretrained_model_chosen = tf.keras.applications.efficientnet.EfficientNetB0\n",
    "    # elif chosen_model == 'inception_v3':\n",
    "    #     preprocessing_function_chosen = tf.keras.applications.inception_v3.preprocess_input\n",
    "    #     pretrained_model_chosen = tf.keras.applications.inception_v3.InceptionV3\n",
    "    # else:\n",
    "    #     raise ValueError(\"Model name not recognized. Please choose a valid model.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # =========================\n",
    "\n",
    "    ## to do: loss function\n",
    "    # =========================\n",
    "    # =========================\n",
    "\n",
    "\n",
    "    train_df, test_df = train_test_split(images, train_size=0.8, shuffle=True, random_state=1, stratify=images['Label'])\n",
    "\n",
    "\n",
    "    ## train model, k fold cross validation\n",
    "    # ==================================================\n",
    "    fold_no = 1\n",
    "    # test_acc = []\n",
    "    # test_f1 = []\n",
    "    front_test_acc = []\n",
    "    side_test_acc = []\n",
    "    soft_test_acc = []\n",
    "    hard_test_acc = []\n",
    "\n",
    "    front_test_f1 = []\n",
    "    side_test_f1 = []\n",
    "    soft_test_f1 = []\n",
    "    hard_test_f1 = []\n",
    "    \n",
    "    vote_type_arr_acc = [front_test_acc, side_test_acc, soft_test_acc, hard_test_acc]\n",
    "    vote_type_arr_f1 = [front_test_f1, side_test_f1, soft_test_f1, hard_test_f1]\n",
    "    vote_type_arr = [\"front\", \"side\", \"soft\", \"hard\"]\n",
    "\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=1)\n",
    "    for train_index, val_index in kfold.split(train_df, train_df['Label']):\n",
    "        k_fold_train = train_df.iloc[train_index]\n",
    "        k_fold_val = train_df.iloc[val_index]\n",
    "\n",
    "\n",
    "        ## train, validation image\n",
    "        # =========================\n",
    "        ## train front and side\n",
    "        save_path_arr = [\"front\", \"side\"]\n",
    "        for save_path in save_path_arr:\n",
    "            ## 分資料\n",
    "            # =========================\n",
    "            if save_path == \"side\":\n",
    "                k_fold_train.loc[:, \"Filepath\"] = k_fold_train[\"Filepath\"].str.replace(\"front\", \"side\")\n",
    "                k_fold_val.loc[:, \"Filepath\"] = k_fold_val[\"Filepath\"].str.replace(\"front\", \"side\")\n",
    "                test_df.loc[:, \"Filepath\"] = test_df[\"Filepath\"].str.replace(\"front\", \"side\")\n",
    "                preprocessing_function_chosen = tf.keras.applications.efficientnet.preprocess_input\n",
    "                pretrained_model_chosen = tf.keras.applications.efficientnet.EfficientNetB0\n",
    "\n",
    "            if save_path == \"front\":\n",
    "                k_fold_train.loc[:, \"Filepath\"] = k_fold_train[\"Filepath\"].str.replace(\"side\", \"front\")\n",
    "                k_fold_val.loc[:, \"Filepath\"] = k_fold_val[\"Filepath\"].str.replace(\"side\", \"front\")\n",
    "                test_df.loc[:, \"Filepath\"] = test_df[\"Filepath\"].str.replace(\"side\", \"front\")\n",
    "                preprocessing_function_chosen = tf.keras.applications.resnet50.preprocess_input\n",
    "                pretrained_model_chosen = tf.keras.applications.resnet50.ResNet50\n",
    "\n",
    "            print(len(k_fold_train))\n",
    "            print(len(k_fold_val))\n",
    "\n",
    "\n",
    "            # 確認\n",
    "            print(k_fold_train.iloc[0]['Filepath'].split(\"\\\\\")[-3])\n",
    "            print(test_df.iloc[0]['Filepath'].split(\"\\\\\")[-3])\n",
    "            \n",
    "            ## 讀資料\n",
    "            # =========================\n",
    "            train_generator = tf.keras.preprocessing.image.ImageDataGenerator(horizontal_flip=False,preprocessing_function=preprocessing_function_chosen)\n",
    "            train_images = train_generator.flow_from_dataframe(\n",
    "                dataframe=k_fold_train,\n",
    "                x_col='Filepath',\n",
    "                y_col='Label',\n",
    "                target_size=(224, 224),\n",
    "                color_mode='rgb',\n",
    "                class_mode='categorical',\n",
    "                batch_size=64,\n",
    "                shuffle=True,\n",
    "                seed=42,\n",
    "            )\n",
    "            val_images = train_generator.flow_from_dataframe(\n",
    "                dataframe=k_fold_val,\n",
    "                x_col='Filepath',\n",
    "                y_col='Label',\n",
    "                target_size=(224, 224),\n",
    "                color_mode='rgb',\n",
    "                class_mode='categorical',\n",
    "                batch_size=64,\n",
    "                shuffle=True,\n",
    "                seed=42,\n",
    "            )\n",
    "            test_generator = tf.keras.preprocessing.image.ImageDataGenerator(preprocessing_function=preprocessing_function_chosen)\n",
    "            test_images = test_generator.flow_from_dataframe(\n",
    "                dataframe=test_df,\n",
    "                x_col='Filepath',\n",
    "                y_col='Label',\n",
    "                target_size=(224, 224),\n",
    "                color_mode='rgb',\n",
    "                class_mode='categorical',\n",
    "                batch_size=32,\n",
    "                shuffle=False\n",
    "            )\n",
    "            # =========================\n",
    "            \n",
    "            # load model\n",
    "            # =========================\n",
    "            pretrained_model = pretrained_model_chosen(\n",
    "                input_shape=(224, 224, 3),\n",
    "                include_top=False,\n",
    "                weights='imagenet',\n",
    "                pooling='avg')\n",
    "\n",
    "            pretrained_model.trainable = False\n",
    "\n",
    "            inputs = pretrained_model.input\n",
    "            x = tf.keras.layers.Dense(128, activation='relu', name='dense_128')(pretrained_model.output)\n",
    "            x = tf.keras.layers.Dense(50, activation='relu', name='dense_50')(x)\n",
    "\n",
    "            outputs = tf.keras.layers.Dense(class_count, activation='softmax', name='output_layer')(x)\n",
    "            model = tf.keras.Model(inputs, outputs)\n",
    "            # print(model.summary())\n",
    "            # =========================\n",
    "\n",
    "\n",
    "            \n",
    "            ## compile and evaluate\n",
    "            # =========================\n",
    "\n",
    "            print(\"-------Training \" + save_path + \"_\" + concat_type + \"-------\")\n",
    "            model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "            ## early stop \n",
    "            early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\n",
    "            model.fit(train_images, validation_data=val_images, callbacks=[early_stopping], epochs=30, verbose=0)\n",
    "            ## no early stop\n",
    "            # history = model.fit(train_images, validation_data=val_images, epochs=30)\n",
    "\n",
    "            model.evaluate(test_images, verbose=0)\n",
    "            # =========================\n",
    "\n",
    "            pred = model.predict(test_images)\n",
    "\n",
    "            ## 把pred分開存\n",
    "            if save_path == \"front\":\n",
    "                front_pred = pred\n",
    "            else:\n",
    "                side_pred = pred\n",
    "            predicted_labels = np.argmax(pred, axis=1)\n",
    "        # =========================\n",
    "            \n",
    "        ## print each fold results\n",
    "        # =========================\n",
    "        ## 做voting\n",
    "        for i in range(len(vote_type_arr)):\n",
    "            print(\"------- \"+vote_type_arr[i]+\" -------\")\n",
    "            if vote_type_arr[i] == \"front\":\n",
    "                predicted_labels = np.argmax(front_pred, axis=1)\n",
    "            if vote_type_arr[i] == \"side\":\n",
    "                predicted_labels = np.argmax(side_pred, axis=1)\n",
    "            if vote_type_arr[i] == \"soft\":\n",
    "                soft_pred = np.argmax((front_pred + side_pred) / 2 , axis=1)\n",
    "                predicted_labels = soft_pred\n",
    "            if vote_type_arr[i] == \"hard\":\n",
    "                hard_front_pred = np.argmax(front_pred, axis=1)  \n",
    "                hard_side_pred = np.argmax(side_pred, axis=1)  \n",
    "                hard_pred = mode([hard_front_pred, hard_side_pred], axis=0).mode[0]  \n",
    "                predicted_labels = hard_pred\n",
    "            \n",
    "            acc = accuracy_score(test_images.labels, predicted_labels)\n",
    "            f1 = f1_score(test_images.labels, predicted_labels, average='macro')\n",
    "            # precision = precision_score(test_images.labels, predicted_labels, average='macro')\n",
    "            # recall = recall_score(test_images.labels, predicted_labels, average='macro')\n",
    "\n",
    "            print(f\"Test Accuracy: {np.round(acc, 2)}\")\n",
    "            print(f\"f1 score: {np.round(f1, 2)}\")\n",
    "            # print(f\"precision: {np.round(precision, 2)}\")\n",
    "            # print(f\"recall: {np.round(recall, 2)}\")\n",
    "\n",
    "            ## 存起來要做統計\n",
    "            vote_type_arr_acc[i].append(np.round(acc, 2))\n",
    "            vote_type_arr_f1[i].append(np.round(f1, 2))\n",
    "\n",
    "            # print(vote_type_arr_acc)\n",
    "            # print(vote_type_arr_f1)\n",
    "\n",
    "        fold_no += 1\n",
    "        # =========================\n",
    "    # ==================================================\n",
    "        \n",
    "    ## print  mean results\n",
    "    acc_mean = []\n",
    "    acc_std = []\n",
    "    f1_mean = []\n",
    "    f1_std = []\n",
    "    # =========================\n",
    "    for i in range(len(vote_type_arr)):\n",
    "        acc_mean.append(np.round(np.mean(vote_type_arr_acc[i]), 2))\n",
    "        acc_std.append(np.round(np.std(vote_type_arr_acc[i]), 2))\n",
    "        f1_mean.append(np.round(np.mean(vote_type_arr_f1[i]), 2))\n",
    "        f1_std.append(np.round(np.std(vote_type_arr_f1[i]), 2))\n",
    "    # print(f\"acc mean = {acc_mean}, std = {acc_std}\")\n",
    "    # print(test_acc)\n",
    "    # print(f\"f1  mean = {f1_mean}, std = {f1_std}\")\n",
    "    # print(test_f1)\n",
    "    # =========================\n",
    "\n",
    "    return {'acc_mean':acc_mean, 'acc_std':acc_std, 'test_acc':vote_type_arr_acc, 'f1_mean':f1_mean, 'f1_std':f1_std, 'test_f1':vote_type_arr_f1}\n",
    "\n",
    "\n",
    "path = \"E:\\\\data_bone\\\\9-a+b_swift_cut_正確_V2\\\\front\"\n",
    "\n",
    "concat_type = \"voting\"\n",
    "side_pred = \"\"\n",
    "front_pred = \"\"\n",
    "\n",
    "# =========================\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "results = train_cross_validation(image_dir=path, class_count=3)\n",
    "\n",
    "\n",
    "print(f\"acc mean = {results['acc_mean']}, std = {results['acc_std']}, test_acc = {results['test_acc']}\")\n",
    "print(f\"f1  mean = {results['f1_mean']}, std = {results['f1_std']}, test_f1 = {results['test_f1']}\")\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path\n",
    "# import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from scipy.stats import mode\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "## label\n",
    "# =========================\n",
    "def class_2_type(root):\n",
    "    label = \"\"\n",
    "    if \"正常\" in root:\n",
    "        label = \"0\"\n",
    "    else:\n",
    "        label = \"1\"\n",
    "    return label\n",
    "\n",
    "def class_3_type(root):\n",
    "    label = \"\"\n",
    "    if \"正常\" in root:\n",
    "        label = \"0\"\n",
    "    elif \"雙踝\" in root:\n",
    "        label = \"1\"\n",
    "    elif \"三踝\" in root:\n",
    "        label = \"2\"\n",
    "    return label\n",
    "# =========================\n",
    "\n",
    "\n",
    "def load_path(path, class_count):\n",
    "    dataset = []\n",
    "    class_type = ''\n",
    "    if class_count == 2:\n",
    "        class_type = class_2_type\n",
    "    elif class_count == 3:\n",
    "        class_type = class_3_type  \n",
    "\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            label = class_type(root)\n",
    "            # if label != \"\":\n",
    "            dataset.append(\n",
    "                            {   \n",
    "                                'uuid': root.split(\"\\\\\")[-1],\n",
    "                                'label': label,\n",
    "                                'image_path': os.path.join(root, file)\n",
    "                            }\n",
    "                        )\n",
    "\n",
    "    return dataset\n",
    "\n",
    "# def train_cross_validation(image_dir, n_splits=5, class_count=2, maru_part=None,  chosen_model='resnet50'):\n",
    "def train_cross_validation(image_dir, n_splits=5, class_count=2):\n",
    "\n",
    "\n",
    "    ## load data and  labels\n",
    "    # =========================\n",
    "    labels = []\n",
    "    filepaths = []\n",
    "    data = load_path(image_dir, class_count)\n",
    "    for row in data:\n",
    "        labels.append(row['label'])\n",
    "        filepaths.append(row['image_path'])\n",
    "\n",
    "    filepaths = pd.Series(filepaths, name='Filepath').astype(str)\n",
    "    labels = pd.Series(labels, name='Label')\n",
    "\n",
    "    images = pd.concat([filepaths, labels], axis=1)\n",
    "    # =========================\n",
    "\n",
    "\n",
    "    # ## load chosen model\n",
    "    # # =========================\n",
    "    # if chosen_model == 'resnet50':\n",
    "    #     preprocessing_function_chosen = tf.keras.applications.resnet50.preprocess_input\n",
    "    #     pretrained_model_chosen = tf.keras.applications.resnet50.ResNet50\n",
    "    # # elif chosen_model == 'resnet152':\n",
    "    # #     preprocessing_function_chosen = tf.keras.applications.resnet152.preprocess_input\n",
    "    # #     pretrained_model_chosen = tf.keras.applications.resnet152.ResNet152\n",
    "    # elif chosen_model == 'vgg16':\n",
    "    #     preprocessing_function_chosen = tf.keras.applications.vgg16.preprocess_input\n",
    "    #     pretrained_model_chosen = tf.keras.applications.vgg16.VGG16\n",
    "    # elif chosen_model == 'vgg19':\n",
    "    #     preprocessing_function_chosen = tf.keras.applications.vgg19.preprocess_input\n",
    "    #     pretrained_model_chosen = tf.keras.applications.vgg19.VGG19\n",
    "    # elif chosen_model == 'mobilenet':\n",
    "    #     preprocessing_function_chosen = tf.keras.applications.mobilenet.preprocess_input\n",
    "    #     pretrained_model_chosen = tf.keras.applications.mobilenet.MobileNet\n",
    "    # elif chosen_model == 'mobilenet_v2':\n",
    "    #     preprocessing_function_chosen = tf.keras.applications.mobilenet_v2.preprocess_input\n",
    "    #     pretrained_model_chosen = tf.keras.applications.mobilenet_v2.MobileNetV2\n",
    "    # elif chosen_model == 'efficientnet':\n",
    "    #     preprocessing_function_chosen = tf.keras.applications.efficientnet.preprocess_input\n",
    "    #     pretrained_model_chosen = tf.keras.applications.efficientnet.EfficientNetB0\n",
    "    # elif chosen_model == 'inception_v3':\n",
    "    #     preprocessing_function_chosen = tf.keras.applications.inception_v3.preprocess_input\n",
    "    #     pretrained_model_chosen = tf.keras.applications.inception_v3.InceptionV3\n",
    "    # else:\n",
    "    #     raise ValueError(\"Model name not recognized. Please choose a valid model.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # =========================\n",
    "\n",
    "    ## to do: loss function\n",
    "    # =========================\n",
    "    # =========================\n",
    "\n",
    "\n",
    "    train_df, test_df = train_test_split(images, train_size=0.8, shuffle=True, random_state=1, stratify=images['Label'])\n",
    "\n",
    "\n",
    "    ## train model, k fold cross validation\n",
    "    # ==================================================\n",
    "    fold_no = 1\n",
    "    # test_acc = []\n",
    "    # test_f1 = []\n",
    "    front_test_acc = []\n",
    "    side_test_acc = []\n",
    "    soft_test_acc = []\n",
    "    hard_test_acc = []\n",
    "\n",
    "    front_test_f1 = []\n",
    "    side_test_f1 = []\n",
    "    soft_test_f1 = []\n",
    "    hard_test_f1 = []\n",
    "    \n",
    "    vote_type_arr_acc = [front_test_acc, side_test_acc, soft_test_acc, hard_test_acc]\n",
    "    vote_type_arr_f1 = [front_test_f1, side_test_f1, soft_test_f1, hard_test_f1]\n",
    "    vote_type_arr = [\"front\", \"side\", \"soft\", \"hard\"]\n",
    "\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=1)\n",
    "    for train_index, val_index in kfold.split(train_df, train_df['Label']):\n",
    "        k_fold_train = train_df.iloc[train_index]\n",
    "        k_fold_val = train_df.iloc[val_index]\n",
    "\n",
    "\n",
    "        ## train, validation image\n",
    "        # =========================\n",
    "        ## train front and side\n",
    "        save_path_arr = [\"front\", \"side\"]\n",
    "        for save_path in save_path_arr:\n",
    "            ## 分資料\n",
    "            # =========================\n",
    "            if save_path == \"side\":\n",
    "                k_fold_train.loc[:, \"Filepath\"] = k_fold_train[\"Filepath\"].str.replace(\"front\", \"side\")\n",
    "                k_fold_val.loc[:, \"Filepath\"] = k_fold_val[\"Filepath\"].str.replace(\"front\", \"side\")\n",
    "                test_df.loc[:, \"Filepath\"] = test_df[\"Filepath\"].str.replace(\"front\", \"side\")\n",
    "                preprocessing_function_chosen = tf.keras.applications.efficientnet.preprocess_input\n",
    "                pretrained_model_chosen = tf.keras.applications.efficientnet.EfficientNetB0\n",
    "\n",
    "            if save_path == \"front\":\n",
    "                k_fold_train.loc[:, \"Filepath\"] = k_fold_train[\"Filepath\"].str.replace(\"side\", \"front\")\n",
    "                k_fold_val.loc[:, \"Filepath\"] = k_fold_val[\"Filepath\"].str.replace(\"side\", \"front\")\n",
    "                test_df.loc[:, \"Filepath\"] = test_df[\"Filepath\"].str.replace(\"side\", \"front\")\n",
    "                preprocessing_function_chosen = tf.keras.applications.resnet50.preprocess_input\n",
    "                pretrained_model_chosen = tf.keras.applications.resnet50.ResNet50\n",
    "\n",
    "            print(len(k_fold_train))\n",
    "            print(len(k_fold_val))\n",
    "\n",
    "\n",
    "            # 確認\n",
    "            print(k_fold_train.iloc[0]['Filepath'].split(\"\\\\\")[-3])\n",
    "            print(test_df.iloc[0]['Filepath'].split(\"\\\\\")[-3])\n",
    "            \n",
    "            ## 讀資料\n",
    "            # =========================\n",
    "            train_generator = tf.keras.preprocessing.image.ImageDataGenerator(horizontal_flip=False,preprocessing_function=preprocessing_function_chosen)\n",
    "            train_images = train_generator.flow_from_dataframe(\n",
    "                dataframe=k_fold_train,\n",
    "                x_col='Filepath',\n",
    "                y_col='Label',\n",
    "                target_size=(224, 224),\n",
    "                color_mode='rgb',\n",
    "                class_mode='categorical',\n",
    "                batch_size=64,\n",
    "                shuffle=True,\n",
    "                seed=42,\n",
    "            )\n",
    "            val_images = train_generator.flow_from_dataframe(\n",
    "                dataframe=k_fold_val,\n",
    "                x_col='Filepath',\n",
    "                y_col='Label',\n",
    "                target_size=(224, 224),\n",
    "                color_mode='rgb',\n",
    "                class_mode='categorical',\n",
    "                batch_size=64,\n",
    "                shuffle=True,\n",
    "                seed=42,\n",
    "            )\n",
    "            test_generator = tf.keras.preprocessing.image.ImageDataGenerator(preprocessing_function=preprocessing_function_chosen)\n",
    "            test_images = test_generator.flow_from_dataframe(\n",
    "                dataframe=test_df,\n",
    "                x_col='Filepath',\n",
    "                y_col='Label',\n",
    "                target_size=(224, 224),\n",
    "                color_mode='rgb',\n",
    "                class_mode='categorical',\n",
    "                batch_size=32,\n",
    "                shuffle=False\n",
    "            )\n",
    "            # =========================\n",
    "            \n",
    "            # load model\n",
    "            # =========================\n",
    "            pretrained_model = pretrained_model_chosen(\n",
    "                input_shape=(224, 224, 3),\n",
    "                include_top=False,\n",
    "                weights='imagenet',\n",
    "                pooling='avg')\n",
    "\n",
    "            pretrained_model.trainable = False\n",
    "\n",
    "            inputs = pretrained_model.input\n",
    "            x = tf.keras.layers.Dense(128, activation='relu', name='dense_128')(pretrained_model.output)\n",
    "            x = tf.keras.layers.Dense(50, activation='relu', name='dense_50')(x)\n",
    "\n",
    "            outputs = tf.keras.layers.Dense(class_count, activation='softmax', name='output_layer')(x)\n",
    "            model = tf.keras.Model(inputs, outputs)\n",
    "            # print(model.summary())\n",
    "            # =========================\n",
    "\n",
    "\n",
    "            \n",
    "            ## compile and evaluate\n",
    "            # =========================\n",
    "\n",
    "            print(\"-------Training \" + save_path + \"_\" + concat_type + \"-------\")\n",
    "            model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "            ## early stop \n",
    "            # early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)\n",
    "            # model.fit(train_images, validation_data=val_images, callbacks=[early_stopping], epochs=30)\n",
    "            ## no early stop\n",
    "            model.fit(train_images, validation_data=val_images, epochs=30, verbose=0)\n",
    "\n",
    "            model.evaluate(test_images, verbose=0)\n",
    "            # =========================\n",
    "\n",
    "            pred = model.predict(test_images)\n",
    "\n",
    "            ## 把pred分開存\n",
    "            if save_path == \"front\":\n",
    "                front_pred = pred\n",
    "            else:\n",
    "                side_pred = pred\n",
    "            predicted_labels = np.argmax(pred, axis=1)\n",
    "        # =========================\n",
    "            \n",
    "        ## print each fold results\n",
    "        # =========================\n",
    "        ## 做voting\n",
    "        for i in range(len(vote_type_arr)):\n",
    "            print(\"------- \"+vote_type_arr[i]+\" -------\")\n",
    "            if vote_type_arr[i] == \"front\":\n",
    "                predicted_labels = np.argmax(front_pred, axis=1)\n",
    "            if vote_type_arr[i] == \"side\":\n",
    "                predicted_labels = np.argmax(side_pred, axis=1)\n",
    "            if vote_type_arr[i] == \"soft\":\n",
    "                soft_pred = np.argmax((front_pred + side_pred) / 2 , axis=1)\n",
    "                predicted_labels = soft_pred\n",
    "            if vote_type_arr[i] == \"hard\":\n",
    "                hard_front_pred = np.argmax(front_pred, axis=1)  \n",
    "                hard_side_pred = np.argmax(side_pred, axis=1)  \n",
    "                hard_pred = mode([hard_front_pred, hard_side_pred], axis=0).mode[0]  \n",
    "                predicted_labels = hard_pred\n",
    "            \n",
    "            acc = accuracy_score(test_images.labels, predicted_labels)\n",
    "            f1 = f1_score(test_images.labels, predicted_labels, average='macro')\n",
    "            # precision = precision_score(test_images.labels, predicted_labels, average='macro')\n",
    "            # recall = recall_score(test_images.labels, predicted_labels, average='macro')\n",
    "\n",
    "            print(f\"Test Accuracy: {np.round(acc, 2)}\")\n",
    "            print(f\"f1 score: {np.round(f1, 2)}\")\n",
    "            # print(f\"precision: {np.round(precision, 2)}\")\n",
    "            # print(f\"recall: {np.round(recall, 2)}\")\n",
    "\n",
    "            ## 存起來要做統計\n",
    "            vote_type_arr_acc[i].append(np.round(acc, 2))\n",
    "            vote_type_arr_f1[i].append(np.round(f1, 2))\n",
    "\n",
    "            # print(vote_type_arr_acc)\n",
    "            # print(vote_type_arr_f1)\n",
    "\n",
    "        fold_no += 1\n",
    "        # =========================\n",
    "    # ==================================================\n",
    "        \n",
    "    ## print  mean results\n",
    "    acc_mean = []\n",
    "    acc_std = []\n",
    "    f1_mean = []\n",
    "    f1_std = []\n",
    "    # =========================\n",
    "    for i in range(len(vote_type_arr)):\n",
    "        acc_mean.append(np.round(np.mean(vote_type_arr_acc[i]), 2))\n",
    "        acc_std.append(np.round(np.std(vote_type_arr_acc[i]), 2))\n",
    "        f1_mean.append(np.round(np.mean(vote_type_arr_f1[i]), 2))\n",
    "        f1_std.append(np.round(np.std(vote_type_arr_f1[i]), 2))\n",
    "    # print(f\"acc mean = {acc_mean}, std = {acc_std}\")\n",
    "    # print(test_acc)\n",
    "    # print(f\"f1  mean = {f1_mean}, std = {f1_std}\")\n",
    "    # print(test_f1)\n",
    "    # =========================\n",
    "\n",
    "    return {'acc_mean':acc_mean, 'acc_std':acc_std, 'test_acc':vote_type_arr_acc, 'f1_mean':f1_mean, 'f1_std':f1_std, 'test_f1':vote_type_arr_f1}\n",
    "\n",
    "\n",
    "path = \"E:\\\\data_bone\\\\9-a+b_swift_cut_正確_V2\\\\front\"\n",
    "\n",
    "concat_type = \"voting\"\n",
    "side_pred = \"\"\n",
    "front_pred = \"\"\n",
    "\n",
    "# =========================\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "results = train_cross_validation(image_dir=path, class_count=3)\n",
    "\n",
    "\n",
    "print(f\"acc mean = {results['acc_mean']}, std = {results['acc_std']}, test_acc = {results['test_acc']}\")\n",
    "print(f\"f1  mean = {results['f1_mean']}, std = {results['f1_std']}, test_f1 = {results['test_f1']}\")\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bone_20240719",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
