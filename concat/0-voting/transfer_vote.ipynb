{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, f1_score, precision_score, recall_score\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label\n",
    "# =========================\n",
    "def class_2_type(root):\n",
    "    label = \"\"\n",
    "    if \"正常\" in root:\n",
    "        label = \"0\"\n",
    "    else:\n",
    "        label = \"1\"\n",
    "    return label\n",
    "\n",
    "# def class_2_type(root):\n",
    "#     label = \"\"\n",
    "#     if \"雙踝\" in root:\n",
    "#         label = \"0\"\n",
    "#     elif \"三踝\" in root:\n",
    "#         label = \"1\"\n",
    "#     return label\n",
    "\n",
    "def class_3_type(root):\n",
    "    label = \"\"\n",
    "    if \"正常\" in root:\n",
    "        label = \"0\"\n",
    "    elif \"雙踝\" in root:\n",
    "        label = \"1\"\n",
    "    elif \"三踝\" in root:\n",
    "        label = \"2\"\n",
    "    return label\n",
    "# ========================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_path(path, class_count):\n",
    "    dataset = []\n",
    "    class_type = ''\n",
    "    if class_count == 2:\n",
    "        class_type = class_2_type\n",
    "    elif class_count == 3:\n",
    "        class_type = class_3_type   \n",
    "\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            label = class_type(root)\n",
    "            if label != \"\":\n",
    "                dataset.append(\n",
    "                                {   \n",
    "                                    'uuid': root.split(\"\\\\\")[-1],\n",
    "                                    'label': label,\n",
    "                                    'image_path': os.path.join(root, file)\n",
    "                                }\n",
    "                            )\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 參數設置\n",
    "image_dir = \"E:\\\\data_bone\\\\9-a+b_swift_cut_正確_V2\\\\front\"\n",
    "concat_type = \"voting\"\n",
    "class_count = 3\n",
    "maru_part=None\n",
    "\n",
    "side_pred = \"\"\n",
    "front_pred = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set label distribution:\n",
      " 0    128\n",
      "2     95\n",
      "1     93\n",
      "Name: Label, dtype: int64\n",
      "Test set label distribution:\n",
      " 0    32\n",
      "1    24\n",
      "2    24\n",
      "Name: Label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## load data and  labels\n",
    "# =========================\n",
    "data = load_path(image_dir, class_count)\n",
    "labels = []\n",
    "filepaths = []\n",
    "for row in data:\n",
    "    labels.append(row['label'])\n",
    "    filepaths.append(row['image_path'])\n",
    "\n",
    "filepaths = pd.Series(filepaths, name='Filepath').astype(str)\n",
    "labels = pd.Series(labels, name='Label')\n",
    "\n",
    "images = pd.concat([filepaths, labels], axis=1)\n",
    "# =========================\n",
    "\n",
    "\n",
    "## split image\n",
    "# =========================\n",
    "train_df, test_df = train_test_split(images, train_size=0.8, shuffle=True, random_state=44, stratify=images['Label'])\n",
    "print(\"Training set label distribution:\\n\", train_df['Label'].value_counts(normalize=False))\n",
    "print(\"Test set label distribution:\\n\", test_df['Label'].value_counts(normalize=False))\n",
    "\n",
    "# 關閉翻轉\n",
    "train_generator = tf.keras.preprocessing.image.ImageDataGenerator(horizontal_flip=False,\n",
    "                                                                    preprocessing_function=tf.keras.applications.resnet50.preprocess_input,\n",
    "                                                                    validation_split=0.2)\n",
    "test_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    preprocessing_function=tf.keras.applications.resnet50.preprocess_input)\n",
    "# ========================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "front\n",
      "Found 253 validated image filenames belonging to 3 classes.\n",
      "Found 63 validated image filenames belonging to 3 classes.\n",
      "Found 80 validated image filenames belonging to 3 classes.\n",
      "-------Training front_voting-------\n",
      "Epoch 1/30\n",
      "4/4 [==============================] - 5s 728ms/step - loss: 1.4417 - accuracy: 0.3439 - val_loss: 1.1214 - val_accuracy: 0.4286\n",
      "Epoch 2/30\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 1.0681 - accuracy: 0.4506 - val_loss: 1.0391 - val_accuracy: 0.5556\n",
      "Epoch 3/30\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 0.9873 - accuracy: 0.5257 - val_loss: 1.0066 - val_accuracy: 0.5873\n",
      "Epoch 4/30\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.9205 - accuracy: 0.6047 - val_loss: 0.9154 - val_accuracy: 0.6190\n",
      "Epoch 5/30\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 0.8419 - accuracy: 0.6640 - val_loss: 0.8350 - val_accuracy: 0.7143\n",
      "Epoch 6/30\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 0.7782 - accuracy: 0.7036 - val_loss: 0.7811 - val_accuracy: 0.7143\n",
      "Epoch 7/30\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 0.7362 - accuracy: 0.6957 - val_loss: 0.7326 - val_accuracy: 0.7302\n",
      "Epoch 8/30\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 0.6834 - accuracy: 0.7352 - val_loss: 0.6886 - val_accuracy: 0.7460\n",
      "Epoch 9/30\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 0.6404 - accuracy: 0.7787 - val_loss: 0.6540 - val_accuracy: 0.7619\n",
      "Epoch 10/30\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 0.6047 - accuracy: 0.8024 - val_loss: 0.6146 - val_accuracy: 0.7937\n",
      "Epoch 11/30\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 0.5703 - accuracy: 0.8063 - val_loss: 0.5886 - val_accuracy: 0.7619\n",
      "Epoch 12/30\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 0.5469 - accuracy: 0.8221 - val_loss: 0.5679 - val_accuracy: 0.7619\n",
      "Epoch 13/30\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 0.5208 - accuracy: 0.8300 - val_loss: 0.5386 - val_accuracy: 0.7778\n",
      "Epoch 14/30\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 0.4982 - accuracy: 0.8458 - val_loss: 0.5213 - val_accuracy: 0.7619\n",
      "Epoch 15/30\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 0.4756 - accuracy: 0.8538 - val_loss: 0.5135 - val_accuracy: 0.7778\n",
      "Epoch 16/30\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.4615 - accuracy: 0.8656 - val_loss: 0.4983 - val_accuracy: 0.7778\n",
      "Epoch 17/30\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 0.4403 - accuracy: 0.8775 - val_loss: 0.4893 - val_accuracy: 0.7778\n",
      "Epoch 18/30\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 0.4315 - accuracy: 0.8735 - val_loss: 0.4760 - val_accuracy: 0.8413\n",
      "Epoch 19/30\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 0.4101 - accuracy: 0.8972 - val_loss: 0.4709 - val_accuracy: 0.7937\n",
      "Epoch 20/30\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 0.3997 - accuracy: 0.8933 - val_loss: 0.4679 - val_accuracy: 0.7937\n",
      "Epoch 21/30\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 0.3846 - accuracy: 0.8933 - val_loss: 0.4531 - val_accuracy: 0.8413\n",
      "Epoch 22/30\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 0.3779 - accuracy: 0.8893 - val_loss: 0.4507 - val_accuracy: 0.8254\n",
      "Epoch 23/30\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 0.3618 - accuracy: 0.9051 - val_loss: 0.4449 - val_accuracy: 0.8254\n",
      "Epoch 24/30\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.3509 - accuracy: 0.9091 - val_loss: 0.4410 - val_accuracy: 0.8254\n",
      "Epoch 25/30\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 0.3416 - accuracy: 0.9170 - val_loss: 0.4361 - val_accuracy: 0.8571\n",
      "Epoch 26/30\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.3329 - accuracy: 0.9249 - val_loss: 0.4338 - val_accuracy: 0.8413\n",
      "Epoch 27/30\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.3216 - accuracy: 0.9289 - val_loss: 0.4334 - val_accuracy: 0.8254\n",
      "Epoch 28/30\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 0.3137 - accuracy: 0.9249 - val_loss: 0.4279 - val_accuracy: 0.8413\n",
      "Epoch 29/30\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 0.3041 - accuracy: 0.9289 - val_loss: 0.4248 - val_accuracy: 0.8571\n",
      "Epoch 30/30\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 0.2960 - accuracy: 0.9289 - val_loss: 0.4230 - val_accuracy: 0.8413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\bone_20240719\\lib\\site-packages\\keras\\utils\\generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n",
      "d:\\anaconda3\\envs\\bone_20240719\\lib\\site-packages\\pandas\\core\\indexing.py:1781: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item_labels[indexer[info_axis]]] = value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "side\n",
      "Found 253 validated image filenames belonging to 3 classes.\n",
      "Found 63 validated image filenames belonging to 3 classes.\n",
      "Found 80 validated image filenames belonging to 3 classes.\n",
      "-------Training side_voting-------\n",
      "Epoch 1/30\n",
      "4/4 [==============================] - 3s 503ms/step - loss: 1.1862 - accuracy: 0.3320 - val_loss: 1.0711 - val_accuracy: 0.3968\n",
      "Epoch 2/30\n",
      "4/4 [==============================] - 1s 309ms/step - loss: 1.0689 - accuracy: 0.4862 - val_loss: 1.0576 - val_accuracy: 0.4921\n",
      "Epoch 3/30\n",
      "4/4 [==============================] - 1s 283ms/step - loss: 1.0139 - accuracy: 0.5534 - val_loss: 0.9874 - val_accuracy: 0.5714\n",
      "Epoch 4/30\n",
      "4/4 [==============================] - 1s 306ms/step - loss: 0.9427 - accuracy: 0.5850 - val_loss: 0.9458 - val_accuracy: 0.6508\n",
      "Epoch 5/30\n",
      "4/4 [==============================] - 1s 306ms/step - loss: 0.8998 - accuracy: 0.6047 - val_loss: 0.9132 - val_accuracy: 0.6190\n",
      "Epoch 6/30\n",
      "4/4 [==============================] - 1s 298ms/step - loss: 0.8441 - accuracy: 0.6245 - val_loss: 0.8686 - val_accuracy: 0.6984\n",
      "Epoch 7/30\n",
      "4/4 [==============================] - 1s 298ms/step - loss: 0.7988 - accuracy: 0.7154 - val_loss: 0.8420 - val_accuracy: 0.6508\n",
      "Epoch 8/30\n",
      "4/4 [==============================] - 1s 305ms/step - loss: 0.7604 - accuracy: 0.7273 - val_loss: 0.8056 - val_accuracy: 0.6825\n",
      "Epoch 9/30\n",
      "4/4 [==============================] - 1s 297ms/step - loss: 0.7202 - accuracy: 0.7391 - val_loss: 0.7812 - val_accuracy: 0.6825\n",
      "Epoch 10/30\n",
      "4/4 [==============================] - 1s 305ms/step - loss: 0.6879 - accuracy: 0.7628 - val_loss: 0.7609 - val_accuracy: 0.6984\n",
      "Epoch 11/30\n",
      "4/4 [==============================] - 1s 301ms/step - loss: 0.6584 - accuracy: 0.7826 - val_loss: 0.7470 - val_accuracy: 0.7302\n",
      "Epoch 12/30\n",
      "4/4 [==============================] - 1s 305ms/step - loss: 0.6279 - accuracy: 0.7984 - val_loss: 0.7281 - val_accuracy: 0.7143\n",
      "Epoch 13/30\n",
      "4/4 [==============================] - 1s 299ms/step - loss: 0.5991 - accuracy: 0.7866 - val_loss: 0.7115 - val_accuracy: 0.6825\n",
      "Epoch 14/30\n",
      "4/4 [==============================] - 1s 303ms/step - loss: 0.5767 - accuracy: 0.7945 - val_loss: 0.6981 - val_accuracy: 0.6984\n",
      "Epoch 15/30\n",
      "4/4 [==============================] - 1s 300ms/step - loss: 0.5531 - accuracy: 0.8261 - val_loss: 0.6908 - val_accuracy: 0.7143\n",
      "Epoch 16/30\n",
      "4/4 [==============================] - 1s 308ms/step - loss: 0.5403 - accuracy: 0.8379 - val_loss: 0.6858 - val_accuracy: 0.7143\n",
      "Epoch 17/30\n",
      "4/4 [==============================] - 1s 293ms/step - loss: 0.5105 - accuracy: 0.8142 - val_loss: 0.6789 - val_accuracy: 0.7302\n",
      "Epoch 18/30\n",
      "4/4 [==============================] - 1s 299ms/step - loss: 0.5036 - accuracy: 0.8182 - val_loss: 0.6681 - val_accuracy: 0.7143\n",
      "Epoch 19/30\n",
      "4/4 [==============================] - 1s 299ms/step - loss: 0.4819 - accuracy: 0.8419 - val_loss: 0.6679 - val_accuracy: 0.7302\n",
      "Epoch 20/30\n",
      "4/4 [==============================] - 1s 373ms/step - loss: 0.4663 - accuracy: 0.8419 - val_loss: 0.6554 - val_accuracy: 0.7143\n",
      "Epoch 21/30\n",
      "4/4 [==============================] - 1s 351ms/step - loss: 0.4492 - accuracy: 0.8656 - val_loss: 0.6485 - val_accuracy: 0.7302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\bone_20240719\\lib\\site-packages\\keras\\utils\\generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## train front and side\n",
    "save_path_arr = [\"front\", \"side\"]\n",
    "for save_path in save_path_arr:\n",
    "    \n",
    "    # load model\n",
    "    # =========================\n",
    "    pretrained_model = tf.keras.applications.resnet50.ResNet50(\n",
    "        input_shape=(224, 224, 3),\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        pooling='avg')\n",
    "\n",
    "    pretrained_model.trainable = False\n",
    "\n",
    "    inputs = pretrained_model.input\n",
    "    x = tf.keras.layers.Dense(128, activation='relu', name='dense_128')(pretrained_model.output)\n",
    "    x = tf.keras.layers.Dense(50, activation='relu', name='dense_50')(x)\n",
    "\n",
    "    outputs = tf.keras.layers.Dense(class_count, activation='softmax', name='output_layer')(x)\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    # print(model.summary())\n",
    "    # =========================\n",
    "\n",
    "    ## 分資料\n",
    "    # =========================\n",
    "    if save_path == \"side\":\n",
    "        train_df.loc[:, \"Filepath\"] = train_df[\"Filepath\"].str.replace(\"front\", \"side\")\n",
    "        test_df.loc[:, \"Filepath\"] = test_df[\"Filepath\"].str.replace(\"front\", \"side\")\n",
    "    # 確認\n",
    "    print(train_df.iloc[0]['Filepath'].split(\"\\\\\")[-3])\n",
    "    \n",
    "    train_images = train_generator.flow_from_dataframe(\n",
    "        dataframe=train_df,\n",
    "        x_col='Filepath',\n",
    "        y_col='Label',\n",
    "        target_size=(224, 224),\n",
    "        color_mode='rgb',\n",
    "        class_mode='categorical',\n",
    "        batch_size=64,\n",
    "        shuffle=False,\n",
    "        seed=42,\n",
    "        subset='training'\n",
    "    )\n",
    "\n",
    "    val_images = train_generator.flow_from_dataframe(\n",
    "        dataframe=train_df,\n",
    "        x_col='Filepath',\n",
    "        y_col='Label',\n",
    "        target_size=(224, 224),\n",
    "        color_mode='rgb',\n",
    "        class_mode='categorical',\n",
    "        batch_size=64,\n",
    "        shuffle=False,\n",
    "        seed=42,\n",
    "        subset='validation'\n",
    "    )\n",
    "\n",
    "    test_images = test_generator.flow_from_dataframe(\n",
    "        dataframe=test_df,\n",
    "        x_col='Filepath',\n",
    "        y_col='Label',\n",
    "        target_size=(224, 224),\n",
    "        color_mode='rgb',\n",
    "        class_mode='categorical',\n",
    "        batch_size=32,\n",
    "        shuffle=False\n",
    "    )\n",
    "    # =========================\n",
    "\n",
    "    \n",
    "    ## compile and evaluate\n",
    "    # =========================\n",
    "\n",
    "    print(\"-------Training \" + save_path + \"_\" + concat_type + \"-------\")\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    ## early stop \n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)\n",
    "    history=model.fit(train_images, validation_data=val_images, callbacks=[early_stopping], epochs=30)\n",
    "    ## no early stop\n",
    "    # history = model.fit(train_images, validation_data=val_images, epochs=30)\n",
    "\n",
    "    results = model.evaluate(test_images, verbose=0)\n",
    "    # =========================\n",
    "\n",
    "\n",
    "    ## save model to this path\n",
    "    # =========================\n",
    "    model.save(\"./weights/\"+concat_type+\"_\"+save_path + \"_frac.h5\")\n",
    "    # =========================\n",
    "\n",
    "\n",
    "    ## print results\n",
    "    # =========================\n",
    "    # print(save_path + \"_\" + concat_type + \"_Results:\")\n",
    "    pred = model.predict(test_images)\n",
    "\n",
    "    ## 把pred分開存\n",
    "    if save_path == \"front\":\n",
    "        front_pred = pred\n",
    "    else:\n",
    "        side_pred = pred\n",
    "    predicted_labels = np.argmax(pred, axis=1)\n",
    "    # f1 = f1_score(test_images.labels, predicted_labels, average='macro')\n",
    "    # precision = precision_score(test_images.labels, predicted_labels, average='macro')\n",
    "    # recall = recall_score(test_images.labels, predicted_labels, average='macro')\n",
    "\n",
    "    # print(results)\n",
    "    # print(f\"Test Accuracy: {np.round(results[1], 2)}\")\n",
    "    # print(f\"f1 score: {np.round(f1, 2)}\")\n",
    "    # print(f\"precision: {np.round(precision, 2)}\")\n",
    "    # print(f\"recall: {np.round(recall, 2)}\")\n",
    "    # =========================\n",
    "\n",
    "\n",
    "    # create plots for accuracy and save it\n",
    "    # =========================\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    figAcc = plt.gcf()\n",
    "    my_file = os.path.join(\"./plots/\"+concat_type+\"_\"+save_path+\"_Accuracy.jpeg\")\n",
    "    figAcc.savefig(my_file)\n",
    "    plt.clf()\n",
    "    # =========================\n",
    "\n",
    "\n",
    "    ## create plots for loss and save it\n",
    "    # =========================\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    figAcc = plt.gcf()\n",
    "    my_file = os.path.join(\"./plots/\"+concat_type+\"_\"+save_path+\"_Loss.jpeg\")\n",
    "    figAcc.savefig(my_file)\n",
    "    plt.clf()\n",
    "    # =========================\n",
    "\n",
    "\n",
    "    ## plot confusion matrix\n",
    "    # =========================\n",
    "    if class_count == 2:\n",
    "        display_labels = [0, 1]\n",
    "    elif class_count == 3:\n",
    "        display_labels = [0, 1, 2]\n",
    "    elif class_count == 4:\n",
    "        display_labels = [0, 1, 2, 3]\n",
    "\n",
    "\n",
    "    cm = confusion_matrix(test_images.labels, predicted_labels)\n",
    "    cm_display = ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = display_labels)\n",
    "    cm_display.plot()\n",
    "    plt.title('Confusion Matrix')\n",
    "    figAcc = plt.gcf()\n",
    "    my_file = os.path.join(\"./plots/\"+concat_type+\"_\"+save_path+\"_Confusion Matrix.jpeg\")\n",
    "    figAcc.savefig(my_file)\n",
    "    plt.clf()\n",
    "    # ========================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- front -------\n",
      "Test Accuracy: 0.79\n",
      "f1 score: 0.76\n",
      "precision: 0.76\n",
      "recall: 0.76\n",
      "------- side -------\n",
      "Test Accuracy: 0.66\n",
      "f1 score: 0.61\n",
      "precision: 0.61\n",
      "recall: 0.62\n",
      "------- soft -------\n",
      "Test Accuracy: 0.76\n",
      "f1 score: 0.73\n",
      "precision: 0.73\n",
      "recall: 0.74\n",
      "------- hard -------\n",
      "Test Accuracy: 0.65\n",
      "f1 score: 0.6\n",
      "precision: 0.62\n",
      "recall: 0.61\n",
      "------- product -------\n",
      "Test Accuracy: 0.76\n",
      "f1 score: 0.73\n",
      "precision: 0.73\n",
      "recall: 0.74\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import mode\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "vote_type_arr = [\"front\", \"side\", \"soft\", \"hard\", \"product\"]\n",
    "for vote_type in vote_type_arr:\n",
    "    print(\"------- \"+vote_type+\" -------\")\n",
    "    if vote_type == \"front\":\n",
    "        predicted_labels = np.argmax(front_pred, axis=1)\n",
    "    if vote_type == \"side\":\n",
    "        predicted_labels = np.argmax(side_pred, axis=1)\n",
    "    if vote_type == \"soft\":\n",
    "        soft_pred = np.argmax((front_pred + side_pred) / 2 , axis=1)\n",
    "        predicted_labels = soft_pred\n",
    "    if vote_type == \"hard\":\n",
    "        hard_front_pred = np.argmax(front_pred, axis=1)  \n",
    "        hard_side_pred = np.argmax(side_pred, axis=1)  \n",
    "        hard_pred = mode([hard_front_pred, hard_side_pred], axis=0).mode[0]  \n",
    "        predicted_labels = hard_pred\n",
    "    if vote_type == \"product\":\n",
    "        product_pred = [[a * b for a, b in zip(sublist1, sublist2)] for sublist1, sublist2 in zip(front_pred, side_pred)]\n",
    "        product_pred = np.argmax(product_pred, axis=1) \n",
    "        predicted_labels = product_pred\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    acc = accuracy_score(test_images.labels, predicted_labels)\n",
    "    f1 = f1_score(test_images.labels, predicted_labels, average='macro')\n",
    "    precision = precision_score(test_images.labels, predicted_labels, average='macro')\n",
    "    recall = recall_score(test_images.labels, predicted_labels, average='macro')\n",
    "\n",
    "    print(f\"Test Accuracy: {np.round(acc, 2)}\")\n",
    "    print(f\"f1 score: {np.round(f1, 2)}\")\n",
    "    print(f\"precision: {np.round(precision, 2)}\")\n",
    "    print(f\"recall: {np.round(recall, 2)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11 15 17 20 29 32 37 40 43 44 53 65 66 67 68 71 78]\n",
      "[ 4  6 10 11 19 20 22 25 26 29 32 34 35 40 41 43 50 53 57 60 61 63 65 66\n",
      " 68 69 76]\n",
      "[11 15 17 19 20 29 32 35 40 41 43 44 53 65 66 67 68 71 78]\n",
      "[ 4  6 10 11 15 17 19 20 22 25 26 29 32 34 35 37 40 43 44 50 53 57 63 65\n",
      " 66 67 68 76]\n",
      "[11 15 17 19 20 29 32 35 40 41 43 44 53 65 66 67 68 71 78]\n"
     ]
    }
   ],
   "source": [
    "# 錯的\n",
    "print(np.where(test_images.labels != hard_front_pred)[0])\n",
    "print(np.where(test_images.labels != hard_side_pred)[0])\n",
    "print(np.where(test_images.labels != soft_pred)[0])\n",
    "print(np.where(test_images.labels != hard_pred)[0])\n",
    "print(np.where(test_images.labels != product_pred)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df[\"pred\"] = predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## grad_cam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "def make_gradcam_heatmap(img_array, model, last_conv_layer_name=\"conv5_block3_out\", pred_index=None):\n",
    "    # 建立一個模型，同時輸出最後一個卷積層和整個模型的預測結果\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        model.inputs, [model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "    \n",
    "    # 計算對於輸入圖像的預測類別，相對於最後一個卷積層的梯度\n",
    "    with tf.GradientTape() as tape:\n",
    "        last_conv_layer_output, preds = grad_model(img_array)\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(preds[0])\n",
    "        class_channel = preds[:, pred_index]\n",
    "\n",
    "    # 輸出分類神經元相對於最後一個卷積層的輸出特徵圖的梯度\n",
    "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
    "\n",
    "    # 這是一個向量，其中每個數字都是特定特徵圖通道上的梯度的平均強度\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "    # 將特徵圖乘以權重，等於該特徵圖中的某些區域對於該分類的重要性\n",
    "    last_conv_layer_output = last_conv_layer_output[0]\n",
    "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap) # 然後將所有通道相加以獲得熱圖\n",
    "\n",
    "    # 為了視覺化，將熱圖正規化0~1之間\n",
    "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
    "    return heatmap.numpy()\n",
    "\n",
    "def save_and_display_gradcam(img_path, heatmap, alpha=0.4):\n",
    "    # 載入原始圖像\n",
    "    img = tf.keras.utils.load_img(img_path)\n",
    "    img = tf.keras.utils.img_to_array(img)\n",
    "\n",
    "    # 將熱圖重新縮放到0-255的範圍\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "\n",
    "    # 使用Jet色彩映射將熱圖上色\n",
    "    jet = cm.get_cmap(\"Purples\")\n",
    "\n",
    "    # 使用Jet色彩映射的RGB值\n",
    "    jet_colors = jet(np.arange(256))[:, :3]\n",
    "    jet_heatmap = jet_colors[heatmap]\n",
    "\n",
    "    # 創建帶有RGB色彩的熱圖圖像\n",
    "    jet_heatmap = tf.keras.utils.array_to_img(jet_heatmap)\n",
    "    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n",
    "    jet_heatmap = tf.keras.utils.img_to_array(jet_heatmap)\n",
    "\n",
    "    # 在原始圖像上疊加熱圖\n",
    "    superimposed_img = jet_heatmap * alpha + img\n",
    "    superimposed_img = tf.keras.utils.array_to_img(superimposed_img)\n",
    "    plt.imshow(superimposed_img)\n",
    "    plt.axis('off')  # 不顯示坐標軸\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.image as mpimg\n",
    "# chosen_model = \"frac.h5\"\n",
    "\n",
    "# filtered_df = test_df[(test_df['Label'] == \"1\") & (test_df['pred'] == 2)]\n",
    "\n",
    "# img = filtered_df[\"Filepath\"].values\n",
    "# for im in img:\n",
    "#     temp_img = image.load_img(im, target_size=(224, 224))\n",
    "#     x = image.img_to_array(temp_img)\n",
    "#     x = np.expand_dims(x, axis=0)\n",
    "#     images = np.vstack([x])\n",
    "#     heatmap = make_gradcam_heatmap(images, tf.keras.models.load_model(chosen_model))\n",
    "#     print(f\"image path={im}\")\n",
    "#     save_and_display_gradcam(im, heatmap)\n",
    "#     print(\"##################################################################################\")\n",
    "# ############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 單一查看\n",
    "# import matplotlib.image as mpimg\n",
    "# chosen_model = \".//weights//中榮//front//transfer_imagenet//all//imagenet_AP+Mortise_swift_cut_2class.h5\"\n",
    "\n",
    "# im = \"E://data_bone//1-swift_cut//front//三踝//001744332C_R.jpg\"\n",
    "\n",
    "# temp_img = image.load_img(im, target_size=(224, 224))\n",
    "# x = image.img_to_array(temp_img)\n",
    "# x = np.expand_dims(x, axis=0)\n",
    "# images = np.vstack([x])\n",
    "# heatmap = make_gradcam_heatmap(images, tf.keras.models.load_model(chosen_model))\n",
    "# print(f\"image path={im}\")\n",
    "# save_and_display_gradcam(im, heatmap)\n",
    "# print(\"##################################################################################\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bone_20240719",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
