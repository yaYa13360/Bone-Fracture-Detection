{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, f1_score, precision_score, recall_score\n",
    "import os\n",
    "import math\n",
    "# label\n",
    "# =========================\n",
    "def class_2_type(root):\n",
    "    label = \"\"\n",
    "    if \"正常\" in root:\n",
    "        label = \"0\"\n",
    "    else:\n",
    "        label = \"1\"\n",
    "    return label\n",
    "\n",
    "def class_3_type(root):\n",
    "    label = \"\"\n",
    "    if \"正常\" in root:\n",
    "        label = \"0\"\n",
    "    elif \"雙踝\" in root:\n",
    "        label = \"1\"\n",
    "    elif \"三踝\" in root:\n",
    "        label = \"2\"\n",
    "    return label\n",
    "# =========================\n",
    "\n",
    "def load_path(path, class_count):\n",
    "    dataset = []\n",
    "    class_type = ''\n",
    "    if class_count == 2:\n",
    "        class_type = class_2_type\n",
    "    elif class_count == 3:\n",
    "        class_type = class_3_type   \n",
    "\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            label = class_type(root)\n",
    "            if label != \"\":\n",
    "                dataset.append(\n",
    "                                {   \n",
    "                                    'uuid': root.split(\"\\\\\")[-1],\n",
    "                                    'label': label,\n",
    "                                    'image_path': os.path.join(root, file)\n",
    "                                }\n",
    "                            )\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 參數設置\n",
    "image_dir = \"E:\\\\data_bone\\\\9-a+b_swift_cut_正確_V2\\\\front\"\n",
    "concat_type = \"concat2\"\n",
    "class_count = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load data and  labels\n",
    "# =========================\n",
    "data = load_path(image_dir, class_count)\n",
    "labels = []\n",
    "filepaths = []\n",
    "for row in data:\n",
    "    labels.append(row['label'])\n",
    "    filepaths.append(row['image_path'])\n",
    "\n",
    "filepaths = pd.Series(filepaths, name='Filepath').astype(str)\n",
    "labels = pd.Series(labels, name='Label')\n",
    "\n",
    "images = pd.concat([filepaths, labels], axis=1)\n",
    "# =========================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set label distribution:\n",
      " 0    128\n",
      "2     95\n",
      "1     93\n",
      "Name: Label, dtype: int64\n",
      "Test set label distribution:\n",
      " 0    32\n",
      "2    24\n",
      "1    24\n",
      "Name: Label, dtype: int64\n",
      "Found 253 validated image filenames belonging to 3 classes.\n",
      "Found 63 validated image filenames belonging to 3 classes.\n",
      "Found 80 validated image filenames belonging to 3 classes.\n",
      "Found 253 validated image filenames belonging to 3 classes.\n",
      "Found 63 validated image filenames belonging to 3 classes.\n",
      "Found 80 validated image filenames belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "## split image\n",
    "# =========================\n",
    "train_df_front, test_df_front = train_test_split(images, train_size=0.8, shuffle=True, random_state=1, stratify=images['Label'])\n",
    "print(\"Training set label distribution:\\n\", train_df_front['Label'].value_counts(normalize=False))\n",
    "print(\"Test set label distribution:\\n\", test_df_front['Label'].value_counts(normalize=False))\n",
    "# =========================\n",
    "\n",
    "preprocessing_function_chosen_front = tf.keras.applications.resnet50.preprocess_input\n",
    "# preprocessing_function_chosen_side = tf.keras.applications.efficientnet.preprocess_input\n",
    "preprocessing_function_chosen_side = tf.keras.applications.resnet50.preprocess_input\n",
    "\n",
    "# front images\n",
    "# =========================\n",
    "train_generator_front = tf.keras.preprocessing.image.ImageDataGenerator(horizontal_flip=False,\n",
    "                                                                    preprocessing_function=preprocessing_function_chosen_front,\n",
    "                                                                    validation_split=0.2)\n",
    "test_generator_front = tf.keras.preprocessing.image.ImageDataGenerator(preprocessing_function=preprocessing_function_chosen_front)\n",
    "\n",
    "train_images_front = train_generator_front.flow_from_dataframe(\n",
    "    dataframe=train_df_front,\n",
    "    x_col='Filepath',\n",
    "    y_col='Label',\n",
    "    target_size=(224, 224),\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=64,\n",
    "    shuffle=False,\n",
    "    seed=42,\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "val_images_front = train_generator_front.flow_from_dataframe(\n",
    "    dataframe=train_df_front,\n",
    "    x_col='Filepath',\n",
    "    y_col='Label',\n",
    "    target_size=(224, 224),\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=64,\n",
    "    shuffle=False,\n",
    "    seed=42,\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "test_images_front = test_generator_front.flow_from_dataframe(\n",
    "    dataframe=test_df_front,\n",
    "    x_col='Filepath',\n",
    "    y_col='Label',\n",
    "    target_size=(224, 224),\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")\n",
    "# =========================\n",
    "\n",
    "\n",
    "# side images\n",
    "# =========================\n",
    "train_df_side = train_df_front.copy()\n",
    "test_df_side = test_df_front.copy()\n",
    "train_df_side.loc[:, \"Filepath\"] = train_df_front[\"Filepath\"].str.replace(\"front\", \"side\")\n",
    "test_df_side.loc[:, \"Filepath\"] = test_df_side[\"Filepath\"].str.replace(\"front\", \"side\")\n",
    "\n",
    "train_generator_side = tf.keras.preprocessing.image.ImageDataGenerator(horizontal_flip=False,\n",
    "                                                                    preprocessing_function=preprocessing_function_chosen_side,\n",
    "                                                                    validation_split=0.2)\n",
    "test_generator_side = tf.keras.preprocessing.image.ImageDataGenerator(preprocessing_function=preprocessing_function_chosen_side)\n",
    "\n",
    "train_images_side = train_generator_side.flow_from_dataframe(\n",
    "    dataframe=train_df_side,\n",
    "    x_col='Filepath',\n",
    "    y_col='Label',\n",
    "    target_size=(224, 224),\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=64,\n",
    "    shuffle=False,\n",
    "    seed=42,\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "val_images_side = train_generator_side.flow_from_dataframe(\n",
    "    dataframe=train_df_side,\n",
    "    x_col='Filepath',\n",
    "    y_col='Label',\n",
    "    target_size=(224, 224),\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=64,\n",
    "    shuffle=False,\n",
    "    seed=42,\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "test_images_side = test_generator_side.flow_from_dataframe(\n",
    "    dataframe=test_df_side,\n",
    "    x_col='Filepath',\n",
    "    y_col='Label',\n",
    "    target_size=(224, 224),\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")\n",
    "# =========================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df_side\n",
    "# test_df_front\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "AP(Mortise) (InputLayer)        [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Lateral (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "AP_pretrain_resnet_model (Funct (None, 2048)         23587712    AP(Mortise)[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Lateral_pretrain_efficientnet_m (None, 1280)         4049571     Lateral[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "AP_dense_50 (Dense)             (None, 50)           102450      AP_pretrain_resnet_model[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "Lateral_dense_50 (Dense)        (None, 50)           64050       Lateral_pretrain_efficientnet_mod\n",
      "__________________________________________________________________________________________________\n",
      "AP_dense_128 (Dense)            (None, 128)          6528        AP_dense_50[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Lateral_dense_128 (Dense)       (None, 128)          6528        Lateral_dense_50[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "feature_fusion (Concatenate)    (None, 256)          0           AP_dense_128[0][0]               \n",
      "                                                                 Lateral_dense_128[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 256)          0           feature_fusion[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "output_layer (Dense)            (None, 3)            771         dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 27,817,610\n",
      "Trainable params: 180,327\n",
      "Non-trainable params: 27,637,283\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Concatenate, Dropout, Add\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "\n",
    "\n",
    "\n",
    "def create_front_extract():\n",
    "    pretrained_model_chosen = tf.keras.applications.resnet50.ResNet50\n",
    "    pretrained_model = pretrained_model_chosen(\n",
    "        input_shape=(224, 224, 3),\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        pooling='avg')\n",
    "    pretrained_model._name = 'AP_pretrain_resnet_model'\n",
    "    pretrained_model.trainable = False\n",
    "    return pretrained_model\n",
    "\n",
    "def create_side_extract():\n",
    "    pretrained_model_chosen = tf.keras.applications.efficientnet.EfficientNetB0\n",
    "    pretrained_model = pretrained_model_chosen(\n",
    "        input_shape=(224, 224, 3),\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        pooling='avg')\n",
    "    pretrained_model._name = 'Lateral_pretrain_efficientnet_model'\n",
    "    pretrained_model.trainable = False\n",
    "    return pretrained_model\n",
    "\n",
    "# input \n",
    "input_front = Input(shape=(224, 224, 3), name=\"AP(Mortise)\")\n",
    "input_side = Input(shape=(224, 224, 3), name=\"Lateral\")\n",
    "\n",
    "# model\n",
    "model_front = create_front_extract()\n",
    "model_side = create_side_extract()\n",
    "\n",
    "features_front = model_front(input_front)\n",
    "features_side = model_side(input_side)\n",
    "\n",
    "features_front_x = tf.keras.layers.Dense(50, activation='relu', name='AP_dense_50')(features_front)\n",
    "features_front_x = tf.keras.layers.Dense(128, activation='relu', name='AP_dense_128')(features_front_x)\n",
    "\n",
    "features_side_x = tf.keras.layers.Dense(50, activation='relu', name='Lateral_dense_50')(features_side)\n",
    "features_side_x = tf.keras.layers.Dense(128, activation='relu', name='Lateral_dense_128')(features_side_x)\n",
    "\n",
    "fused_features = Concatenate(name=\"feature_fusion\")([features_front_x, features_side_x])\n",
    "# fused_features = tf.keras.layers.Dense(50, activation='relu', name='fusion_dense_50')(fused_features)\n",
    "fused_features = Dropout(0.1)(fused_features)\n",
    "\n",
    "final_output = Dense(class_count, activation='sigmoid', name='output_layer')(fused_features)\n",
    "multi_view_model = None\n",
    "multi_view_model = Model(\n",
    "    inputs=[input_front, input_side],\n",
    "    outputs=final_output\n",
    ")\n",
    "multi_view_model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "multi_view_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_input_generator(front_gen, side_gen):\n",
    "    while True:\n",
    "        front_batch, y1 = next(front_gen)\n",
    "        side_batch, y2 = next(side_gen)\n",
    "        assert (y1 == y2).all(), \"Label mismatch!\"  # 確保標籤一致\n",
    "        yield ([front_batch, side_batch], y1)\n",
    "\n",
    "train_generator = multi_input_generator(train_images_front, train_images_side)\n",
    "val_generator = multi_input_generator(val_images_front, val_images_side)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------Training _concat2-------\n",
      "Epoch 1/30\n",
      "4/4 [==============================] - 9s 1s/step - loss: 1.1708 - accuracy: 0.2609 - val_loss: 1.1078 - val_accuracy: 0.3810\n",
      "Epoch 2/30\n",
      "4/4 [==============================] - 2s 658ms/step - loss: 1.0978 - accuracy: 0.4032 - val_loss: 1.0445 - val_accuracy: 0.4762\n",
      "Epoch 3/30\n",
      "4/4 [==============================] - 2s 615ms/step - loss: 1.0122 - accuracy: 0.5099 - val_loss: 0.9879 - val_accuracy: 0.5397\n",
      "Epoch 4/30\n",
      "4/4 [==============================] - 2s 617ms/step - loss: 0.9800 - accuracy: 0.5296 - val_loss: 0.9370 - val_accuracy: 0.6032\n",
      "Epoch 5/30\n",
      "4/4 [==============================] - 2s 604ms/step - loss: 0.9072 - accuracy: 0.6087 - val_loss: 0.8936 - val_accuracy: 0.6190\n",
      "Epoch 6/30\n",
      "4/4 [==============================] - 2s 599ms/step - loss: 0.8716 - accuracy: 0.6522 - val_loss: 0.8549 - val_accuracy: 0.6508\n",
      "Epoch 7/30\n",
      "4/4 [==============================] - 2s 601ms/step - loss: 0.8224 - accuracy: 0.7036 - val_loss: 0.8221 - val_accuracy: 0.6349\n",
      "Epoch 8/30\n",
      "4/4 [==============================] - 2s 607ms/step - loss: 0.7935 - accuracy: 0.7115 - val_loss: 0.7887 - val_accuracy: 0.6667\n",
      "Epoch 9/30\n",
      "4/4 [==============================] - 2s 609ms/step - loss: 0.7649 - accuracy: 0.7352 - val_loss: 0.7590 - val_accuracy: 0.6667\n",
      "Epoch 10/30\n",
      "4/4 [==============================] - 2s 598ms/step - loss: 0.7286 - accuracy: 0.7628 - val_loss: 0.7312 - val_accuracy: 0.7143\n",
      "Epoch 11/30\n",
      "4/4 [==============================] - 2s 603ms/step - loss: 0.7013 - accuracy: 0.7549 - val_loss: 0.7056 - val_accuracy: 0.7302\n",
      "Epoch 12/30\n",
      "4/4 [==============================] - 2s 602ms/step - loss: 0.6779 - accuracy: 0.7352 - val_loss: 0.6818 - val_accuracy: 0.7143\n",
      "Epoch 13/30\n",
      "4/4 [==============================] - 2s 597ms/step - loss: 0.6458 - accuracy: 0.7708 - val_loss: 0.6606 - val_accuracy: 0.7619\n",
      "Epoch 14/30\n",
      "4/4 [==============================] - 2s 604ms/step - loss: 0.6291 - accuracy: 0.7747 - val_loss: 0.6429 - val_accuracy: 0.7778\n",
      "Epoch 15/30\n",
      "4/4 [==============================] - 2s 600ms/step - loss: 0.6084 - accuracy: 0.7747 - val_loss: 0.6267 - val_accuracy: 0.7778\n",
      "Epoch 16/30\n",
      "4/4 [==============================] - 2s 593ms/step - loss: 0.5783 - accuracy: 0.7628 - val_loss: 0.6116 - val_accuracy: 0.7778\n",
      "Epoch 17/30\n",
      "4/4 [==============================] - 2s 593ms/step - loss: 0.5627 - accuracy: 0.7708 - val_loss: 0.5980 - val_accuracy: 0.7778\n",
      "Epoch 18/30\n",
      "4/4 [==============================] - 2s 602ms/step - loss: 0.5455 - accuracy: 0.7945 - val_loss: 0.5860 - val_accuracy: 0.7778\n",
      "Epoch 19/30\n",
      "4/4 [==============================] - 2s 601ms/step - loss: 0.5230 - accuracy: 0.7984 - val_loss: 0.5752 - val_accuracy: 0.7778\n",
      "Epoch 20/30\n",
      "4/4 [==============================] - 2s 607ms/step - loss: 0.5072 - accuracy: 0.7905 - val_loss: 0.5659 - val_accuracy: 0.8095\n",
      "Epoch 21/30\n",
      "4/4 [==============================] - 2s 607ms/step - loss: 0.5069 - accuracy: 0.8300 - val_loss: 0.5576 - val_accuracy: 0.7937\n",
      "Epoch 22/30\n",
      "4/4 [==============================] - 2s 597ms/step - loss: 0.4721 - accuracy: 0.8340 - val_loss: 0.5500 - val_accuracy: 0.8095\n",
      "Epoch 23/30\n",
      "4/4 [==============================] - 2s 604ms/step - loss: 0.4485 - accuracy: 0.8735 - val_loss: 0.5444 - val_accuracy: 0.8254\n",
      "Epoch 24/30\n",
      "4/4 [==============================] - 2s 605ms/step - loss: 0.4527 - accuracy: 0.8300 - val_loss: 0.5376 - val_accuracy: 0.8254\n",
      "Epoch 25/30\n",
      "4/4 [==============================] - 2s 601ms/step - loss: 0.4431 - accuracy: 0.8419 - val_loss: 0.5307 - val_accuracy: 0.8254\n",
      "Epoch 26/30\n",
      "4/4 [==============================] - 2s 605ms/step - loss: 0.4532 - accuracy: 0.8103 - val_loss: 0.5297 - val_accuracy: 0.8095\n",
      "Epoch 27/30\n",
      "4/4 [==============================] - 2s 605ms/step - loss: 0.4101 - accuracy: 0.8735 - val_loss: 0.5204 - val_accuracy: 0.8254\n",
      "Epoch 28/30\n",
      "4/4 [==============================] - 2s 601ms/step - loss: 0.4142 - accuracy: 0.8498 - val_loss: 0.5176 - val_accuracy: 0.8413\n",
      "Epoch 29/30\n",
      "4/4 [==============================] - 2s 603ms/step - loss: 0.3938 - accuracy: 0.8735 - val_loss: 0.5125 - val_accuracy: 0.8413\n",
      "Epoch 30/30\n",
      "4/4 [==============================] - 2s 600ms/step - loss: 0.3887 - accuracy: 0.8656 - val_loss: 0.5081 - val_accuracy: 0.8095\n"
     ]
    }
   ],
   "source": [
    "## compile and evaluate\n",
    "# =========================\n",
    "\n",
    "print(\"-------Training \" + \"_\" + concat_type + \"-------\")\n",
    "batch_size = 64\n",
    "## early stop \n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)\n",
    "history=model.fit([train_images_front, train_images_side], validation_data=[val_images_front, val_images_side], callbacks=[early_stopping], epochs=30)\n",
    "## no early stop\n",
    "# history = multi_view_model.fit(train_generator, validation_data=val_generator, epochs=30,\n",
    "#                             steps_per_epoch= math.ceil(train_images_front.samples / batch_size), \n",
    "#                             validation_steps= math.ceil(val_images_front.samples / batch_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\bone_20240719\\lib\\site-packages\\keras\\utils\\generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## save model to this path\n",
    "# =========================\n",
    "multi_view_model.save(\"./weights/\"+concat_type+\"_\" + \"_frac.h5\")\n",
    "# =========================\n",
    "\n",
    "\n",
    "## print results\n",
    "# =========================\n",
    "test_generator = multi_input_generator(test_images_front, test_images_side)\n",
    "\n",
    "batch_size=32\n",
    "pred = multi_view_model.predict(test_generator,  steps=math.ceil(test_images_front.samples / batch_size))\n",
    "predicted_labels = np.argmax(pred, axis=1)\n",
    "# =========================\n",
    "\n",
    "\n",
    "\n",
    "# create plots for accuracy and save it\n",
    "# =========================\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "figAcc = plt.gcf()\n",
    "my_file = os.path.join(\"./plots/\"+concat_type+\"_Accuracy.jpeg\")\n",
    "figAcc.savefig(my_file)\n",
    "plt.clf()\n",
    "# =========================\n",
    "\n",
    "\n",
    "## create plots for loss and save it\n",
    "# =========================\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "figAcc = plt.gcf()\n",
    "my_file = os.path.join(\"./plots/\"+concat_type+\"_\"+\"_Loss.jpeg\")\n",
    "figAcc.savefig(my_file)\n",
    "plt.clf()\n",
    "# =========================\n",
    "\n",
    "\n",
    "## plot confusion matrix\n",
    "# =========================\n",
    "if class_count == 2:\n",
    "    display_labels = [0, 1]\n",
    "elif class_count == 3:\n",
    "    display_labels = [0, 1, 2]\n",
    "elif class_count == 4:\n",
    "    display_labels = [0, 1, 2, 3]\n",
    "\n",
    "\n",
    "cm = confusion_matrix(test_images_front.labels, predicted_labels)\n",
    "cm_display = ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = display_labels)\n",
    "cm_display.plot()\n",
    "plt.title('Confusion Matrix')\n",
    "figAcc = plt.gcf()\n",
    "my_file = os.path.join(\"./plots/\"+concat_type+\"_\"+\"_Confusion Matrix.jpeg\")\n",
    "figAcc.savefig(my_file)\n",
    "plt.clf()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bone_20240719",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
