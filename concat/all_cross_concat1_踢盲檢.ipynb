{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"E:\\\\data_bone\\\\11-a+b_swift_cut_正確_V2_踢盲檢\\\\front\"\n",
    "\n",
    "concat_type = \"concat1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set label distribution:\n",
      " 0    101\n",
      "2     69\n",
      "1     67\n",
      "Name: Label, dtype: int64\n",
      "Test set label distribution:\n",
      " 0    25\n",
      "2    18\n",
      "1    17\n",
      "Name: Label, dtype: int64\n",
      "Found 189 validated image filenames belonging to 3 classes.\n",
      "Found 48 validated image filenames belonging to 3 classes.\n",
      "Found 60 validated image filenames belonging to 3 classes.\n",
      "Found 189 validated image filenames belonging to 3 classes.\n",
      "Found 48 validated image filenames belonging to 3 classes.\n",
      "Found 60 validated image filenames belonging to 3 classes.\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "AP(Mortise) (InputLayer)        [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Lateral (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "resnet50 (Functional)           (None, 2048)         23587712    AP(Mortise)[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "efficientnetb0 (Functional)     (None, 1280)         4049571     Lateral[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "AP_dense_128 (Dense)            (None, 128)          262272      resnet50[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Lateral_dense_128 (Dense)       (None, 128)          163968      efficientnetb0[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "AP_dense_50 (Dense)             (None, 50)           6450        AP_dense_128[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Lateral_dense_50 (Dense)        (None, 50)           6450        Lateral_dense_128[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "feature_fusion (Concatenate)    (None, 100)          0           AP_dense_50[0][0]                \n",
      "                                                                 Lateral_dense_50[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 100)          0           feature_fusion[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "output_layer (Dense)            (None, 3)            303         dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 28,076,726\n",
      "Trainable params: 439,443\n",
      "Non-trainable params: 27,637,283\n",
      "__________________________________________________________________________________________________\n",
      "-------Training_concat1-------\n",
      "Epoch 1/30\n",
      "3/3 [==============================] - 13s 3s/step - loss: 1.1062 - accuracy: 0.4021 - val_loss: 1.0357 - val_accuracy: 0.5000\n",
      "Epoch 2/30\n",
      "3/3 [==============================] - 1s 615ms/step - loss: 0.9587 - accuracy: 0.5450 - val_loss: 0.9457 - val_accuracy: 0.5417\n",
      "Epoch 3/30\n",
      "3/3 [==============================] - 1s 605ms/step - loss: 0.8763 - accuracy: 0.6349 - val_loss: 0.8773 - val_accuracy: 0.5833\n",
      "Epoch 4/30\n",
      "3/3 [==============================] - 1s 605ms/step - loss: 0.8281 - accuracy: 0.6984 - val_loss: 0.8216 - val_accuracy: 0.6458\n",
      "Epoch 5/30\n",
      "3/3 [==============================] - 1s 618ms/step - loss: 0.7679 - accuracy: 0.7090 - val_loss: 0.7755 - val_accuracy: 0.6458\n",
      "Epoch 6/30\n",
      "3/3 [==============================] - 1s 614ms/step - loss: 0.7192 - accuracy: 0.7249 - val_loss: 0.7355 - val_accuracy: 0.6458\n",
      "Epoch 7/30\n",
      "3/3 [==============================] - 1s 600ms/step - loss: 0.6818 - accuracy: 0.7725 - val_loss: 0.7045 - val_accuracy: 0.6875\n",
      "Epoch 8/30\n",
      "3/3 [==============================] - 1s 608ms/step - loss: 0.6294 - accuracy: 0.7725 - val_loss: 0.6766 - val_accuracy: 0.6875\n",
      "Epoch 9/30\n",
      "3/3 [==============================] - 1s 608ms/step - loss: 0.5971 - accuracy: 0.7937 - val_loss: 0.6516 - val_accuracy: 0.6875\n",
      "Epoch 10/30\n",
      "3/3 [==============================] - 1s 610ms/step - loss: 0.5704 - accuracy: 0.8307 - val_loss: 0.6275 - val_accuracy: 0.7083\n",
      "Epoch 11/30\n",
      "3/3 [==============================] - 1s 608ms/step - loss: 0.5543 - accuracy: 0.8148 - val_loss: 0.6052 - val_accuracy: 0.7292\n",
      "Epoch 12/30\n",
      "3/3 [==============================] - 1s 601ms/step - loss: 0.5014 - accuracy: 0.8466 - val_loss: 0.5851 - val_accuracy: 0.7708\n",
      "Epoch 13/30\n",
      "3/3 [==============================] - 1s 612ms/step - loss: 0.4799 - accuracy: 0.8307 - val_loss: 0.5689 - val_accuracy: 0.7083\n",
      "Epoch 14/30\n",
      "3/3 [==============================] - 1s 603ms/step - loss: 0.4752 - accuracy: 0.8413 - val_loss: 0.5558 - val_accuracy: 0.7292\n",
      "Epoch 15/30\n",
      "3/3 [==============================] - 1s 617ms/step - loss: 0.4389 - accuracy: 0.8730 - val_loss: 0.5447 - val_accuracy: 0.7500\n",
      "Epoch 16/30\n",
      "3/3 [==============================] - 1s 615ms/step - loss: 0.4311 - accuracy: 0.8360 - val_loss: 0.5334 - val_accuracy: 0.7708\n",
      "Epoch 17/30\n",
      "3/3 [==============================] - 1s 606ms/step - loss: 0.4278 - accuracy: 0.8307 - val_loss: 0.5222 - val_accuracy: 0.7500\n",
      "Epoch 18/30\n",
      "3/3 [==============================] - 1s 596ms/step - loss: 0.4056 - accuracy: 0.8783 - val_loss: 0.5126 - val_accuracy: 0.7708\n",
      "Epoch 19/30\n",
      "3/3 [==============================] - 1s 597ms/step - loss: 0.3978 - accuracy: 0.8942 - val_loss: 0.5050 - val_accuracy: 0.7708\n",
      "Epoch 20/30\n",
      "3/3 [==============================] - 1s 593ms/step - loss: 0.3873 - accuracy: 0.8730 - val_loss: 0.4969 - val_accuracy: 0.7917\n",
      "Epoch 21/30\n",
      "3/3 [==============================] - 1s 595ms/step - loss: 0.3675 - accuracy: 0.8889 - val_loss: 0.4889 - val_accuracy: 0.7917\n",
      "Epoch 22/30\n",
      "3/3 [==============================] - 1s 607ms/step - loss: 0.3575 - accuracy: 0.8836 - val_loss: 0.4807 - val_accuracy: 0.7917\n",
      "Epoch 23/30\n",
      "3/3 [==============================] - 1s 602ms/step - loss: 0.3489 - accuracy: 0.9048 - val_loss: 0.4741 - val_accuracy: 0.7708\n",
      "Epoch 24/30\n",
      "3/3 [==============================] - 1s 604ms/step - loss: 0.3277 - accuracy: 0.9153 - val_loss: 0.4699 - val_accuracy: 0.7917\n",
      "Epoch 25/30\n",
      "3/3 [==============================] - 1s 603ms/step - loss: 0.3111 - accuracy: 0.9153 - val_loss: 0.4625 - val_accuracy: 0.7917\n",
      "Epoch 26/30\n",
      "3/3 [==============================] - 1s 601ms/step - loss: 0.2978 - accuracy: 0.9524 - val_loss: 0.4563 - val_accuracy: 0.7917\n",
      "Epoch 27/30\n",
      "3/3 [==============================] - 1s 604ms/step - loss: 0.2994 - accuracy: 0.9312 - val_loss: 0.4502 - val_accuracy: 0.7917\n",
      "Epoch 28/30\n",
      "3/3 [==============================] - 1s 591ms/step - loss: 0.3066 - accuracy: 0.9048 - val_loss: 0.4446 - val_accuracy: 0.7917\n",
      "Epoch 29/30\n",
      "3/3 [==============================] - 1s 603ms/step - loss: 0.2667 - accuracy: 0.9312 - val_loss: 0.4392 - val_accuracy: 0.7708\n",
      "Epoch 30/30\n",
      "3/3 [==============================] - 1s 595ms/step - loss: 0.2655 - accuracy: 0.9471 - val_loss: 0.4376 - val_accuracy: 0.7917\n",
      "Found 189 validated image filenames belonging to 3 classes.\n",
      "Found 48 validated image filenames belonging to 3 classes.\n",
      "Found 60 validated image filenames belonging to 3 classes.\n",
      "Found 189 validated image filenames belonging to 3 classes.\n",
      "Found 48 validated image filenames belonging to 3 classes.\n",
      "Found 60 validated image filenames belonging to 3 classes.\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "AP(Mortise) (InputLayer)        [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Lateral (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "resnet50 (Functional)           (None, 2048)         23587712    AP(Mortise)[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "efficientnetb0 (Functional)     (None, 1280)         4049571     Lateral[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "AP_dense_128 (Dense)            (None, 128)          262272      resnet50[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Lateral_dense_128 (Dense)       (None, 128)          163968      efficientnetb0[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "AP_dense_50 (Dense)             (None, 50)           6450        AP_dense_128[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Lateral_dense_50 (Dense)        (None, 50)           6450        Lateral_dense_128[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "feature_fusion (Concatenate)    (None, 100)          0           AP_dense_50[0][0]                \n",
      "                                                                 Lateral_dense_50[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 100)          0           feature_fusion[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "output_layer (Dense)            (None, 3)            303         dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 28,076,726\n",
      "Trainable params: 439,443\n",
      "Non-trainable params: 27,637,283\n",
      "__________________________________________________________________________________________________\n",
      "-------Training_concat1-------\n",
      "Epoch 1/30\n",
      "3/3 [==============================] - 6s 991ms/step - loss: 1.1433 - accuracy: 0.3386 - val_loss: 1.0250 - val_accuracy: 0.4375\n",
      "Epoch 2/30\n",
      "3/3 [==============================] - 1s 631ms/step - loss: 0.9918 - accuracy: 0.5397 - val_loss: 0.9250 - val_accuracy: 0.5208\n",
      "Epoch 3/30\n",
      "3/3 [==============================] - 1s 624ms/step - loss: 0.9296 - accuracy: 0.5767 - val_loss: 0.8337 - val_accuracy: 0.6875\n",
      "Epoch 4/30\n",
      "3/3 [==============================] - 1s 620ms/step - loss: 0.8297 - accuracy: 0.6878 - val_loss: 0.7600 - val_accuracy: 0.7292\n",
      "Epoch 5/30\n",
      "3/3 [==============================] - 1s 611ms/step - loss: 0.7618 - accuracy: 0.7460 - val_loss: 0.7059 - val_accuracy: 0.7917\n",
      "Epoch 6/30\n",
      "3/3 [==============================] - 1s 607ms/step - loss: 0.7115 - accuracy: 0.7143 - val_loss: 0.6716 - val_accuracy: 0.7292\n",
      "Epoch 7/30\n",
      "3/3 [==============================] - 1s 610ms/step - loss: 0.6674 - accuracy: 0.7672 - val_loss: 0.6386 - val_accuracy: 0.7083\n",
      "Epoch 8/30\n",
      "3/3 [==============================] - 1s 601ms/step - loss: 0.6148 - accuracy: 0.7672 - val_loss: 0.6060 - val_accuracy: 0.7708\n",
      "Epoch 9/30\n",
      "3/3 [==============================] - 1s 604ms/step - loss: 0.5878 - accuracy: 0.7566 - val_loss: 0.5782 - val_accuracy: 0.7708\n",
      "Epoch 10/30\n",
      "3/3 [==============================] - 1s 615ms/step - loss: 0.5353 - accuracy: 0.8148 - val_loss: 0.5505 - val_accuracy: 0.8125\n",
      "Epoch 11/30\n",
      "3/3 [==============================] - 1s 611ms/step - loss: 0.5207 - accuracy: 0.8201 - val_loss: 0.5266 - val_accuracy: 0.8542\n",
      "Epoch 12/30\n",
      "3/3 [==============================] - 1s 610ms/step - loss: 0.5130 - accuracy: 0.7989 - val_loss: 0.5085 - val_accuracy: 0.8542\n",
      "Epoch 13/30\n",
      "3/3 [==============================] - 1s 609ms/step - loss: 0.4748 - accuracy: 0.8360 - val_loss: 0.4935 - val_accuracy: 0.8542\n",
      "Epoch 14/30\n",
      "3/3 [==============================] - 1s 607ms/step - loss: 0.4865 - accuracy: 0.7831 - val_loss: 0.4863 - val_accuracy: 0.8542\n",
      "Epoch 15/30\n",
      "3/3 [==============================] - 1s 607ms/step - loss: 0.4371 - accuracy: 0.8519 - val_loss: 0.4806 - val_accuracy: 0.8542\n",
      "Epoch 16/30\n",
      "3/3 [==============================] - 1s 647ms/step - loss: 0.4253 - accuracy: 0.8571 - val_loss: 0.4706 - val_accuracy: 0.8542\n",
      "Epoch 17/30\n",
      "3/3 [==============================] - 1s 615ms/step - loss: 0.3869 - accuracy: 0.8836 - val_loss: 0.4599 - val_accuracy: 0.8750\n",
      "Epoch 18/30\n",
      "3/3 [==============================] - 1s 605ms/step - loss: 0.4264 - accuracy: 0.8571 - val_loss: 0.4543 - val_accuracy: 0.8542\n",
      "Epoch 19/30\n",
      "3/3 [==============================] - 1s 612ms/step - loss: 0.3796 - accuracy: 0.8730 - val_loss: 0.4527 - val_accuracy: 0.8542\n",
      "Epoch 20/30\n",
      "3/3 [==============================] - 1s 615ms/step - loss: 0.3620 - accuracy: 0.8783 - val_loss: 0.4540 - val_accuracy: 0.8750\n",
      "Epoch 21/30\n",
      "3/3 [==============================] - 1s 602ms/step - loss: 0.3301 - accuracy: 0.9206 - val_loss: 0.4484 - val_accuracy: 0.8542\n",
      "Epoch 22/30\n",
      "3/3 [==============================] - 1s 612ms/step - loss: 0.3578 - accuracy: 0.8836 - val_loss: 0.4379 - val_accuracy: 0.8333\n",
      "Epoch 23/30\n",
      "3/3 [==============================] - 1s 610ms/step - loss: 0.3102 - accuracy: 0.9312 - val_loss: 0.4239 - val_accuracy: 0.8542\n",
      "Epoch 24/30\n",
      "3/3 [==============================] - 1s 606ms/step - loss: 0.3255 - accuracy: 0.9312 - val_loss: 0.4222 - val_accuracy: 0.9167\n",
      "Epoch 25/30\n",
      "3/3 [==============================] - 1s 610ms/step - loss: 0.2896 - accuracy: 0.9524 - val_loss: 0.4238 - val_accuracy: 0.8750\n",
      "Epoch 26/30\n",
      "3/3 [==============================] - 1s 604ms/step - loss: 0.2920 - accuracy: 0.9312 - val_loss: 0.4197 - val_accuracy: 0.8750\n",
      "Epoch 27/30\n",
      "3/3 [==============================] - 1s 601ms/step - loss: 0.2934 - accuracy: 0.9206 - val_loss: 0.4113 - val_accuracy: 0.8750\n",
      "Epoch 28/30\n",
      "3/3 [==============================] - 1s 605ms/step - loss: 0.2778 - accuracy: 0.9259 - val_loss: 0.4058 - val_accuracy: 0.8958\n",
      "Epoch 29/30\n",
      "3/3 [==============================] - 1s 603ms/step - loss: 0.2924 - accuracy: 0.9206 - val_loss: 0.4071 - val_accuracy: 0.9167\n",
      "Epoch 30/30\n",
      "3/3 [==============================] - 1s 609ms/step - loss: 0.2774 - accuracy: 0.9259 - val_loss: 0.4081 - val_accuracy: 0.8750\n",
      "Found 190 validated image filenames belonging to 3 classes.\n",
      "Found 47 validated image filenames belonging to 3 classes.\n",
      "Found 60 validated image filenames belonging to 3 classes.\n",
      "Found 190 validated image filenames belonging to 3 classes.\n",
      "Found 47 validated image filenames belonging to 3 classes.\n",
      "Found 60 validated image filenames belonging to 3 classes.\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "AP(Mortise) (InputLayer)        [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Lateral (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "resnet50 (Functional)           (None, 2048)         23587712    AP(Mortise)[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "efficientnetb0 (Functional)     (None, 1280)         4049571     Lateral[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "AP_dense_128 (Dense)            (None, 128)          262272      resnet50[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Lateral_dense_128 (Dense)       (None, 128)          163968      efficientnetb0[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "AP_dense_50 (Dense)             (None, 50)           6450        AP_dense_128[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Lateral_dense_50 (Dense)        (None, 50)           6450        Lateral_dense_128[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "feature_fusion (Concatenate)    (None, 100)          0           AP_dense_50[0][0]                \n",
      "                                                                 Lateral_dense_50[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 100)          0           feature_fusion[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "output_layer (Dense)            (None, 3)            303         dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 28,076,726\n",
      "Trainable params: 439,443\n",
      "Non-trainable params: 27,637,283\n",
      "__________________________________________________________________________________________________\n",
      "-------Training_concat1-------\n",
      "Epoch 1/30\n",
      "3/3 [==============================] - 7s 2s/step - loss: 1.3278 - accuracy: 0.2947 - val_loss: 1.1355 - val_accuracy: 0.3830\n",
      "Epoch 2/30\n",
      "3/3 [==============================] - 1s 625ms/step - loss: 1.0505 - accuracy: 0.4737 - val_loss: 1.0900 - val_accuracy: 0.4468\n",
      "Epoch 3/30\n",
      "3/3 [==============================] - 1s 624ms/step - loss: 1.0022 - accuracy: 0.5474 - val_loss: 1.0520 - val_accuracy: 0.5106\n",
      "Epoch 4/30\n",
      "3/3 [==============================] - 1s 617ms/step - loss: 0.9575 - accuracy: 0.5421 - val_loss: 0.9927 - val_accuracy: 0.4681\n",
      "Epoch 5/30\n",
      "3/3 [==============================] - 1s 621ms/step - loss: 0.8433 - accuracy: 0.6526 - val_loss: 0.9343 - val_accuracy: 0.5319\n",
      "Epoch 6/30\n",
      "3/3 [==============================] - 1s 620ms/step - loss: 0.7930 - accuracy: 0.7421 - val_loss: 0.9072 - val_accuracy: 0.6383\n",
      "Epoch 7/30\n",
      "3/3 [==============================] - 1s 616ms/step - loss: 0.7486 - accuracy: 0.7474 - val_loss: 0.8818 - val_accuracy: 0.6170\n",
      "Epoch 8/30\n",
      "3/3 [==============================] - 1s 626ms/step - loss: 0.7232 - accuracy: 0.7421 - val_loss: 0.8474 - val_accuracy: 0.5957\n",
      "Epoch 9/30\n",
      "3/3 [==============================] - 1s 623ms/step - loss: 0.6638 - accuracy: 0.7842 - val_loss: 0.8166 - val_accuracy: 0.6596\n",
      "Epoch 10/30\n",
      "3/3 [==============================] - 1s 617ms/step - loss: 0.6292 - accuracy: 0.8000 - val_loss: 0.7932 - val_accuracy: 0.6809\n",
      "Epoch 11/30\n",
      "3/3 [==============================] - 1s 619ms/step - loss: 0.6022 - accuracy: 0.7579 - val_loss: 0.7741 - val_accuracy: 0.6383\n",
      "Epoch 12/30\n",
      "3/3 [==============================] - 1s 620ms/step - loss: 0.5445 - accuracy: 0.8316 - val_loss: 0.7598 - val_accuracy: 0.6383\n",
      "Epoch 13/30\n",
      "3/3 [==============================] - 1s 610ms/step - loss: 0.5386 - accuracy: 0.8000 - val_loss: 0.7507 - val_accuracy: 0.6383\n",
      "Epoch 14/30\n",
      "3/3 [==============================] - 1s 623ms/step - loss: 0.4905 - accuracy: 0.8579 - val_loss: 0.7430 - val_accuracy: 0.6170\n",
      "Epoch 15/30\n",
      "3/3 [==============================] - 1s 621ms/step - loss: 0.4932 - accuracy: 0.7947 - val_loss: 0.7325 - val_accuracy: 0.6383\n",
      "Epoch 16/30\n",
      "3/3 [==============================] - 1s 615ms/step - loss: 0.4854 - accuracy: 0.8263 - val_loss: 0.7201 - val_accuracy: 0.6383\n",
      "Epoch 17/30\n",
      "3/3 [==============================] - 1s 626ms/step - loss: 0.4426 - accuracy: 0.8789 - val_loss: 0.7116 - val_accuracy: 0.6383\n",
      "Epoch 18/30\n",
      "3/3 [==============================] - 1s 624ms/step - loss: 0.4350 - accuracy: 0.8632 - val_loss: 0.7046 - val_accuracy: 0.6596\n",
      "Epoch 19/30\n",
      "3/3 [==============================] - 1s 616ms/step - loss: 0.4019 - accuracy: 0.9158 - val_loss: 0.7005 - val_accuracy: 0.6596\n",
      "Epoch 20/30\n",
      "3/3 [==============================] - 1s 623ms/step - loss: 0.3905 - accuracy: 0.8684 - val_loss: 0.6970 - val_accuracy: 0.6596\n",
      "Epoch 21/30\n",
      "3/3 [==============================] - 1s 619ms/step - loss: 0.3999 - accuracy: 0.8737 - val_loss: 0.6916 - val_accuracy: 0.6596\n",
      "Epoch 22/30\n",
      "3/3 [==============================] - 1s 620ms/step - loss: 0.3668 - accuracy: 0.9263 - val_loss: 0.6879 - val_accuracy: 0.6383\n",
      "Epoch 23/30\n",
      "3/3 [==============================] - 1s 626ms/step - loss: 0.3545 - accuracy: 0.8947 - val_loss: 0.6852 - val_accuracy: 0.6596\n",
      "Epoch 24/30\n",
      "3/3 [==============================] - 1s 616ms/step - loss: 0.3383 - accuracy: 0.9105 - val_loss: 0.6822 - val_accuracy: 0.6596\n",
      "Epoch 25/30\n",
      "3/3 [==============================] - 1s 622ms/step - loss: 0.3463 - accuracy: 0.9000 - val_loss: 0.6777 - val_accuracy: 0.6596\n",
      "Epoch 26/30\n",
      "3/3 [==============================] - 1s 623ms/step - loss: 0.3325 - accuracy: 0.8947 - val_loss: 0.6722 - val_accuracy: 0.6596\n",
      "Epoch 27/30\n",
      "3/3 [==============================] - 1s 611ms/step - loss: 0.3238 - accuracy: 0.9211 - val_loss: 0.6723 - val_accuracy: 0.6596\n",
      "Epoch 28/30\n",
      "3/3 [==============================] - 1s 624ms/step - loss: 0.3243 - accuracy: 0.8947 - val_loss: 0.6722 - val_accuracy: 0.6596\n",
      "Epoch 29/30\n",
      "3/3 [==============================] - 1s 622ms/step - loss: 0.3014 - accuracy: 0.9211 - val_loss: 0.6691 - val_accuracy: 0.6596\n",
      "Epoch 30/30\n",
      "3/3 [==============================] - 1s 620ms/step - loss: 0.2800 - accuracy: 0.9368 - val_loss: 0.6687 - val_accuracy: 0.6596\n",
      "Found 190 validated image filenames belonging to 3 classes.\n",
      "Found 47 validated image filenames belonging to 3 classes.\n",
      "Found 60 validated image filenames belonging to 3 classes.\n",
      "Found 190 validated image filenames belonging to 3 classes.\n",
      "Found 47 validated image filenames belonging to 3 classes.\n",
      "Found 60 validated image filenames belonging to 3 classes.\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "AP(Mortise) (InputLayer)        [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Lateral (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "resnet50 (Functional)           (None, 2048)         23587712    AP(Mortise)[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "efficientnetb0 (Functional)     (None, 1280)         4049571     Lateral[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "AP_dense_128 (Dense)            (None, 128)          262272      resnet50[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Lateral_dense_128 (Dense)       (None, 128)          163968      efficientnetb0[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "AP_dense_50 (Dense)             (None, 50)           6450        AP_dense_128[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Lateral_dense_50 (Dense)        (None, 50)           6450        Lateral_dense_128[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "feature_fusion (Concatenate)    (None, 100)          0           AP_dense_50[0][0]                \n",
      "                                                                 Lateral_dense_50[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 100)          0           feature_fusion[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "output_layer (Dense)            (None, 3)            303         dropout_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 28,076,726\n",
      "Trainable params: 439,443\n",
      "Non-trainable params: 27,637,283\n",
      "__________________________________________________________________________________________________\n",
      "-------Training_concat1-------\n",
      "Epoch 1/30\n",
      "3/3 [==============================] - 6s 992ms/step - loss: 1.3147 - accuracy: 0.2789 - val_loss: 1.0648 - val_accuracy: 0.4468\n",
      "Epoch 2/30\n",
      "3/3 [==============================] - 1s 622ms/step - loss: 1.0589 - accuracy: 0.4579 - val_loss: 1.0252 - val_accuracy: 0.4255\n",
      "Epoch 3/30\n",
      "3/3 [==============================] - 1s 621ms/step - loss: 0.9823 - accuracy: 0.4895 - val_loss: 0.9801 - val_accuracy: 0.4894\n",
      "Epoch 4/30\n",
      "3/3 [==============================] - 1s 619ms/step - loss: 0.9353 - accuracy: 0.5421 - val_loss: 0.9037 - val_accuracy: 0.5745\n",
      "Epoch 5/30\n",
      "3/3 [==============================] - 1s 614ms/step - loss: 0.8601 - accuracy: 0.6211 - val_loss: 0.8454 - val_accuracy: 0.6170\n",
      "Epoch 6/30\n",
      "3/3 [==============================] - 1s 612ms/step - loss: 0.7726 - accuracy: 0.6895 - val_loss: 0.8049 - val_accuracy: 0.6383\n",
      "Epoch 7/30\n",
      "3/3 [==============================] - 1s 614ms/step - loss: 0.7448 - accuracy: 0.7526 - val_loss: 0.7810 - val_accuracy: 0.6170\n",
      "Epoch 8/30\n",
      "3/3 [==============================] - 1s 630ms/step - loss: 0.7251 - accuracy: 0.7316 - val_loss: 0.7589 - val_accuracy: 0.6170\n",
      "Epoch 9/30\n",
      "3/3 [==============================] - 1s 619ms/step - loss: 0.6771 - accuracy: 0.7474 - val_loss: 0.7299 - val_accuracy: 0.6383\n",
      "Epoch 10/30\n",
      "3/3 [==============================] - 1s 622ms/step - loss: 0.6233 - accuracy: 0.7684 - val_loss: 0.6980 - val_accuracy: 0.7021\n",
      "Epoch 11/30\n",
      "3/3 [==============================] - 1s 626ms/step - loss: 0.6041 - accuracy: 0.7632 - val_loss: 0.6721 - val_accuracy: 0.7234\n",
      "Epoch 12/30\n",
      "3/3 [==============================] - 1s 615ms/step - loss: 0.5845 - accuracy: 0.7895 - val_loss: 0.6524 - val_accuracy: 0.7234\n",
      "Epoch 13/30\n",
      "3/3 [==============================] - 1s 620ms/step - loss: 0.5539 - accuracy: 0.8000 - val_loss: 0.6389 - val_accuracy: 0.7021\n",
      "Epoch 14/30\n",
      "3/3 [==============================] - 1s 625ms/step - loss: 0.5587 - accuracy: 0.7737 - val_loss: 0.6266 - val_accuracy: 0.7021\n",
      "Epoch 15/30\n",
      "3/3 [==============================] - 1s 625ms/step - loss: 0.5323 - accuracy: 0.8263 - val_loss: 0.6143 - val_accuracy: 0.7021\n",
      "Epoch 16/30\n",
      "3/3 [==============================] - 1s 628ms/step - loss: 0.5251 - accuracy: 0.8053 - val_loss: 0.6034 - val_accuracy: 0.7447\n",
      "Epoch 17/30\n",
      "3/3 [==============================] - 1s 626ms/step - loss: 0.4841 - accuracy: 0.8526 - val_loss: 0.5897 - val_accuracy: 0.7447\n",
      "Epoch 18/30\n",
      "3/3 [==============================] - 1s 615ms/step - loss: 0.4821 - accuracy: 0.8474 - val_loss: 0.5810 - val_accuracy: 0.7447\n",
      "Epoch 19/30\n",
      "3/3 [==============================] - 1s 622ms/step - loss: 0.4672 - accuracy: 0.8263 - val_loss: 0.5790 - val_accuracy: 0.7447\n",
      "Epoch 20/30\n",
      "3/3 [==============================] - 1s 629ms/step - loss: 0.4350 - accuracy: 0.8421 - val_loss: 0.5755 - val_accuracy: 0.7234\n",
      "Epoch 21/30\n",
      "3/3 [==============================] - 1s 625ms/step - loss: 0.4207 - accuracy: 0.8632 - val_loss: 0.5678 - val_accuracy: 0.7234\n",
      "Epoch 22/30\n",
      "3/3 [==============================] - 1s 623ms/step - loss: 0.4114 - accuracy: 0.8842 - val_loss: 0.5587 - val_accuracy: 0.7660\n",
      "Epoch 23/30\n",
      "3/3 [==============================] - 1s 626ms/step - loss: 0.3852 - accuracy: 0.8947 - val_loss: 0.5513 - val_accuracy: 0.7447\n",
      "Epoch 24/30\n",
      "3/3 [==============================] - 1s 622ms/step - loss: 0.3878 - accuracy: 0.9053 - val_loss: 0.5492 - val_accuracy: 0.7447\n",
      "Epoch 25/30\n",
      "3/3 [==============================] - 1s 621ms/step - loss: 0.3824 - accuracy: 0.8947 - val_loss: 0.5538 - val_accuracy: 0.7447\n",
      "Epoch 26/30\n",
      "3/3 [==============================] - 1s 621ms/step - loss: 0.3327 - accuracy: 0.9211 - val_loss: 0.5579 - val_accuracy: 0.7234\n",
      "Epoch 27/30\n",
      "3/3 [==============================] - 1s 622ms/step - loss: 0.3465 - accuracy: 0.9000 - val_loss: 0.5540 - val_accuracy: 0.7234\n",
      "Epoch 28/30\n",
      "3/3 [==============================] - 1s 616ms/step - loss: 0.3438 - accuracy: 0.8895 - val_loss: 0.5452 - val_accuracy: 0.7660\n",
      "Epoch 29/30\n",
      "3/3 [==============================] - 1s 615ms/step - loss: 0.3155 - accuracy: 0.9421 - val_loss: 0.5387 - val_accuracy: 0.7660\n",
      "Epoch 30/30\n",
      "3/3 [==============================] - 1s 617ms/step - loss: 0.3376 - accuracy: 0.8895 - val_loss: 0.5346 - val_accuracy: 0.7660\n",
      "Found 190 validated image filenames belonging to 3 classes.\n",
      "Found 47 validated image filenames belonging to 3 classes.\n",
      "Found 60 validated image filenames belonging to 3 classes.\n",
      "Found 190 validated image filenames belonging to 3 classes.\n",
      "Found 47 validated image filenames belonging to 3 classes.\n",
      "Found 60 validated image filenames belonging to 3 classes.\n",
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "AP(Mortise) (InputLayer)        [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Lateral (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "resnet50 (Functional)           (None, 2048)         23587712    AP(Mortise)[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "efficientnetb0 (Functional)     (None, 1280)         4049571     Lateral[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "AP_dense_128 (Dense)            (None, 128)          262272      resnet50[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Lateral_dense_128 (Dense)       (None, 128)          163968      efficientnetb0[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "AP_dense_50 (Dense)             (None, 50)           6450        AP_dense_128[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Lateral_dense_50 (Dense)        (None, 50)           6450        Lateral_dense_128[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "feature_fusion (Concatenate)    (None, 100)          0           AP_dense_50[0][0]                \n",
      "                                                                 Lateral_dense_50[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 100)          0           feature_fusion[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "output_layer (Dense)            (None, 3)            303         dropout_4[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 28,076,726\n",
      "Trainable params: 439,443\n",
      "Non-trainable params: 27,637,283\n",
      "__________________________________________________________________________________________________\n",
      "-------Training_concat1-------\n",
      "Epoch 1/30\n",
      "3/3 [==============================] - 6s 986ms/step - loss: 1.0797 - accuracy: 0.4000 - val_loss: 0.9544 - val_accuracy: 0.5957\n",
      "Epoch 2/30\n",
      "3/3 [==============================] - 1s 626ms/step - loss: 0.9868 - accuracy: 0.5526 - val_loss: 0.8889 - val_accuracy: 0.6383\n",
      "Epoch 3/30\n",
      "3/3 [==============================] - 1s 632ms/step - loss: 0.9149 - accuracy: 0.6211 - val_loss: 0.8168 - val_accuracy: 0.7234\n",
      "Epoch 4/30\n",
      "3/3 [==============================] - 1s 620ms/step - loss: 0.8439 - accuracy: 0.6579 - val_loss: 0.7586 - val_accuracy: 0.7660\n",
      "Epoch 5/30\n",
      "3/3 [==============================] - 1s 623ms/step - loss: 0.7836 - accuracy: 0.6789 - val_loss: 0.7170 - val_accuracy: 0.7447\n",
      "Epoch 6/30\n",
      "3/3 [==============================] - 1s 626ms/step - loss: 0.7145 - accuracy: 0.7368 - val_loss: 0.6812 - val_accuracy: 0.7447\n",
      "Epoch 7/30\n",
      "3/3 [==============================] - 1s 623ms/step - loss: 0.6986 - accuracy: 0.7105 - val_loss: 0.6531 - val_accuracy: 0.7660\n",
      "Epoch 8/30\n",
      "3/3 [==============================] - 1s 623ms/step - loss: 0.6576 - accuracy: 0.7158 - val_loss: 0.6281 - val_accuracy: 0.7234\n",
      "Epoch 9/30\n",
      "3/3 [==============================] - 1s 626ms/step - loss: 0.5969 - accuracy: 0.8105 - val_loss: 0.6064 - val_accuracy: 0.7021\n",
      "Epoch 10/30\n",
      "3/3 [==============================] - 1s 627ms/step - loss: 0.5761 - accuracy: 0.8000 - val_loss: 0.5875 - val_accuracy: 0.7660\n",
      "Epoch 11/30\n",
      "3/3 [==============================] - 1s 618ms/step - loss: 0.5513 - accuracy: 0.8263 - val_loss: 0.5716 - val_accuracy: 0.7660\n",
      "Epoch 12/30\n",
      "3/3 [==============================] - 1s 620ms/step - loss: 0.5160 - accuracy: 0.8316 - val_loss: 0.5603 - val_accuracy: 0.7447\n",
      "Epoch 13/30\n",
      "3/3 [==============================] - 1s 644ms/step - loss: 0.4871 - accuracy: 0.8579 - val_loss: 0.5518 - val_accuracy: 0.7234\n",
      "Epoch 14/30\n",
      "3/3 [==============================] - 1s 627ms/step - loss: 0.4635 - accuracy: 0.8789 - val_loss: 0.5440 - val_accuracy: 0.7021\n",
      "Epoch 15/30\n",
      "3/3 [==============================] - 1s 622ms/step - loss: 0.4640 - accuracy: 0.8316 - val_loss: 0.5370 - val_accuracy: 0.6809\n",
      "Epoch 16/30\n",
      "3/3 [==============================] - 1s 633ms/step - loss: 0.4181 - accuracy: 0.8737 - val_loss: 0.5306 - val_accuracy: 0.7021\n",
      "Epoch 17/30\n",
      "3/3 [==============================] - 1s 626ms/step - loss: 0.4160 - accuracy: 0.8789 - val_loss: 0.5258 - val_accuracy: 0.7021\n",
      "Epoch 18/30\n",
      "3/3 [==============================] - 1s 625ms/step - loss: 0.4215 - accuracy: 0.8421 - val_loss: 0.5235 - val_accuracy: 0.6809\n",
      "Epoch 19/30\n",
      "3/3 [==============================] - 1s 626ms/step - loss: 0.3620 - accuracy: 0.9158 - val_loss: 0.5225 - val_accuracy: 0.7021\n",
      "Epoch 20/30\n",
      "3/3 [==============================] - 1s 626ms/step - loss: 0.3778 - accuracy: 0.8842 - val_loss: 0.5163 - val_accuracy: 0.7021\n",
      "Epoch 21/30\n",
      "3/3 [==============================] - 1s 622ms/step - loss: 0.3462 - accuracy: 0.9105 - val_loss: 0.5119 - val_accuracy: 0.7021\n",
      "Epoch 22/30\n",
      "3/3 [==============================] - 1s 618ms/step - loss: 0.3574 - accuracy: 0.8947 - val_loss: 0.5104 - val_accuracy: 0.7021\n",
      "Epoch 23/30\n",
      "3/3 [==============================] - 1s 623ms/step - loss: 0.3242 - accuracy: 0.9158 - val_loss: 0.5113 - val_accuracy: 0.7021\n",
      "Epoch 24/30\n",
      "3/3 [==============================] - 1s 626ms/step - loss: 0.3323 - accuracy: 0.9316 - val_loss: 0.5097 - val_accuracy: 0.7021\n",
      "Epoch 25/30\n",
      "3/3 [==============================] - 1s 628ms/step - loss: 0.2915 - accuracy: 0.9421 - val_loss: 0.5089 - val_accuracy: 0.7021\n",
      "Epoch 26/30\n",
      "3/3 [==============================] - 1s 619ms/step - loss: 0.3163 - accuracy: 0.9211 - val_loss: 0.5128 - val_accuracy: 0.7021\n",
      "Epoch 27/30\n",
      "3/3 [==============================] - 1s 625ms/step - loss: 0.2824 - accuracy: 0.9421 - val_loss: 0.5131 - val_accuracy: 0.7021\n",
      "Epoch 28/30\n",
      "3/3 [==============================] - 1s 618ms/step - loss: 0.2833 - accuracy: 0.9263 - val_loss: 0.5107 - val_accuracy: 0.7021\n",
      "Epoch 29/30\n",
      "3/3 [==============================] - 1s 623ms/step - loss: 0.2619 - accuracy: 0.9474 - val_loss: 0.5094 - val_accuracy: 0.7234\n",
      "Epoch 30/30\n",
      "3/3 [==============================] - 1s 628ms/step - loss: 0.2731 - accuracy: 0.9316 - val_loss: 0.5144 - val_accuracy: 0.7234\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002BC2F838288> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "acc mean = 0.74, std = 0.04, test_acc = [0.77, 0.73, 0.68, 0.72, 0.78]\n",
      "f1  mean = 0.71, std = 0.03, test_f1 = [0.74, 0.7, 0.66, 0.69, 0.75]\n"
     ]
    }
   ],
   "source": [
    "# import\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path\n",
    "# import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import os\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from tensorflow.keras.layers import Input, Dense, Concatenate, Dropout\n",
    "import math\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "## label\n",
    "# =========================\n",
    "def class_2_type(root):\n",
    "    label = \"\"\n",
    "    if \"正常\" in root:\n",
    "        label = \"0\"\n",
    "    else:\n",
    "        label = \"1\"\n",
    "    return label\n",
    "\n",
    "def class_3_type(root):\n",
    "    label = \"\"\n",
    "    if \"正常\" in root:\n",
    "        label = \"0\"\n",
    "    elif \"雙踝\" in root:\n",
    "        label = \"1\"\n",
    "    elif \"三踝\" in root:\n",
    "        label = \"2\"\n",
    "    return label\n",
    "# =========================\n",
    "\n",
    "\n",
    "def load_path(path, class_count):\n",
    "    dataset = []\n",
    "    class_type = ''\n",
    "    if class_count == 2:\n",
    "        class_type = class_2_type\n",
    "    elif class_count == 3:\n",
    "        class_type = class_3_type  \n",
    "\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            label = class_type(root)\n",
    "            # if label != \"\":\n",
    "            dataset.append(\n",
    "                            {   \n",
    "                                'uuid': root.split(\"\\\\\")[-1],\n",
    "                                'label': label,\n",
    "                                'image_path': os.path.join(root, file)\n",
    "                            }\n",
    "                        )\n",
    "\n",
    "    return dataset\n",
    "\n",
    "def create_front_extract():\n",
    "    pretrained_model_chosen = tf.keras.applications.resnet50.ResNet50\n",
    "    pretrained_model = pretrained_model_chosen(\n",
    "        input_shape=(224, 224, 3),\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        pooling='avg')\n",
    "    pretrained_model.trainable = False\n",
    "    return pretrained_model\n",
    "\n",
    "def create_side_extract():\n",
    "    pretrained_model_chosen = tf.keras.applications.efficientnet.EfficientNetB0\n",
    "    pretrained_model = pretrained_model_chosen(\n",
    "        input_shape=(224, 224, 3),\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        pooling='avg')\n",
    "    pretrained_model.trainable = False\n",
    "    return pretrained_model\n",
    "\n",
    "def multi_input_generator(front_gen, side_gen):\n",
    "    while True:\n",
    "        front_batch, y1 = next(front_gen)\n",
    "        side_batch, y2 = next(side_gen)\n",
    "        assert (y1 == y2).all(), \"Label mismatch!\"  # 確保標籤一致\n",
    "        yield ([front_batch, side_batch], y1)\n",
    "\n",
    "\n",
    "# def train_cross_validation(image_dir, n_splits=5, class_count=2, maru_part=None,  chosen_model='resnet50'):\n",
    "def train_cross_validation(image_dir, n_splits=5, class_count=2):\n",
    "\n",
    "\n",
    "    ## load data and  labels\n",
    "    # =========================\n",
    "    labels = []\n",
    "    filepaths = []\n",
    "    data = load_path(image_dir, class_count)\n",
    "    for row in data:\n",
    "        labels.append(row['label'])\n",
    "        filepaths.append(row['image_path'])\n",
    "\n",
    "    filepaths = pd.Series(filepaths, name='Filepath').astype(str)\n",
    "    labels = pd.Series(labels, name='Label')\n",
    "\n",
    "    images = pd.concat([filepaths, labels], axis=1)\n",
    "    # =========================\n",
    "\n",
    "    ## split image\n",
    "    # =========================\n",
    "    train_df_front, test_df_front = train_test_split(images, train_size=0.8, shuffle=True, random_state=1, stratify=images['Label'])\n",
    "    print(\"Training set label distribution:\\n\", train_df_front['Label'].value_counts(normalize=False))\n",
    "    print(\"Test set label distribution:\\n\", test_df_front['Label'].value_counts(normalize=False))\n",
    "    # =========================\n",
    "\n",
    "    preprocessing_function_chosen_front = tf.keras.applications.resnet50.preprocess_input\n",
    "    preprocessing_function_chosen_side = tf.keras.applications.efficientnet.preprocess_input\n",
    "\n",
    "\n",
    "    ## train model, k fold cross validation\n",
    "    # ==================================================\n",
    "    fold_no = 1\n",
    "    test_acc = []\n",
    "    test_f1 = []\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=1)\n",
    "    for train_index, val_index in kfold.split(train_df_front, train_df_front['Label']):\n",
    "        k_fold_train_front = train_df_front.iloc[train_index]\n",
    "        k_fold_val_front = train_df_front.iloc[val_index]\n",
    "\n",
    "        # front images\n",
    "        # =========================\n",
    "        train_generator_front = tf.keras.preprocessing.image.ImageDataGenerator(horizontal_flip=False,\n",
    "                                                                                preprocessing_function=preprocessing_function_chosen_front)\n",
    "        test_generator_front = tf.keras.preprocessing.image.ImageDataGenerator(preprocessing_function=preprocessing_function_chosen_front)\n",
    "\n",
    "        train_images_front = train_generator_front.flow_from_dataframe(\n",
    "            dataframe=k_fold_train_front,\n",
    "            x_col='Filepath',\n",
    "            y_col='Label',\n",
    "            target_size=(224, 224),\n",
    "            color_mode='rgb',\n",
    "            class_mode='categorical',\n",
    "            batch_size=64,\n",
    "            shuffle=False,\n",
    "            seed=42\n",
    "        )\n",
    "\n",
    "        val_images_front = train_generator_front.flow_from_dataframe(\n",
    "            dataframe=k_fold_val_front,\n",
    "            x_col='Filepath',\n",
    "            y_col='Label',\n",
    "            target_size=(224, 224),\n",
    "            color_mode='rgb',\n",
    "            class_mode='categorical',\n",
    "            batch_size=64,\n",
    "            shuffle=False,\n",
    "            seed=42\n",
    "        )\n",
    "\n",
    "        test_images_front = test_generator_front.flow_from_dataframe(\n",
    "            dataframe=test_df_front,\n",
    "            x_col='Filepath',\n",
    "            y_col='Label',\n",
    "            target_size=(224, 224),\n",
    "            color_mode='rgb',\n",
    "            class_mode='categorical',\n",
    "            batch_size=32,\n",
    "            shuffle=False\n",
    "        )\n",
    "        # =========================   \n",
    "\n",
    "        # side images\n",
    "        # =========================\n",
    "        train_df_side = train_df_front.copy()\n",
    "        test_df_side = test_df_front.copy()\n",
    "        train_df_side.loc[:, \"Filepath\"] = train_df_front[\"Filepath\"].str.replace(\"front\", \"side\")\n",
    "        test_df_side.loc[:, \"Filepath\"] = test_df_side[\"Filepath\"].str.replace(\"front\", \"side\")\n",
    "\n",
    "        k_fold_train_side = train_df_side.iloc[train_index]\n",
    "        k_fold_val_side = train_df_side.iloc[val_index]\n",
    "\n",
    "        train_generator_side = tf.keras.preprocessing.image.ImageDataGenerator(horizontal_flip=False,\n",
    "                                                                                preprocessing_function=preprocessing_function_chosen_side)\n",
    "        test_generator_side = tf.keras.preprocessing.image.ImageDataGenerator(preprocessing_function=preprocessing_function_chosen_side)\n",
    "\n",
    "        train_images_side = train_generator_side.flow_from_dataframe(\n",
    "            dataframe=k_fold_train_side,\n",
    "            x_col='Filepath',\n",
    "            y_col='Label',\n",
    "            target_size=(224, 224),\n",
    "            color_mode='rgb',\n",
    "            class_mode='categorical',\n",
    "            batch_size=64,\n",
    "            shuffle=False,\n",
    "            seed=42\n",
    "        )\n",
    "\n",
    "        val_images_side = train_generator_side.flow_from_dataframe(\n",
    "            dataframe=k_fold_val_side,\n",
    "            x_col='Filepath',\n",
    "            y_col='Label',\n",
    "            target_size=(224, 224),\n",
    "            color_mode='rgb',\n",
    "            class_mode='categorical',\n",
    "            batch_size=64,\n",
    "            shuffle=False,\n",
    "            seed=42\n",
    "        )\n",
    "\n",
    "        test_images_side = test_generator_side.flow_from_dataframe(\n",
    "            dataframe=test_df_side,\n",
    "            x_col='Filepath',\n",
    "            y_col='Label',\n",
    "            target_size=(224, 224),\n",
    "            color_mode='rgb',\n",
    "            class_mode='categorical',\n",
    "            batch_size=32,\n",
    "            shuffle=False\n",
    "        )\n",
    "        # ========================= \n",
    "        \n",
    "        # load model\n",
    "        # =========================\n",
    "        # input \n",
    "        input_front = Input(shape=(224, 224, 3), name=\"AP(Mortise)\")\n",
    "        input_side = Input(shape=(224, 224, 3), name=\"Lateral\")\n",
    "\n",
    "        # model\n",
    "        model_front = create_front_extract()\n",
    "        model_side = create_side_extract()\n",
    "\n",
    "        features_front = model_front(input_front)\n",
    "        features_side = model_side(input_side)\n",
    "\n",
    "        features_front_x = tf.keras.layers.Dense(128, activation='relu', name='AP_dense_128')(features_front)\n",
    "        features_front_x = tf.keras.layers.Dense(50, activation='relu', name='AP_dense_50')(features_front_x)\n",
    "\n",
    "        features_side_x = tf.keras.layers.Dense(128, activation='relu', name='Lateral_dense_128')(features_side)\n",
    "        features_side_x = tf.keras.layers.Dense(50, activation='relu', name='Lateral_dense_50')(features_side_x)\n",
    "\n",
    "        fused_features = Concatenate(name=\"feature_fusion\")([features_front_x, features_side_x])\n",
    "        # fused_features = tf.keras.layers.Dense(50, activation='relu', name='fusion_dense_50')(fused_features)\n",
    "        fused_features = Dropout(0.1)(fused_features)\n",
    "\n",
    "        final_output = Dense(class_count, activation='sigmoid', name='output_layer')(fused_features)\n",
    "        multi_view_model = None\n",
    "        multi_view_model = Model(\n",
    "            inputs=[input_front, input_side],\n",
    "            outputs=final_output\n",
    "        )\n",
    "        multi_view_model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        multi_view_model.summary()\n",
    "        # print(model.summary())\n",
    "        # =========================\n",
    "\n",
    "        train_generator = multi_input_generator(train_images_front, train_images_side)\n",
    "        val_generator = multi_input_generator(val_images_front, val_images_side)\n",
    "        \n",
    "        ## compile and evaluate\n",
    "        # =========================\n",
    "\n",
    "        print(\"-------Training_\" + concat_type + \"-------\")\n",
    "        multi_view_model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "        batch_size = 64\n",
    "        ## early stop \n",
    "        # early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)\n",
    "        # multi_view_model.fit(train_generator, validation_data=val_generator, callbacks=[early_stopping], epochs=30,\n",
    "        #                             steps_per_epoch= math.ceil(train_images_front.samples / batch_size), \n",
    "        #                             validation_steps= math.ceil(val_images_front.samples / batch_size))\n",
    "        ## no early stop\n",
    "        multi_view_model.fit(train_generator, validation_data=val_generator, epochs=30,\n",
    "                            steps_per_epoch= math.ceil(train_images_front.samples / batch_size), \n",
    "                            validation_steps= math.ceil(val_images_front.samples / batch_size))\n",
    "\n",
    "        # =========================\n",
    "\n",
    "        test_generator = multi_input_generator(test_images_front, test_images_side)\n",
    "        batch_size=32\n",
    "        pred = multi_view_model.predict(test_generator,  steps=math.ceil(test_images_front.samples / batch_size))\n",
    "        predicted_labels = np.argmax(pred, axis=1)\n",
    "\n",
    "        # =========================\n",
    "            \n",
    "        ## print results\n",
    "        # =========================\n",
    "        acc = accuracy_score(test_images_front.labels, predicted_labels)\n",
    "\n",
    "        test_acc.append(np.round(acc, 2))\n",
    "        f1 = f1_score(test_images_front.labels, predicted_labels, average='macro')\n",
    "        test_f1.append(np.round(f1, 2))\n",
    "        fold_no += 1\n",
    "        # =========================\n",
    "    # ==================================================\n",
    "        \n",
    "    ## print  mean results\n",
    "    # =========================\n",
    "    acc_mean  = np.round(np.mean(test_acc), 2)\n",
    "    acc_std = np.round(np.std(test_acc), 2)\n",
    "    f1_mean  = np.round(np.mean(test_f1), 2)\n",
    "    f1_std = np.round(np.std(test_f1), 2)\n",
    "    # print(f\"acc mean = {acc_mean}, std = {acc_std}\")\n",
    "    # print(test_acc)\n",
    "    # print(f\"f1  mean = {f1_mean}, std = {f1_std}\")\n",
    "    # print(test_f1)\n",
    "    # =========================\n",
    "\n",
    "    return {'acc_mean':acc_mean, 'acc_std':acc_std, 'test_acc':test_acc, 'f1_mean':f1_mean, 'f1_std':f1_std, 'test_f1':test_f1}\n",
    "\n",
    "\n",
    "# =========================\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "results = []\n",
    "results = train_cross_validation(image_dir=path, class_count=3)\n",
    "\n",
    "\n",
    "print(f\"acc mean = {results['acc_mean']}, std = {results['acc_std']}, test_acc = {results['test_acc']}\")\n",
    "print(f\"f1  mean = {results['f1_mean']}, std = {results['f1_std']}, test_f1 = {results['test_f1']}\")\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set label distribution:\n",
      " 0    101\n",
      "2     69\n",
      "1     67\n",
      "Name: Label, dtype: int64\n",
      "Test set label distribution:\n",
      " 0    25\n",
      "2    18\n",
      "1    17\n",
      "Name: Label, dtype: int64\n",
      "Found 189 validated image filenames belonging to 3 classes.\n",
      "Found 48 validated image filenames belonging to 3 classes.\n",
      "Found 60 validated image filenames belonging to 3 classes.\n",
      "Found 189 validated image filenames belonging to 3 classes.\n",
      "Found 48 validated image filenames belonging to 3 classes.\n",
      "Found 60 validated image filenames belonging to 3 classes.\n",
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "AP(Mortise) (InputLayer)        [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Lateral (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "resnet50 (Functional)           (None, 2048)         23587712    AP(Mortise)[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "efficientnetb0 (Functional)     (None, 1280)         4049571     Lateral[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "AP_dense_128 (Dense)            (None, 128)          262272      resnet50[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Lateral_dense_128 (Dense)       (None, 128)          163968      efficientnetb0[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "AP_dense_50 (Dense)             (None, 50)           6450        AP_dense_128[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Lateral_dense_50 (Dense)        (None, 50)           6450        Lateral_dense_128[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "feature_fusion (Concatenate)    (None, 100)          0           AP_dense_50[0][0]                \n",
      "                                                                 Lateral_dense_50[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 100)          0           feature_fusion[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "output_layer (Dense)            (None, 3)            303         dropout_5[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 28,076,726\n",
      "Trainable params: 439,443\n",
      "Non-trainable params: 27,637,283\n",
      "__________________________________________________________________________________________________\n",
      "-------Training_concat1-------\n",
      "Epoch 1/30\n",
      "3/3 [==============================] - 6s 971ms/step - loss: 1.2004 - accuracy: 0.3122 - val_loss: 1.0654 - val_accuracy: 0.5000\n",
      "Epoch 2/30\n",
      "3/3 [==============================] - 1s 632ms/step - loss: 1.0413 - accuracy: 0.4868 - val_loss: 0.9966 - val_accuracy: 0.5208\n",
      "Epoch 3/30\n",
      "3/3 [==============================] - 1s 631ms/step - loss: 0.9770 - accuracy: 0.5079 - val_loss: 0.9396 - val_accuracy: 0.5833\n",
      "Epoch 4/30\n",
      "3/3 [==============================] - 1s 633ms/step - loss: 0.8952 - accuracy: 0.5767 - val_loss: 0.8826 - val_accuracy: 0.6458\n",
      "Epoch 5/30\n",
      "3/3 [==============================] - 1s 632ms/step - loss: 0.8568 - accuracy: 0.6614 - val_loss: 0.8365 - val_accuracy: 0.6667\n",
      "Epoch 6/30\n",
      "3/3 [==============================] - 1s 644ms/step - loss: 0.7954 - accuracy: 0.7354 - val_loss: 0.7982 - val_accuracy: 0.7083\n",
      "Epoch 7/30\n",
      "3/3 [==============================] - 1s 637ms/step - loss: 0.7540 - accuracy: 0.7196 - val_loss: 0.7599 - val_accuracy: 0.7500\n",
      "Epoch 8/30\n",
      "3/3 [==============================] - 1s 638ms/step - loss: 0.6837 - accuracy: 0.7566 - val_loss: 0.7266 - val_accuracy: 0.7708\n",
      "Epoch 9/30\n",
      "3/3 [==============================] - 1s 637ms/step - loss: 0.6664 - accuracy: 0.7566 - val_loss: 0.6980 - val_accuracy: 0.7708\n",
      "Epoch 10/30\n",
      "3/3 [==============================] - 1s 629ms/step - loss: 0.6369 - accuracy: 0.7989 - val_loss: 0.6720 - val_accuracy: 0.7708\n",
      "Epoch 11/30\n",
      "3/3 [==============================] - 1s 632ms/step - loss: 0.5976 - accuracy: 0.8254 - val_loss: 0.6513 - val_accuracy: 0.7708\n",
      "Epoch 12/30\n",
      "3/3 [==============================] - 1s 624ms/step - loss: 0.5712 - accuracy: 0.8201 - val_loss: 0.6314 - val_accuracy: 0.7708\n",
      "Epoch 13/30\n",
      "3/3 [==============================] - 1s 621ms/step - loss: 0.5491 - accuracy: 0.8360 - val_loss: 0.6133 - val_accuracy: 0.8333\n",
      "Epoch 14/30\n",
      "3/3 [==============================] - 1s 623ms/step - loss: 0.5188 - accuracy: 0.8571 - val_loss: 0.5970 - val_accuracy: 0.8333\n",
      "Epoch 15/30\n",
      "3/3 [==============================] - 1s 629ms/step - loss: 0.5020 - accuracy: 0.8042 - val_loss: 0.5816 - val_accuracy: 0.8125\n",
      "Epoch 16/30\n",
      "3/3 [==============================] - 1s 629ms/step - loss: 0.4684 - accuracy: 0.8942 - val_loss: 0.5690 - val_accuracy: 0.8125\n",
      "Epoch 17/30\n",
      "3/3 [==============================] - 1s 630ms/step - loss: 0.4661 - accuracy: 0.8519 - val_loss: 0.5557 - val_accuracy: 0.8125\n",
      "Epoch 18/30\n",
      "3/3 [==============================] - 1s 623ms/step - loss: 0.4361 - accuracy: 0.8519 - val_loss: 0.5448 - val_accuracy: 0.8125\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002BC681809D8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Found 189 validated image filenames belonging to 3 classes.\n",
      "Found 48 validated image filenames belonging to 3 classes.\n",
      "Found 60 validated image filenames belonging to 3 classes.\n",
      "Found 189 validated image filenames belonging to 3 classes.\n",
      "Found 48 validated image filenames belonging to 3 classes.\n",
      "Found 60 validated image filenames belonging to 3 classes.\n",
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "AP(Mortise) (InputLayer)        [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Lateral (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "resnet50 (Functional)           (None, 2048)         23587712    AP(Mortise)[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "efficientnetb0 (Functional)     (None, 1280)         4049571     Lateral[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "AP_dense_128 (Dense)            (None, 128)          262272      resnet50[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Lateral_dense_128 (Dense)       (None, 128)          163968      efficientnetb0[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "AP_dense_50 (Dense)             (None, 50)           6450        AP_dense_128[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Lateral_dense_50 (Dense)        (None, 50)           6450        Lateral_dense_128[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "feature_fusion (Concatenate)    (None, 100)          0           AP_dense_50[0][0]                \n",
      "                                                                 Lateral_dense_50[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 100)          0           feature_fusion[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "output_layer (Dense)            (None, 3)            303         dropout_6[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 28,076,726\n",
      "Trainable params: 439,443\n",
      "Non-trainable params: 27,637,283\n",
      "__________________________________________________________________________________________________\n",
      "-------Training_concat1-------\n",
      "Epoch 1/30\n",
      "3/3 [==============================] - 6s 1s/step - loss: 1.5143 - accuracy: 0.2857 - val_loss: 1.1603 - val_accuracy: 0.2500\n",
      "Epoch 2/30\n",
      "3/3 [==============================] - 1s 647ms/step - loss: 1.1099 - accuracy: 0.3915 - val_loss: 1.0578 - val_accuracy: 0.4583\n",
      "Epoch 3/30\n",
      "3/3 [==============================] - 1s 635ms/step - loss: 1.0328 - accuracy: 0.4974 - val_loss: 1.0636 - val_accuracy: 0.4167\n",
      "Epoch 4/30\n",
      "3/3 [==============================] - 1s 645ms/step - loss: 0.9800 - accuracy: 0.5026 - val_loss: 0.9890 - val_accuracy: 0.4167\n",
      "Epoch 5/30\n",
      "3/3 [==============================] - 1s 640ms/step - loss: 0.9400 - accuracy: 0.5344 - val_loss: 0.8790 - val_accuracy: 0.5417\n",
      "Epoch 6/30\n",
      "3/3 [==============================] - 1s 632ms/step - loss: 0.8244 - accuracy: 0.7037 - val_loss: 0.7929 - val_accuracy: 0.6875\n",
      "Epoch 7/30\n",
      "3/3 [==============================] - 1s 638ms/step - loss: 0.7659 - accuracy: 0.7196 - val_loss: 0.7430 - val_accuracy: 0.7292\n",
      "Epoch 8/30\n",
      "3/3 [==============================] - 1s 640ms/step - loss: 0.7212 - accuracy: 0.7672 - val_loss: 0.7083 - val_accuracy: 0.7083\n",
      "Epoch 9/30\n",
      "3/3 [==============================] - 1s 640ms/step - loss: 0.6751 - accuracy: 0.7619 - val_loss: 0.6794 - val_accuracy: 0.7083\n",
      "Epoch 10/30\n",
      "3/3 [==============================] - 1s 643ms/step - loss: 0.6110 - accuracy: 0.7989 - val_loss: 0.6610 - val_accuracy: 0.6875\n",
      "Epoch 11/30\n",
      "3/3 [==============================] - 1s 634ms/step - loss: 0.5961 - accuracy: 0.7778 - val_loss: 0.6448 - val_accuracy: 0.7083\n",
      "Epoch 12/30\n",
      "3/3 [==============================] - 1s 641ms/step - loss: 0.5676 - accuracy: 0.7566 - val_loss: 0.6181 - val_accuracy: 0.7083\n",
      "Found 190 validated image filenames belonging to 3 classes.\n",
      "Found 47 validated image filenames belonging to 3 classes.\n",
      "Found 60 validated image filenames belonging to 3 classes.\n",
      "Found 190 validated image filenames belonging to 3 classes.\n",
      "Found 47 validated image filenames belonging to 3 classes.\n",
      "Found 60 validated image filenames belonging to 3 classes.\n",
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "AP(Mortise) (InputLayer)        [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Lateral (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "resnet50 (Functional)           (None, 2048)         23587712    AP(Mortise)[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "efficientnetb0 (Functional)     (None, 1280)         4049571     Lateral[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "AP_dense_128 (Dense)            (None, 128)          262272      resnet50[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Lateral_dense_128 (Dense)       (None, 128)          163968      efficientnetb0[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "AP_dense_50 (Dense)             (None, 50)           6450        AP_dense_128[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Lateral_dense_50 (Dense)        (None, 50)           6450        Lateral_dense_128[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "feature_fusion (Concatenate)    (None, 100)          0           AP_dense_50[0][0]                \n",
      "                                                                 Lateral_dense_50[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 100)          0           feature_fusion[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "output_layer (Dense)            (None, 3)            303         dropout_7[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 28,076,726\n",
      "Trainable params: 439,443\n",
      "Non-trainable params: 27,637,283\n",
      "__________________________________________________________________________________________________\n",
      "-------Training_concat1-------\n",
      "Epoch 1/30\n",
      "3/3 [==============================] - 6s 1s/step - loss: 1.0005 - accuracy: 0.5053 - val_loss: 0.9320 - val_accuracy: 0.5319\n",
      "Epoch 2/30\n",
      "3/3 [==============================] - 1s 653ms/step - loss: 0.8852 - accuracy: 0.6105 - val_loss: 0.8452 - val_accuracy: 0.6809\n",
      "Epoch 3/30\n",
      "3/3 [==============================] - 1s 649ms/step - loss: 0.8074 - accuracy: 0.6737 - val_loss: 0.7804 - val_accuracy: 0.7021\n",
      "Epoch 4/30\n",
      "3/3 [==============================] - 1s 647ms/step - loss: 0.7310 - accuracy: 0.6842 - val_loss: 0.7370 - val_accuracy: 0.6809\n",
      "Epoch 5/30\n",
      "3/3 [==============================] - 1s 655ms/step - loss: 0.6777 - accuracy: 0.7474 - val_loss: 0.7120 - val_accuracy: 0.6383\n",
      "Epoch 6/30\n",
      "3/3 [==============================] - 1s 657ms/step - loss: 0.6425 - accuracy: 0.7368 - val_loss: 0.6944 - val_accuracy: 0.6596\n",
      "Epoch 7/30\n",
      "3/3 [==============================] - 1s 654ms/step - loss: 0.5784 - accuracy: 0.7842 - val_loss: 0.6755 - val_accuracy: 0.6809\n",
      "Epoch 8/30\n",
      "3/3 [==============================] - 1s 650ms/step - loss: 0.5449 - accuracy: 0.7842 - val_loss: 0.6588 - val_accuracy: 0.7234\n",
      "Epoch 9/30\n",
      "3/3 [==============================] - 1s 651ms/step - loss: 0.5153 - accuracy: 0.8316 - val_loss: 0.6467 - val_accuracy: 0.7021\n",
      "Epoch 10/30\n",
      "3/3 [==============================] - 1s 651ms/step - loss: 0.4894 - accuracy: 0.8053 - val_loss: 0.6347 - val_accuracy: 0.7447\n",
      "Epoch 11/30\n",
      "3/3 [==============================] - 1s 650ms/step - loss: 0.4899 - accuracy: 0.8053 - val_loss: 0.6283 - val_accuracy: 0.7447\n",
      "Epoch 12/30\n",
      "3/3 [==============================] - 1s 650ms/step - loss: 0.4777 - accuracy: 0.8000 - val_loss: 0.6239 - val_accuracy: 0.7447\n",
      "Epoch 13/30\n",
      "3/3 [==============================] - 1s 650ms/step - loss: 0.4191 - accuracy: 0.8737 - val_loss: 0.6174 - val_accuracy: 0.6809\n",
      "Epoch 14/30\n",
      "3/3 [==============================] - 1s 651ms/step - loss: 0.4334 - accuracy: 0.8368 - val_loss: 0.6118 - val_accuracy: 0.7021\n",
      "Epoch 15/30\n",
      "3/3 [==============================] - 1s 647ms/step - loss: 0.3979 - accuracy: 0.8579 - val_loss: 0.6056 - val_accuracy: 0.7447\n",
      "Found 190 validated image filenames belonging to 3 classes.\n",
      "Found 47 validated image filenames belonging to 3 classes.\n",
      "Found 60 validated image filenames belonging to 3 classes.\n",
      "Found 190 validated image filenames belonging to 3 classes.\n",
      "Found 47 validated image filenames belonging to 3 classes.\n",
      "Found 60 validated image filenames belonging to 3 classes.\n",
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "AP(Mortise) (InputLayer)        [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Lateral (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "resnet50 (Functional)           (None, 2048)         23587712    AP(Mortise)[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "efficientnetb0 (Functional)     (None, 1280)         4049571     Lateral[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "AP_dense_128 (Dense)            (None, 128)          262272      resnet50[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Lateral_dense_128 (Dense)       (None, 128)          163968      efficientnetb0[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "AP_dense_50 (Dense)             (None, 50)           6450        AP_dense_128[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Lateral_dense_50 (Dense)        (None, 50)           6450        Lateral_dense_128[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "feature_fusion (Concatenate)    (None, 100)          0           AP_dense_50[0][0]                \n",
      "                                                                 Lateral_dense_50[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 100)          0           feature_fusion[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "output_layer (Dense)            (None, 3)            303         dropout_8[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 28,076,726\n",
      "Trainable params: 439,443\n",
      "Non-trainable params: 27,637,283\n",
      "__________________________________________________________________________________________________\n",
      "-------Training_concat1-------\n",
      "Epoch 1/30\n",
      "3/3 [==============================] - 6s 989ms/step - loss: 1.2395 - accuracy: 0.2579 - val_loss: 1.1116 - val_accuracy: 0.3830\n",
      "Epoch 2/30\n",
      "3/3 [==============================] - 1s 643ms/step - loss: 1.0963 - accuracy: 0.3789 - val_loss: 1.0447 - val_accuracy: 0.4468\n",
      "Epoch 3/30\n",
      "3/3 [==============================] - 1s 641ms/step - loss: 1.0253 - accuracy: 0.4421 - val_loss: 0.9949 - val_accuracy: 0.4681\n",
      "Epoch 4/30\n",
      "3/3 [==============================] - 1s 638ms/step - loss: 0.9777 - accuracy: 0.5105 - val_loss: 0.9410 - val_accuracy: 0.5319\n",
      "Epoch 5/30\n",
      "3/3 [==============================] - 1s 646ms/step - loss: 0.8912 - accuracy: 0.6105 - val_loss: 0.8947 - val_accuracy: 0.5957\n",
      "Epoch 6/30\n",
      "3/3 [==============================] - 1s 644ms/step - loss: 0.8141 - accuracy: 0.6632 - val_loss: 0.8563 - val_accuracy: 0.5745\n",
      "Epoch 7/30\n",
      "3/3 [==============================] - 1s 652ms/step - loss: 0.7675 - accuracy: 0.7526 - val_loss: 0.8243 - val_accuracy: 0.5957\n",
      "Epoch 8/30\n",
      "3/3 [==============================] - 1s 642ms/step - loss: 0.7353 - accuracy: 0.7158 - val_loss: 0.7954 - val_accuracy: 0.6383\n",
      "Epoch 9/30\n",
      "3/3 [==============================] - 1s 643ms/step - loss: 0.7037 - accuracy: 0.7579 - val_loss: 0.7655 - val_accuracy: 0.6170\n",
      "Epoch 10/30\n",
      "3/3 [==============================] - 1s 645ms/step - loss: 0.6345 - accuracy: 0.7789 - val_loss: 0.7404 - val_accuracy: 0.6170\n",
      "Epoch 11/30\n",
      "3/3 [==============================] - 1s 639ms/step - loss: 0.6263 - accuracy: 0.7632 - val_loss: 0.7184 - val_accuracy: 0.5957\n",
      "Epoch 12/30\n",
      "3/3 [==============================] - 1s 648ms/step - loss: 0.5747 - accuracy: 0.7789 - val_loss: 0.6994 - val_accuracy: 0.5957\n",
      "Epoch 13/30\n",
      "3/3 [==============================] - 1s 653ms/step - loss: 0.5560 - accuracy: 0.8053 - val_loss: 0.6847 - val_accuracy: 0.5745\n",
      "Found 190 validated image filenames belonging to 3 classes.\n",
      "Found 47 validated image filenames belonging to 3 classes.\n",
      "Found 60 validated image filenames belonging to 3 classes.\n",
      "Found 190 validated image filenames belonging to 3 classes.\n",
      "Found 47 validated image filenames belonging to 3 classes.\n",
      "Found 60 validated image filenames belonging to 3 classes.\n",
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "AP(Mortise) (InputLayer)        [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Lateral (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "resnet50 (Functional)           (None, 2048)         23587712    AP(Mortise)[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "efficientnetb0 (Functional)     (None, 1280)         4049571     Lateral[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "AP_dense_128 (Dense)            (None, 128)          262272      resnet50[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Lateral_dense_128 (Dense)       (None, 128)          163968      efficientnetb0[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "AP_dense_50 (Dense)             (None, 50)           6450        AP_dense_128[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Lateral_dense_50 (Dense)        (None, 50)           6450        Lateral_dense_128[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "feature_fusion (Concatenate)    (None, 100)          0           AP_dense_50[0][0]                \n",
      "                                                                 Lateral_dense_50[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 100)          0           feature_fusion[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "output_layer (Dense)            (None, 3)            303         dropout_9[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 28,076,726\n",
      "Trainable params: 439,443\n",
      "Non-trainable params: 27,637,283\n",
      "__________________________________________________________________________________________________\n",
      "-------Training_concat1-------\n",
      "Epoch 1/30\n",
      "3/3 [==============================] - 6s 989ms/step - loss: 1.1690 - accuracy: 0.3211 - val_loss: 1.0287 - val_accuracy: 0.4894\n",
      "Epoch 2/30\n",
      "3/3 [==============================] - 1s 659ms/step - loss: 1.0304 - accuracy: 0.4947 - val_loss: 0.9632 - val_accuracy: 0.5106\n",
      "Epoch 3/30\n",
      "3/3 [==============================] - 1s 652ms/step - loss: 0.9480 - accuracy: 0.5263 - val_loss: 0.8910 - val_accuracy: 0.5532\n",
      "Epoch 4/30\n",
      "3/3 [==============================] - 1s 646ms/step - loss: 0.8711 - accuracy: 0.6263 - val_loss: 0.8428 - val_accuracy: 0.6170\n",
      "Epoch 5/30\n",
      "3/3 [==============================] - 1s 648ms/step - loss: 0.7957 - accuracy: 0.6895 - val_loss: 0.7984 - val_accuracy: 0.6383\n",
      "Epoch 6/30\n",
      "3/3 [==============================] - 2s 698ms/step - loss: 0.7697 - accuracy: 0.7000 - val_loss: 0.7549 - val_accuracy: 0.6383\n",
      "Epoch 7/30\n",
      "3/3 [==============================] - 2s 702ms/step - loss: 0.6974 - accuracy: 0.7526 - val_loss: 0.7221 - val_accuracy: 0.6596\n",
      "Epoch 8/30\n",
      "3/3 [==============================] - 1s 685ms/step - loss: 0.6841 - accuracy: 0.7684 - val_loss: 0.6972 - val_accuracy: 0.6809\n",
      "Epoch 9/30\n",
      "3/3 [==============================] - 1s 685ms/step - loss: 0.6246 - accuracy: 0.7579 - val_loss: 0.6799 - val_accuracy: 0.6596\n",
      "Epoch 10/30\n",
      "3/3 [==============================] - 1s 658ms/step - loss: 0.6018 - accuracy: 0.7842 - val_loss: 0.6634 - val_accuracy: 0.6596\n",
      "Epoch 11/30\n",
      "3/3 [==============================] - 1s 647ms/step - loss: 0.5799 - accuracy: 0.7895 - val_loss: 0.6472 - val_accuracy: 0.6809\n",
      "Epoch 12/30\n",
      "3/3 [==============================] - 1s 652ms/step - loss: 0.5534 - accuracy: 0.8263 - val_loss: 0.6345 - val_accuracy: 0.6809\n",
      "Epoch 13/30\n",
      "3/3 [==============================] - 1s 650ms/step - loss: 0.5355 - accuracy: 0.8211 - val_loss: 0.6260 - val_accuracy: 0.6596\n",
      "acc mean = 0.67, std = 0.06, test_acc = [0.65, 0.7, 0.73, 0.55, 0.7]\n",
      "f1  mean = 0.63, std = 0.08, test_f1 = [0.62, 0.68, 0.71, 0.49, 0.65]\n"
     ]
    }
   ],
   "source": [
    "# import\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path\n",
    "# import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import os\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from tensorflow.keras.layers import Input, Dense, Concatenate, Dropout\n",
    "import math\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "## label\n",
    "# =========================\n",
    "def class_2_type(root):\n",
    "    label = \"\"\n",
    "    if \"正常\" in root:\n",
    "        label = \"0\"\n",
    "    else:\n",
    "        label = \"1\"\n",
    "    return label\n",
    "\n",
    "def class_3_type(root):\n",
    "    label = \"\"\n",
    "    if \"正常\" in root:\n",
    "        label = \"0\"\n",
    "    elif \"雙踝\" in root:\n",
    "        label = \"1\"\n",
    "    elif \"三踝\" in root:\n",
    "        label = \"2\"\n",
    "    return label\n",
    "# =========================\n",
    "\n",
    "\n",
    "def load_path(path, class_count):\n",
    "    dataset = []\n",
    "    class_type = ''\n",
    "    if class_count == 2:\n",
    "        class_type = class_2_type\n",
    "    elif class_count == 3:\n",
    "        class_type = class_3_type  \n",
    "\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            label = class_type(root)\n",
    "            # if label != \"\":\n",
    "            dataset.append(\n",
    "                            {   \n",
    "                                'uuid': root.split(\"\\\\\")[-1],\n",
    "                                'label': label,\n",
    "                                'image_path': os.path.join(root, file)\n",
    "                            }\n",
    "                        )\n",
    "\n",
    "    return dataset\n",
    "\n",
    "def create_front_extract():\n",
    "    pretrained_model_chosen = tf.keras.applications.resnet50.ResNet50\n",
    "    pretrained_model = pretrained_model_chosen(\n",
    "        input_shape=(224, 224, 3),\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        pooling='avg')\n",
    "    pretrained_model.trainable = False\n",
    "    return pretrained_model\n",
    "\n",
    "def create_side_extract():\n",
    "    pretrained_model_chosen = tf.keras.applications.efficientnet.EfficientNetB0\n",
    "    pretrained_model = pretrained_model_chosen(\n",
    "        input_shape=(224, 224, 3),\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        pooling='avg')\n",
    "    pretrained_model.trainable = False\n",
    "    return pretrained_model\n",
    "\n",
    "def multi_input_generator(front_gen, side_gen):\n",
    "    while True:\n",
    "        front_batch, y1 = next(front_gen)\n",
    "        side_batch, y2 = next(side_gen)\n",
    "        assert (y1 == y2).all(), \"Label mismatch!\"  # 確保標籤一致\n",
    "        yield ([front_batch, side_batch], y1)\n",
    "\n",
    "\n",
    "# def train_cross_validation(image_dir, n_splits=5, class_count=2, maru_part=None,  chosen_model='resnet50'):\n",
    "def train_cross_validation(image_dir, n_splits=5, class_count=2):\n",
    "\n",
    "\n",
    "    ## load data and  labels\n",
    "    # =========================\n",
    "    labels = []\n",
    "    filepaths = []\n",
    "    data = load_path(image_dir, class_count)\n",
    "    for row in data:\n",
    "        labels.append(row['label'])\n",
    "        filepaths.append(row['image_path'])\n",
    "\n",
    "    filepaths = pd.Series(filepaths, name='Filepath').astype(str)\n",
    "    labels = pd.Series(labels, name='Label')\n",
    "\n",
    "    images = pd.concat([filepaths, labels], axis=1)\n",
    "    # =========================\n",
    "\n",
    "    ## split image\n",
    "    # =========================\n",
    "    train_df_front, test_df_front = train_test_split(images, train_size=0.8, shuffle=True, random_state=1, stratify=images['Label'])\n",
    "    print(\"Training set label distribution:\\n\", train_df_front['Label'].value_counts(normalize=False))\n",
    "    print(\"Test set label distribution:\\n\", test_df_front['Label'].value_counts(normalize=False))\n",
    "    # =========================\n",
    "\n",
    "    preprocessing_function_chosen_front = tf.keras.applications.resnet50.preprocess_input\n",
    "    preprocessing_function_chosen_side = tf.keras.applications.efficientnet.preprocess_input\n",
    "\n",
    "\n",
    "    ## train model, k fold cross validation\n",
    "    # ==================================================\n",
    "    fold_no = 1\n",
    "    test_acc = []\n",
    "    test_f1 = []\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=1)\n",
    "    for train_index, val_index in kfold.split(train_df_front, train_df_front['Label']):\n",
    "        k_fold_train_front = train_df_front.iloc[train_index]\n",
    "        k_fold_val_front = train_df_front.iloc[val_index]\n",
    "\n",
    "        # front images\n",
    "        # =========================\n",
    "        train_generator_front = tf.keras.preprocessing.image.ImageDataGenerator(horizontal_flip=False,\n",
    "                                                                                preprocessing_function=preprocessing_function_chosen_front)\n",
    "        test_generator_front = tf.keras.preprocessing.image.ImageDataGenerator(preprocessing_function=preprocessing_function_chosen_front)\n",
    "\n",
    "        train_images_front = train_generator_front.flow_from_dataframe(\n",
    "            dataframe=k_fold_train_front,\n",
    "            x_col='Filepath',\n",
    "            y_col='Label',\n",
    "            target_size=(224, 224),\n",
    "            color_mode='rgb',\n",
    "            class_mode='categorical',\n",
    "            batch_size=64,\n",
    "            shuffle=False,\n",
    "            seed=42\n",
    "        )\n",
    "\n",
    "        val_images_front = train_generator_front.flow_from_dataframe(\n",
    "            dataframe=k_fold_val_front,\n",
    "            x_col='Filepath',\n",
    "            y_col='Label',\n",
    "            target_size=(224, 224),\n",
    "            color_mode='rgb',\n",
    "            class_mode='categorical',\n",
    "            batch_size=64,\n",
    "            shuffle=False,\n",
    "            seed=42\n",
    "        )\n",
    "\n",
    "        test_images_front = test_generator_front.flow_from_dataframe(\n",
    "            dataframe=test_df_front,\n",
    "            x_col='Filepath',\n",
    "            y_col='Label',\n",
    "            target_size=(224, 224),\n",
    "            color_mode='rgb',\n",
    "            class_mode='categorical',\n",
    "            batch_size=32,\n",
    "            shuffle=False\n",
    "        )\n",
    "        # =========================   \n",
    "\n",
    "        # side images\n",
    "        # =========================\n",
    "        train_df_side = train_df_front.copy()\n",
    "        test_df_side = test_df_front.copy()\n",
    "        train_df_side.loc[:, \"Filepath\"] = train_df_front[\"Filepath\"].str.replace(\"front\", \"side\")\n",
    "        test_df_side.loc[:, \"Filepath\"] = test_df_side[\"Filepath\"].str.replace(\"front\", \"side\")\n",
    "\n",
    "        k_fold_train_side = train_df_side.iloc[train_index]\n",
    "        k_fold_val_side = train_df_side.iloc[val_index]\n",
    "\n",
    "        train_generator_side = tf.keras.preprocessing.image.ImageDataGenerator(horizontal_flip=False,\n",
    "                                                                                preprocessing_function=preprocessing_function_chosen_side)\n",
    "        test_generator_side = tf.keras.preprocessing.image.ImageDataGenerator(preprocessing_function=preprocessing_function_chosen_side)\n",
    "\n",
    "        train_images_side = train_generator_side.flow_from_dataframe(\n",
    "            dataframe=k_fold_train_side,\n",
    "            x_col='Filepath',\n",
    "            y_col='Label',\n",
    "            target_size=(224, 224),\n",
    "            color_mode='rgb',\n",
    "            class_mode='categorical',\n",
    "            batch_size=64,\n",
    "            shuffle=False,\n",
    "            seed=42\n",
    "        )\n",
    "\n",
    "        val_images_side = train_generator_side.flow_from_dataframe(\n",
    "            dataframe=k_fold_val_side,\n",
    "            x_col='Filepath',\n",
    "            y_col='Label',\n",
    "            target_size=(224, 224),\n",
    "            color_mode='rgb',\n",
    "            class_mode='categorical',\n",
    "            batch_size=64,\n",
    "            shuffle=False,\n",
    "            seed=42\n",
    "        )\n",
    "\n",
    "        test_images_side = test_generator_side.flow_from_dataframe(\n",
    "            dataframe=test_df_side,\n",
    "            x_col='Filepath',\n",
    "            y_col='Label',\n",
    "            target_size=(224, 224),\n",
    "            color_mode='rgb',\n",
    "            class_mode='categorical',\n",
    "            batch_size=32,\n",
    "            shuffle=False\n",
    "        )\n",
    "        # ========================= \n",
    "        \n",
    "        # load model\n",
    "        # =========================\n",
    "        # input \n",
    "        input_front = Input(shape=(224, 224, 3), name=\"AP(Mortise)\")\n",
    "        input_side = Input(shape=(224, 224, 3), name=\"Lateral\")\n",
    "\n",
    "        # model\n",
    "        model_front = create_front_extract()\n",
    "        model_side = create_side_extract()\n",
    "\n",
    "        features_front = model_front(input_front)\n",
    "        features_side = model_side(input_side)\n",
    "\n",
    "        features_front_x = tf.keras.layers.Dense(128, activation='relu', name='AP_dense_128')(features_front)\n",
    "        features_front_x = tf.keras.layers.Dense(50, activation='relu', name='AP_dense_50')(features_front_x)\n",
    "\n",
    "        features_side_x = tf.keras.layers.Dense(128, activation='relu', name='Lateral_dense_128')(features_side)\n",
    "        features_side_x = tf.keras.layers.Dense(50, activation='relu', name='Lateral_dense_50')(features_side_x)\n",
    "\n",
    "        fused_features = Concatenate(name=\"feature_fusion\")([features_front_x, features_side_x])\n",
    "        # fused_features = tf.keras.layers.Dense(50, activation='relu', name='fusion_dense_50')(fused_features)\n",
    "        fused_features = Dropout(0.1)(fused_features)\n",
    "\n",
    "        final_output = Dense(class_count, activation='sigmoid', name='output_layer')(fused_features)\n",
    "        multi_view_model = None\n",
    "        multi_view_model = Model(\n",
    "            inputs=[input_front, input_side],\n",
    "            outputs=final_output\n",
    "        )\n",
    "        multi_view_model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        multi_view_model.summary()\n",
    "        # print(model.summary())\n",
    "        # =========================\n",
    "\n",
    "        train_generator = multi_input_generator(train_images_front, train_images_side)\n",
    "        val_generator = multi_input_generator(val_images_front, val_images_side)\n",
    "        \n",
    "        ## compile and evaluate\n",
    "        # =========================\n",
    "\n",
    "        print(\"-------Training_\" + concat_type + \"-------\")\n",
    "        multi_view_model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "        batch_size = 64\n",
    "        ## early stop \n",
    "        early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\n",
    "        multi_view_model.fit(train_generator, validation_data=val_generator, callbacks=[early_stopping], epochs=30,\n",
    "                                    steps_per_epoch= math.ceil(train_images_front.samples / batch_size), \n",
    "                                    validation_steps= math.ceil(val_images_front.samples / batch_size))\n",
    "        ## no early stop\n",
    "        # multi_view_model.fit(train_generator, validation_data=val_generator, epochs=30,\n",
    "        #                     steps_per_epoch= math.ceil(train_images_front.samples / batch_size), \n",
    "        #                     validation_steps= math.ceil(val_images_front.samples / batch_size))\n",
    "\n",
    "        # =========================\n",
    "\n",
    "        test_generator = multi_input_generator(test_images_front, test_images_side)\n",
    "        batch_size=32\n",
    "        pred = multi_view_model.predict(test_generator,  steps=math.ceil(test_images_front.samples / batch_size))\n",
    "        predicted_labels = np.argmax(pred, axis=1)\n",
    "\n",
    "        # =========================\n",
    "            \n",
    "        ## print results\n",
    "        # =========================\n",
    "        acc = accuracy_score(test_images_front.labels, predicted_labels)\n",
    "\n",
    "        test_acc.append(np.round(acc, 2))\n",
    "        f1 = f1_score(test_images_front.labels, predicted_labels, average='macro')\n",
    "        test_f1.append(np.round(f1, 2))\n",
    "        fold_no += 1\n",
    "        # =========================\n",
    "    # ==================================================\n",
    "        \n",
    "    ## print  mean results\n",
    "    # =========================\n",
    "    acc_mean  = np.round(np.mean(test_acc), 2)\n",
    "    acc_std = np.round(np.std(test_acc), 2)\n",
    "    f1_mean  = np.round(np.mean(test_f1), 2)\n",
    "    f1_std = np.round(np.std(test_f1), 2)\n",
    "    # print(f\"acc mean = {acc_mean}, std = {acc_std}\")\n",
    "    # print(test_acc)\n",
    "    # print(f\"f1  mean = {f1_mean}, std = {f1_std}\")\n",
    "    # print(test_f1)\n",
    "    # =========================\n",
    "\n",
    "    return {'acc_mean':acc_mean, 'acc_std':acc_std, 'test_acc':test_acc, 'f1_mean':f1_mean, 'f1_std':f1_std, 'test_f1':test_f1}\n",
    "\n",
    "\n",
    "\n",
    "# =========================\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "results = []\n",
    "results = train_cross_validation(image_dir=path, class_count=3)\n",
    "\n",
    "\n",
    "print(f\"acc mean = {results['acc_mean']}, std = {results['acc_std']}, test_acc = {results['test_acc']}\")\n",
    "print(f\"f1  mean = {results['f1_mean']}, std = {results['f1_std']}, test_f1 = {results['test_f1']}\")\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set label distribution:\n",
      " 0    101\n",
      "2     69\n",
      "1     67\n",
      "Name: Label, dtype: int64\n",
      "Test set label distribution:\n",
      " 0    25\n",
      "2    18\n",
      "1    17\n",
      "Name: Label, dtype: int64\n",
      "Found 189 validated image filenames belonging to 3 classes.\n",
      "Found 48 validated image filenames belonging to 3 classes.\n",
      "Found 60 validated image filenames belonging to 3 classes.\n",
      "Found 189 validated image filenames belonging to 3 classes.\n",
      "Found 48 validated image filenames belonging to 3 classes.\n",
      "Found 60 validated image filenames belonging to 3 classes.\n",
      "Model: \"model_10\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "AP(Mortise) (InputLayer)        [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Lateral (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "resnet50 (Functional)           (None, 2048)         23587712    AP(Mortise)[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "efficientnetb0 (Functional)     (None, 1280)         4049571     Lateral[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "AP_dense_128 (Dense)            (None, 128)          262272      resnet50[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Lateral_dense_128 (Dense)       (None, 128)          163968      efficientnetb0[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "AP_dense_50 (Dense)             (None, 50)           6450        AP_dense_128[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Lateral_dense_50 (Dense)        (None, 50)           6450        Lateral_dense_128[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "feature_fusion (Concatenate)    (None, 100)          0           AP_dense_50[0][0]                \n",
      "                                                                 Lateral_dense_50[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 100)          0           feature_fusion[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "output_layer (Dense)            (None, 3)            303         dropout_10[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 28,076,726\n",
      "Trainable params: 439,443\n",
      "Non-trainable params: 27,637,283\n",
      "__________________________________________________________________________________________________\n",
      "-------Training_concat1-------\n",
      "Epoch 1/30\n",
      "3/3 [==============================] - 6s 985ms/step - loss: 1.2253 - accuracy: 0.3545 - val_loss: 0.9707 - val_accuracy: 0.4792\n",
      "Epoch 2/30\n",
      "3/3 [==============================] - 1s 651ms/step - loss: 1.0199 - accuracy: 0.4815 - val_loss: 0.8984 - val_accuracy: 0.5833\n",
      "Epoch 3/30\n",
      "3/3 [==============================] - 1s 656ms/step - loss: 0.9452 - accuracy: 0.5661 - val_loss: 0.8342 - val_accuracy: 0.6667\n",
      "Epoch 4/30\n",
      "3/3 [==============================] - 1s 646ms/step - loss: 0.8687 - accuracy: 0.6138 - val_loss: 0.7785 - val_accuracy: 0.7292\n",
      "Epoch 5/30\n",
      "3/3 [==============================] - 1s 638ms/step - loss: 0.7893 - accuracy: 0.7249 - val_loss: 0.7413 - val_accuracy: 0.7083\n",
      "Epoch 6/30\n",
      "3/3 [==============================] - 1s 638ms/step - loss: 0.7496 - accuracy: 0.7249 - val_loss: 0.7002 - val_accuracy: 0.7083\n",
      "Epoch 7/30\n",
      "3/3 [==============================] - 1s 641ms/step - loss: 0.7039 - accuracy: 0.7354 - val_loss: 0.6498 - val_accuracy: 0.7083\n",
      "Epoch 8/30\n",
      "3/3 [==============================] - 1s 649ms/step - loss: 0.6728 - accuracy: 0.6931 - val_loss: 0.6092 - val_accuracy: 0.7500\n",
      "Epoch 9/30\n",
      "3/3 [==============================] - 1s 631ms/step - loss: 0.5949 - accuracy: 0.7884 - val_loss: 0.5807 - val_accuracy: 0.7500\n",
      "Epoch 10/30\n",
      "3/3 [==============================] - 1s 632ms/step - loss: 0.5799 - accuracy: 0.7725 - val_loss: 0.5595 - val_accuracy: 0.7292\n",
      "Epoch 11/30\n",
      "3/3 [==============================] - 1s 639ms/step - loss: 0.5561 - accuracy: 0.7778 - val_loss: 0.5424 - val_accuracy: 0.7708\n",
      "Epoch 12/30\n",
      "3/3 [==============================] - 1s 636ms/step - loss: 0.5228 - accuracy: 0.7672 - val_loss: 0.5242 - val_accuracy: 0.7708\n",
      "Epoch 13/30\n",
      "3/3 [==============================] - 1s 635ms/step - loss: 0.5194 - accuracy: 0.7884 - val_loss: 0.5063 - val_accuracy: 0.7708\n",
      "Epoch 14/30\n",
      "3/3 [==============================] - 1s 640ms/step - loss: 0.4849 - accuracy: 0.8148 - val_loss: 0.4917 - val_accuracy: 0.8125\n",
      "Epoch 15/30\n",
      "3/3 [==============================] - 1s 634ms/step - loss: 0.4425 - accuracy: 0.8466 - val_loss: 0.4801 - val_accuracy: 0.8125\n",
      "Epoch 16/30\n",
      "3/3 [==============================] - 1s 639ms/step - loss: 0.4371 - accuracy: 0.8201 - val_loss: 0.4711 - val_accuracy: 0.8125\n",
      "Epoch 17/30\n",
      "3/3 [==============================] - 1s 641ms/step - loss: 0.4397 - accuracy: 0.8254 - val_loss: 0.4597 - val_accuracy: 0.8125\n",
      "Epoch 18/30\n",
      "3/3 [==============================] - 1s 644ms/step - loss: 0.4169 - accuracy: 0.8730 - val_loss: 0.4494 - val_accuracy: 0.8125\n",
      "Epoch 19/30\n",
      "3/3 [==============================] - 1s 639ms/step - loss: 0.3871 - accuracy: 0.8783 - val_loss: 0.4431 - val_accuracy: 0.8125\n",
      "Epoch 20/30\n",
      "3/3 [==============================] - 1s 639ms/step - loss: 0.3779 - accuracy: 0.8783 - val_loss: 0.4385 - val_accuracy: 0.8125\n",
      "Epoch 21/30\n",
      "3/3 [==============================] - 1s 641ms/step - loss: 0.3800 - accuracy: 0.8519 - val_loss: 0.4329 - val_accuracy: 0.8125\n",
      "Epoch 22/30\n",
      "3/3 [==============================] - 1s 638ms/step - loss: 0.3587 - accuracy: 0.8889 - val_loss: 0.4284 - val_accuracy: 0.7917\n",
      "Epoch 23/30\n",
      "3/3 [==============================] - 1s 633ms/step - loss: 0.3405 - accuracy: 0.8889 - val_loss: 0.4247 - val_accuracy: 0.8125\n",
      "Epoch 24/30\n",
      "3/3 [==============================] - 1s 651ms/step - loss: 0.3270 - accuracy: 0.9206 - val_loss: 0.4229 - val_accuracy: 0.8125\n",
      "Found 189 validated image filenames belonging to 3 classes.\n",
      "Found 48 validated image filenames belonging to 3 classes.\n",
      "Found 60 validated image filenames belonging to 3 classes.\n",
      "Found 189 validated image filenames belonging to 3 classes.\n",
      "Found 48 validated image filenames belonging to 3 classes.\n",
      "Found 60 validated image filenames belonging to 3 classes.\n",
      "Model: \"model_11\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "AP(Mortise) (InputLayer)        [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Lateral (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "resnet50 (Functional)           (None, 2048)         23587712    AP(Mortise)[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "efficientnetb0 (Functional)     (None, 1280)         4049571     Lateral[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "AP_dense_128 (Dense)            (None, 128)          262272      resnet50[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Lateral_dense_128 (Dense)       (None, 128)          163968      efficientnetb0[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "AP_dense_50 (Dense)             (None, 50)           6450        AP_dense_128[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Lateral_dense_50 (Dense)        (None, 50)           6450        Lateral_dense_128[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "feature_fusion (Concatenate)    (None, 100)          0           AP_dense_50[0][0]                \n",
      "                                                                 Lateral_dense_50[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 100)          0           feature_fusion[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "output_layer (Dense)            (None, 3)            303         dropout_11[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 28,076,726\n",
      "Trainable params: 439,443\n",
      "Non-trainable params: 27,637,283\n",
      "__________________________________________________________________________________________________\n",
      "-------Training_concat1-------\n",
      "Epoch 1/30\n",
      "3/3 [==============================] - 5s 1s/step - loss: 1.2733 - accuracy: 0.3122 - val_loss: 1.0078 - val_accuracy: 0.5417\n",
      "Epoch 2/30\n",
      "3/3 [==============================] - 1s 617ms/step - loss: 1.0057 - accuracy: 0.4656 - val_loss: 0.9803 - val_accuracy: 0.4792\n",
      "Epoch 3/30\n",
      "3/3 [==============================] - 1s 647ms/step - loss: 0.9473 - accuracy: 0.5397 - val_loss: 0.9372 - val_accuracy: 0.5208\n",
      "Epoch 4/30\n",
      "3/3 [==============================] - 1s 644ms/step - loss: 0.8835 - accuracy: 0.6243 - val_loss: 0.8301 - val_accuracy: 0.6458\n",
      "Epoch 5/30\n",
      "3/3 [==============================] - 1s 633ms/step - loss: 0.7853 - accuracy: 0.6720 - val_loss: 0.7456 - val_accuracy: 0.6667\n",
      "Epoch 6/30\n",
      "3/3 [==============================] - 1s 635ms/step - loss: 0.7425 - accuracy: 0.7037 - val_loss: 0.6949 - val_accuracy: 0.6458\n",
      "Epoch 7/30\n",
      "3/3 [==============================] - 1s 636ms/step - loss: 0.6771 - accuracy: 0.7566 - val_loss: 0.6663 - val_accuracy: 0.6875\n",
      "Epoch 8/30\n",
      "3/3 [==============================] - 1s 637ms/step - loss: 0.6482 - accuracy: 0.7566 - val_loss: 0.6389 - val_accuracy: 0.6875\n",
      "Epoch 9/30\n",
      "3/3 [==============================] - 1s 636ms/step - loss: 0.6112 - accuracy: 0.7566 - val_loss: 0.6046 - val_accuracy: 0.6458\n",
      "Epoch 10/30\n",
      "3/3 [==============================] - 1s 635ms/step - loss: 0.5605 - accuracy: 0.7619 - val_loss: 0.5748 - val_accuracy: 0.6875\n",
      "Epoch 11/30\n",
      "3/3 [==============================] - 1s 631ms/step - loss: 0.5569 - accuracy: 0.7672 - val_loss: 0.5530 - val_accuracy: 0.7083\n",
      "Epoch 12/30\n",
      "3/3 [==============================] - 1s 637ms/step - loss: 0.5202 - accuracy: 0.7831 - val_loss: 0.5362 - val_accuracy: 0.7292\n",
      "Epoch 13/30\n",
      "3/3 [==============================] - 1s 631ms/step - loss: 0.5076 - accuracy: 0.8042 - val_loss: 0.5233 - val_accuracy: 0.7500\n",
      "Epoch 14/30\n",
      "3/3 [==============================] - 1s 643ms/step - loss: 0.4708 - accuracy: 0.8571 - val_loss: 0.5100 - val_accuracy: 0.7500\n",
      "Epoch 15/30\n",
      "3/3 [==============================] - 1s 640ms/step - loss: 0.4562 - accuracy: 0.8254 - val_loss: 0.4983 - val_accuracy: 0.7500\n",
      "Epoch 16/30\n",
      "3/3 [==============================] - 1s 636ms/step - loss: 0.4601 - accuracy: 0.8307 - val_loss: 0.4903 - val_accuracy: 0.7500\n",
      "Epoch 17/30\n",
      "3/3 [==============================] - 1s 641ms/step - loss: 0.4216 - accuracy: 0.8571 - val_loss: 0.4830 - val_accuracy: 0.7917\n",
      "Epoch 18/30\n",
      "3/3 [==============================] - 1s 637ms/step - loss: 0.4271 - accuracy: 0.8519 - val_loss: 0.4764 - val_accuracy: 0.7917\n",
      "Epoch 19/30\n",
      "3/3 [==============================] - 1s 634ms/step - loss: 0.4033 - accuracy: 0.8519 - val_loss: 0.4706 - val_accuracy: 0.7500\n",
      "Epoch 20/30\n",
      "3/3 [==============================] - 1s 627ms/step - loss: 0.3778 - accuracy: 0.8836 - val_loss: 0.4643 - val_accuracy: 0.7500\n",
      "Epoch 21/30\n",
      "3/3 [==============================] - 1s 632ms/step - loss: 0.3777 - accuracy: 0.8413 - val_loss: 0.4606 - val_accuracy: 0.7708\n",
      "Epoch 22/30\n",
      "3/3 [==============================] - 1s 632ms/step - loss: 0.3633 - accuracy: 0.8836 - val_loss: 0.4588 - val_accuracy: 0.7500\n",
      "Epoch 23/30\n",
      "3/3 [==============================] - 1s 633ms/step - loss: 0.3557 - accuracy: 0.8889 - val_loss: 0.4524 - val_accuracy: 0.7708\n",
      "Epoch 24/30\n",
      "3/3 [==============================] - 1s 636ms/step - loss: 0.3405 - accuracy: 0.8995 - val_loss: 0.4478 - val_accuracy: 0.7708\n",
      "Epoch 25/30\n",
      "3/3 [==============================] - 1s 634ms/step - loss: 0.3386 - accuracy: 0.8942 - val_loss: 0.4407 - val_accuracy: 0.7708\n",
      "Epoch 26/30\n",
      "3/3 [==============================] - 1s 637ms/step - loss: 0.3114 - accuracy: 0.9365 - val_loss: 0.4328 - val_accuracy: 0.7708\n",
      "Epoch 27/30\n",
      "3/3 [==============================] - 1s 632ms/step - loss: 0.2960 - accuracy: 0.8995 - val_loss: 0.4270 - val_accuracy: 0.7917\n",
      "Found 190 validated image filenames belonging to 3 classes.\n",
      "Found 47 validated image filenames belonging to 3 classes.\n",
      "Found 60 validated image filenames belonging to 3 classes.\n",
      "Found 190 validated image filenames belonging to 3 classes.\n",
      "Found 47 validated image filenames belonging to 3 classes.\n",
      "Found 60 validated image filenames belonging to 3 classes.\n",
      "Model: \"model_12\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "AP(Mortise) (InputLayer)        [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Lateral (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "resnet50 (Functional)           (None, 2048)         23587712    AP(Mortise)[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "efficientnetb0 (Functional)     (None, 1280)         4049571     Lateral[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "AP_dense_128 (Dense)            (None, 128)          262272      resnet50[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Lateral_dense_128 (Dense)       (None, 128)          163968      efficientnetb0[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "AP_dense_50 (Dense)             (None, 50)           6450        AP_dense_128[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Lateral_dense_50 (Dense)        (None, 50)           6450        Lateral_dense_128[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "feature_fusion (Concatenate)    (None, 100)          0           AP_dense_50[0][0]                \n",
      "                                                                 Lateral_dense_50[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 100)          0           feature_fusion[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "output_layer (Dense)            (None, 3)            303         dropout_12[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 28,076,726\n",
      "Trainable params: 439,443\n",
      "Non-trainable params: 27,637,283\n",
      "__________________________________________________________________________________________________\n",
      "-------Training_concat1-------\n",
      "Epoch 1/30\n",
      "3/3 [==============================] - 5s 1s/step - loss: 1.6740 - accuracy: 0.2842 - val_loss: 1.4046 - val_accuracy: 0.2553\n",
      "Epoch 2/30\n",
      "3/3 [==============================] - 1s 665ms/step - loss: 1.3014 - accuracy: 0.3000 - val_loss: 1.1978 - val_accuracy: 0.2340\n",
      "Epoch 3/30\n",
      "3/3 [==============================] - 1s 656ms/step - loss: 1.1299 - accuracy: 0.3474 - val_loss: 1.1397 - val_accuracy: 0.4681\n",
      "Epoch 4/30\n",
      "3/3 [==============================] - 1s 660ms/step - loss: 1.0785 - accuracy: 0.4579 - val_loss: 1.1186 - val_accuracy: 0.4255\n",
      "Epoch 5/30\n",
      "3/3 [==============================] - 1s 654ms/step - loss: 1.0462 - accuracy: 0.4684 - val_loss: 1.0759 - val_accuracy: 0.4255\n",
      "Epoch 6/30\n",
      "3/3 [==============================] - 1s 666ms/step - loss: 0.9332 - accuracy: 0.4947 - val_loss: 1.0208 - val_accuracy: 0.4468\n",
      "Epoch 7/30\n",
      "3/3 [==============================] - 1s 656ms/step - loss: 0.9074 - accuracy: 0.5684 - val_loss: 0.9798 - val_accuracy: 0.4681\n",
      "Epoch 8/30\n",
      "3/3 [==============================] - 1s 657ms/step - loss: 0.8629 - accuracy: 0.6474 - val_loss: 0.9558 - val_accuracy: 0.4894\n",
      "Epoch 9/30\n",
      "3/3 [==============================] - 1s 656ms/step - loss: 0.8248 - accuracy: 0.6789 - val_loss: 0.9273 - val_accuracy: 0.4681\n",
      "Epoch 10/30\n",
      "3/3 [==============================] - 1s 646ms/step - loss: 0.7754 - accuracy: 0.7211 - val_loss: 0.8897 - val_accuracy: 0.5106\n",
      "Epoch 11/30\n",
      "3/3 [==============================] - 1s 659ms/step - loss: 0.7163 - accuracy: 0.7368 - val_loss: 0.8570 - val_accuracy: 0.4894\n",
      "Epoch 12/30\n",
      "3/3 [==============================] - 1s 655ms/step - loss: 0.6800 - accuracy: 0.7737 - val_loss: 0.8309 - val_accuracy: 0.5106\n",
      "Epoch 13/30\n",
      "3/3 [==============================] - 1s 646ms/step - loss: 0.6472 - accuracy: 0.7789 - val_loss: 0.8066 - val_accuracy: 0.5319\n",
      "Epoch 14/30\n",
      "3/3 [==============================] - 1s 653ms/step - loss: 0.6370 - accuracy: 0.7684 - val_loss: 0.7855 - val_accuracy: 0.5957\n",
      "Epoch 15/30\n",
      "3/3 [==============================] - 1s 653ms/step - loss: 0.5841 - accuracy: 0.8421 - val_loss: 0.7682 - val_accuracy: 0.5957\n",
      "Epoch 16/30\n",
      "3/3 [==============================] - 1s 650ms/step - loss: 0.5466 - accuracy: 0.8789 - val_loss: 0.7503 - val_accuracy: 0.5957\n",
      "Epoch 17/30\n",
      "3/3 [==============================] - 1s 650ms/step - loss: 0.5581 - accuracy: 0.8053 - val_loss: 0.7332 - val_accuracy: 0.5957\n",
      "Epoch 18/30\n",
      "3/3 [==============================] - 1s 654ms/step - loss: 0.5181 - accuracy: 0.8000 - val_loss: 0.7197 - val_accuracy: 0.5957\n",
      "Epoch 19/30\n",
      "3/3 [==============================] - 1s 654ms/step - loss: 0.5048 - accuracy: 0.8526 - val_loss: 0.7081 - val_accuracy: 0.6170\n",
      "Epoch 20/30\n",
      "3/3 [==============================] - 1s 655ms/step - loss: 0.4814 - accuracy: 0.8579 - val_loss: 0.7002 - val_accuracy: 0.6170\n",
      "Epoch 21/30\n",
      "3/3 [==============================] - 1s 647ms/step - loss: 0.4670 - accuracy: 0.8526 - val_loss: 0.6918 - val_accuracy: 0.6170\n",
      "Epoch 22/30\n",
      "3/3 [==============================] - 1s 651ms/step - loss: 0.4396 - accuracy: 0.8632 - val_loss: 0.6827 - val_accuracy: 0.5957\n",
      "Epoch 23/30\n",
      "3/3 [==============================] - 1s 654ms/step - loss: 0.4374 - accuracy: 0.8579 - val_loss: 0.6768 - val_accuracy: 0.6170\n",
      "Epoch 24/30\n",
      "3/3 [==============================] - 1s 657ms/step - loss: 0.4188 - accuracy: 0.8895 - val_loss: 0.6735 - val_accuracy: 0.6170\n",
      "Epoch 25/30\n",
      "3/3 [==============================] - 1s 654ms/step - loss: 0.4144 - accuracy: 0.8684 - val_loss: 0.6715 - val_accuracy: 0.6170\n",
      "Epoch 26/30\n",
      "3/3 [==============================] - 1s 640ms/step - loss: 0.3764 - accuracy: 0.8789 - val_loss: 0.6667 - val_accuracy: 0.6383\n",
      "Epoch 27/30\n",
      "3/3 [==============================] - 1s 643ms/step - loss: 0.3907 - accuracy: 0.8842 - val_loss: 0.6599 - val_accuracy: 0.6383\n",
      "Epoch 28/30\n",
      "3/3 [==============================] - 1s 647ms/step - loss: 0.3674 - accuracy: 0.8895 - val_loss: 0.6516 - val_accuracy: 0.6596\n",
      "Epoch 29/30\n",
      "3/3 [==============================] - 1s 648ms/step - loss: 0.3683 - accuracy: 0.8789 - val_loss: 0.6445 - val_accuracy: 0.6596\n",
      "Epoch 30/30\n",
      "3/3 [==============================] - 1s 645ms/step - loss: 0.3523 - accuracy: 0.8895 - val_loss: 0.6401 - val_accuracy: 0.6383\n",
      "Found 190 validated image filenames belonging to 3 classes.\n",
      "Found 47 validated image filenames belonging to 3 classes.\n",
      "Found 60 validated image filenames belonging to 3 classes.\n",
      "Found 190 validated image filenames belonging to 3 classes.\n",
      "Found 47 validated image filenames belonging to 3 classes.\n",
      "Found 60 validated image filenames belonging to 3 classes.\n",
      "Model: \"model_13\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "AP(Mortise) (InputLayer)        [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Lateral (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "resnet50 (Functional)           (None, 2048)         23587712    AP(Mortise)[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "efficientnetb0 (Functional)     (None, 1280)         4049571     Lateral[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "AP_dense_128 (Dense)            (None, 128)          262272      resnet50[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Lateral_dense_128 (Dense)       (None, 128)          163968      efficientnetb0[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "AP_dense_50 (Dense)             (None, 50)           6450        AP_dense_128[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Lateral_dense_50 (Dense)        (None, 50)           6450        Lateral_dense_128[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "feature_fusion (Concatenate)    (None, 100)          0           AP_dense_50[0][0]                \n",
      "                                                                 Lateral_dense_50[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 100)          0           feature_fusion[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "output_layer (Dense)            (None, 3)            303         dropout_13[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 28,076,726\n",
      "Trainable params: 439,443\n",
      "Non-trainable params: 27,637,283\n",
      "__________________________________________________________________________________________________\n",
      "-------Training_concat1-------\n",
      "Epoch 1/30\n",
      "3/3 [==============================] - 5s 1s/step - loss: 1.5736 - accuracy: 0.3053 - val_loss: 1.2660 - val_accuracy: 0.4043\n",
      "Epoch 2/30\n",
      "3/3 [==============================] - 1s 651ms/step - loss: 1.2056 - accuracy: 0.4737 - val_loss: 1.0642 - val_accuracy: 0.4255\n",
      "Epoch 3/30\n",
      "3/3 [==============================] - 1s 662ms/step - loss: 1.0302 - accuracy: 0.4737 - val_loss: 1.0219 - val_accuracy: 0.4468\n",
      "Epoch 4/30\n",
      "3/3 [==============================] - 1s 651ms/step - loss: 0.9913 - accuracy: 0.5000 - val_loss: 0.9968 - val_accuracy: 0.5745\n",
      "Epoch 5/30\n",
      "3/3 [==============================] - 1s 657ms/step - loss: 0.9547 - accuracy: 0.6158 - val_loss: 0.9374 - val_accuracy: 0.5957\n",
      "Epoch 6/30\n",
      "3/3 [==============================] - 1s 641ms/step - loss: 0.8942 - accuracy: 0.6579 - val_loss: 0.8781 - val_accuracy: 0.6170\n",
      "Epoch 7/30\n",
      "3/3 [==============================] - 1s 649ms/step - loss: 0.8138 - accuracy: 0.7053 - val_loss: 0.8438 - val_accuracy: 0.7234\n",
      "Epoch 8/30\n",
      "3/3 [==============================] - 1s 645ms/step - loss: 0.8010 - accuracy: 0.6947 - val_loss: 0.8184 - val_accuracy: 0.7021\n",
      "Epoch 9/30\n",
      "3/3 [==============================] - 1s 644ms/step - loss: 0.7514 - accuracy: 0.7000 - val_loss: 0.7924 - val_accuracy: 0.7021\n",
      "Epoch 10/30\n",
      "3/3 [==============================] - 1s 652ms/step - loss: 0.7244 - accuracy: 0.7000 - val_loss: 0.7653 - val_accuracy: 0.7021\n",
      "Epoch 11/30\n",
      "3/3 [==============================] - 1s 647ms/step - loss: 0.6770 - accuracy: 0.7368 - val_loss: 0.7402 - val_accuracy: 0.6596\n",
      "Epoch 12/30\n",
      "3/3 [==============================] - 1s 650ms/step - loss: 0.6432 - accuracy: 0.7474 - val_loss: 0.7194 - val_accuracy: 0.6809\n",
      "Epoch 13/30\n",
      "3/3 [==============================] - 1s 650ms/step - loss: 0.6259 - accuracy: 0.7579 - val_loss: 0.6991 - val_accuracy: 0.6809\n",
      "Epoch 14/30\n",
      "3/3 [==============================] - 1s 648ms/step - loss: 0.5790 - accuracy: 0.8211 - val_loss: 0.6788 - val_accuracy: 0.7021\n",
      "Epoch 15/30\n",
      "3/3 [==============================] - 1s 649ms/step - loss: 0.5749 - accuracy: 0.8053 - val_loss: 0.6627 - val_accuracy: 0.7021\n",
      "Epoch 16/30\n",
      "3/3 [==============================] - 1s 646ms/step - loss: 0.5332 - accuracy: 0.8474 - val_loss: 0.6483 - val_accuracy: 0.7234\n",
      "Epoch 17/30\n",
      "3/3 [==============================] - 1s 644ms/step - loss: 0.5271 - accuracy: 0.8263 - val_loss: 0.6355 - val_accuracy: 0.7021\n",
      "Found 190 validated image filenames belonging to 3 classes.\n",
      "Found 47 validated image filenames belonging to 3 classes.\n",
      "Found 60 validated image filenames belonging to 3 classes.\n",
      "Found 190 validated image filenames belonging to 3 classes.\n",
      "Found 47 validated image filenames belonging to 3 classes.\n",
      "Found 60 validated image filenames belonging to 3 classes.\n",
      "Model: \"model_14\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "AP(Mortise) (InputLayer)        [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Lateral (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "resnet50 (Functional)           (None, 2048)         23587712    AP(Mortise)[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "efficientnetb0 (Functional)     (None, 1280)         4049571     Lateral[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "AP_dense_128 (Dense)            (None, 128)          262272      resnet50[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Lateral_dense_128 (Dense)       (None, 128)          163968      efficientnetb0[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "AP_dense_50 (Dense)             (None, 50)           6450        AP_dense_128[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Lateral_dense_50 (Dense)        (None, 50)           6450        Lateral_dense_128[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "feature_fusion (Concatenate)    (None, 100)          0           AP_dense_50[0][0]                \n",
      "                                                                 Lateral_dense_50[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 100)          0           feature_fusion[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "output_layer (Dense)            (None, 3)            303         dropout_14[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 28,076,726\n",
      "Trainable params: 439,443\n",
      "Non-trainable params: 27,637,283\n",
      "__________________________________________________________________________________________________\n",
      "-------Training_concat1-------\n",
      "Epoch 1/30\n",
      "3/3 [==============================] - 6s 1s/step - loss: 1.4162 - accuracy: 0.2737 - val_loss: 1.1599 - val_accuracy: 0.3191\n",
      "Epoch 2/30\n",
      "3/3 [==============================] - 2s 663ms/step - loss: 1.1442 - accuracy: 0.3474 - val_loss: 1.0501 - val_accuracy: 0.5106\n",
      "Epoch 3/30\n",
      "3/3 [==============================] - 2s 691ms/step - loss: 1.0159 - accuracy: 0.4895 - val_loss: 1.0168 - val_accuracy: 0.5106\n",
      "Epoch 4/30\n",
      "3/3 [==============================] - 2s 689ms/step - loss: 0.9898 - accuracy: 0.5000 - val_loss: 0.9558 - val_accuracy: 0.5532\n",
      "Epoch 5/30\n",
      "3/3 [==============================] - 1s 681ms/step - loss: 0.8930 - accuracy: 0.5789 - val_loss: 0.8922 - val_accuracy: 0.6170\n",
      "Epoch 6/30\n",
      "3/3 [==============================] - 2s 692ms/step - loss: 0.8456 - accuracy: 0.6737 - val_loss: 0.8507 - val_accuracy: 0.6809\n",
      "Epoch 7/30\n",
      "3/3 [==============================] - 1s 684ms/step - loss: 0.7884 - accuracy: 0.7632 - val_loss: 0.8084 - val_accuracy: 0.7021\n",
      "Epoch 8/30\n",
      "3/3 [==============================] - 2s 687ms/step - loss: 0.7441 - accuracy: 0.7737 - val_loss: 0.7620 - val_accuracy: 0.6809\n",
      "Epoch 9/30\n",
      "3/3 [==============================] - 2s 690ms/step - loss: 0.6886 - accuracy: 0.8263 - val_loss: 0.7201 - val_accuracy: 0.7234\n",
      "Epoch 10/30\n",
      "3/3 [==============================] - 1s 682ms/step - loss: 0.6378 - accuracy: 0.8263 - val_loss: 0.6857 - val_accuracy: 0.7234\n",
      "Epoch 11/30\n",
      "3/3 [==============================] - 2s 690ms/step - loss: 0.6050 - accuracy: 0.8211 - val_loss: 0.6575 - val_accuracy: 0.7447\n",
      "Epoch 12/30\n",
      "3/3 [==============================] - 2s 694ms/step - loss: 0.6006 - accuracy: 0.7789 - val_loss: 0.6378 - val_accuracy: 0.7021\n",
      "Epoch 13/30\n",
      "3/3 [==============================] - 1s 680ms/step - loss: 0.5609 - accuracy: 0.7947 - val_loss: 0.6190 - val_accuracy: 0.7021\n",
      "Epoch 14/30\n",
      "3/3 [==============================] - 1s 681ms/step - loss: 0.5297 - accuracy: 0.8263 - val_loss: 0.5987 - val_accuracy: 0.7447\n",
      "Epoch 15/30\n",
      "3/3 [==============================] - 1s 683ms/step - loss: 0.5295 - accuracy: 0.8368 - val_loss: 0.5822 - val_accuracy: 0.7447\n",
      "Epoch 16/30\n",
      "3/3 [==============================] - 1s 677ms/step - loss: 0.4960 - accuracy: 0.8684 - val_loss: 0.5685 - val_accuracy: 0.7234\n",
      "Epoch 17/30\n",
      "3/3 [==============================] - 1s 684ms/step - loss: 0.4711 - accuracy: 0.8421 - val_loss: 0.5578 - val_accuracy: 0.7234\n",
      "Epoch 18/30\n",
      "3/3 [==============================] - 2s 697ms/step - loss: 0.4579 - accuracy: 0.8737 - val_loss: 0.5507 - val_accuracy: 0.7234\n",
      "Epoch 19/30\n",
      "3/3 [==============================] - 2s 691ms/step - loss: 0.4439 - accuracy: 0.8947 - val_loss: 0.5443 - val_accuracy: 0.7234\n",
      "Epoch 20/30\n",
      "3/3 [==============================] - 2s 687ms/step - loss: 0.4141 - accuracy: 0.8684 - val_loss: 0.5387 - val_accuracy: 0.7234\n",
      "Epoch 21/30\n",
      "3/3 [==============================] - 2s 689ms/step - loss: 0.4100 - accuracy: 0.8895 - val_loss: 0.5352 - val_accuracy: 0.7234\n",
      "acc mean = 0.69, std = 0.05, test_acc = [0.7, 0.68, 0.77, 0.65, 0.63]\n",
      "f1  mean = 0.64, std = 0.07, test_f1 = [0.67, 0.64, 0.75, 0.56, 0.58]\n"
     ]
    }
   ],
   "source": [
    "# import\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path\n",
    "# import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import os\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from tensorflow.keras.layers import Input, Dense, Concatenate, Dropout\n",
    "import math\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "## label\n",
    "# =========================\n",
    "def class_2_type(root):\n",
    "    label = \"\"\n",
    "    if \"正常\" in root:\n",
    "        label = \"0\"\n",
    "    else:\n",
    "        label = \"1\"\n",
    "    return label\n",
    "\n",
    "def class_3_type(root):\n",
    "    label = \"\"\n",
    "    if \"正常\" in root:\n",
    "        label = \"0\"\n",
    "    elif \"雙踝\" in root:\n",
    "        label = \"1\"\n",
    "    elif \"三踝\" in root:\n",
    "        label = \"2\"\n",
    "    return label\n",
    "# =========================\n",
    "\n",
    "\n",
    "def load_path(path, class_count):\n",
    "    dataset = []\n",
    "    class_type = ''\n",
    "    if class_count == 2:\n",
    "        class_type = class_2_type\n",
    "    elif class_count == 3:\n",
    "        class_type = class_3_type  \n",
    "\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            label = class_type(root)\n",
    "            # if label != \"\":\n",
    "            dataset.append(\n",
    "                            {   \n",
    "                                'uuid': root.split(\"\\\\\")[-1],\n",
    "                                'label': label,\n",
    "                                'image_path': os.path.join(root, file)\n",
    "                            }\n",
    "                        )\n",
    "\n",
    "    return dataset\n",
    "\n",
    "def create_front_extract():\n",
    "    pretrained_model_chosen = tf.keras.applications.resnet50.ResNet50\n",
    "    pretrained_model = pretrained_model_chosen(\n",
    "        input_shape=(224, 224, 3),\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        pooling='avg')\n",
    "    pretrained_model.trainable = False\n",
    "    return pretrained_model\n",
    "\n",
    "def create_side_extract():\n",
    "    pretrained_model_chosen = tf.keras.applications.efficientnet.EfficientNetB0\n",
    "    pretrained_model = pretrained_model_chosen(\n",
    "        input_shape=(224, 224, 3),\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        pooling='avg')\n",
    "    pretrained_model.trainable = False\n",
    "    return pretrained_model\n",
    "\n",
    "def multi_input_generator(front_gen, side_gen):\n",
    "    while True:\n",
    "        front_batch, y1 = next(front_gen)\n",
    "        side_batch, y2 = next(side_gen)\n",
    "        assert (y1 == y2).all(), \"Label mismatch!\"  # 確保標籤一致\n",
    "        yield ([front_batch, side_batch], y1)\n",
    "\n",
    "\n",
    "# def train_cross_validation(image_dir, n_splits=5, class_count=2, maru_part=None,  chosen_model='resnet50'):\n",
    "def train_cross_validation(image_dir, n_splits=5, class_count=2):\n",
    "\n",
    "\n",
    "    ## load data and  labels\n",
    "    # =========================\n",
    "    labels = []\n",
    "    filepaths = []\n",
    "    data = load_path(image_dir, class_count)\n",
    "    for row in data:\n",
    "        labels.append(row['label'])\n",
    "        filepaths.append(row['image_path'])\n",
    "\n",
    "    filepaths = pd.Series(filepaths, name='Filepath').astype(str)\n",
    "    labels = pd.Series(labels, name='Label')\n",
    "\n",
    "    images = pd.concat([filepaths, labels], axis=1)\n",
    "    # =========================\n",
    "\n",
    "    ## split image\n",
    "    # =========================\n",
    "    train_df_front, test_df_front = train_test_split(images, train_size=0.8, shuffle=True, random_state=1, stratify=images['Label'])\n",
    "    print(\"Training set label distribution:\\n\", train_df_front['Label'].value_counts(normalize=False))\n",
    "    print(\"Test set label distribution:\\n\", test_df_front['Label'].value_counts(normalize=False))\n",
    "    # =========================\n",
    "\n",
    "    preprocessing_function_chosen_front = tf.keras.applications.resnet50.preprocess_input\n",
    "    preprocessing_function_chosen_side = tf.keras.applications.efficientnet.preprocess_input\n",
    "\n",
    "\n",
    "    ## train model, k fold cross validation\n",
    "    # ==================================================\n",
    "    fold_no = 1\n",
    "    test_acc = []\n",
    "    test_f1 = []\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=1)\n",
    "    for train_index, val_index in kfold.split(train_df_front, train_df_front['Label']):\n",
    "        k_fold_train_front = train_df_front.iloc[train_index]\n",
    "        k_fold_val_front = train_df_front.iloc[val_index]\n",
    "\n",
    "        # front images\n",
    "        # =========================\n",
    "        train_generator_front = tf.keras.preprocessing.image.ImageDataGenerator(horizontal_flip=False,\n",
    "                                                                                preprocessing_function=preprocessing_function_chosen_front)\n",
    "        test_generator_front = tf.keras.preprocessing.image.ImageDataGenerator(preprocessing_function=preprocessing_function_chosen_front)\n",
    "\n",
    "        train_images_front = train_generator_front.flow_from_dataframe(\n",
    "            dataframe=k_fold_train_front,\n",
    "            x_col='Filepath',\n",
    "            y_col='Label',\n",
    "            target_size=(224, 224),\n",
    "            color_mode='rgb',\n",
    "            class_mode='categorical',\n",
    "            batch_size=64,\n",
    "            shuffle=False,\n",
    "            seed=42\n",
    "        )\n",
    "\n",
    "        val_images_front = train_generator_front.flow_from_dataframe(\n",
    "            dataframe=k_fold_val_front,\n",
    "            x_col='Filepath',\n",
    "            y_col='Label',\n",
    "            target_size=(224, 224),\n",
    "            color_mode='rgb',\n",
    "            class_mode='categorical',\n",
    "            batch_size=64,\n",
    "            shuffle=False,\n",
    "            seed=42\n",
    "        )\n",
    "\n",
    "        test_images_front = test_generator_front.flow_from_dataframe(\n",
    "            dataframe=test_df_front,\n",
    "            x_col='Filepath',\n",
    "            y_col='Label',\n",
    "            target_size=(224, 224),\n",
    "            color_mode='rgb',\n",
    "            class_mode='categorical',\n",
    "            batch_size=32,\n",
    "            shuffle=False\n",
    "        )\n",
    "        # =========================   \n",
    "\n",
    "        # side images\n",
    "        # =========================\n",
    "        train_df_side = train_df_front.copy()\n",
    "        test_df_side = test_df_front.copy()\n",
    "        train_df_side.loc[:, \"Filepath\"] = train_df_front[\"Filepath\"].str.replace(\"front\", \"side\")\n",
    "        test_df_side.loc[:, \"Filepath\"] = test_df_side[\"Filepath\"].str.replace(\"front\", \"side\")\n",
    "\n",
    "        k_fold_train_side = train_df_side.iloc[train_index]\n",
    "        k_fold_val_side = train_df_side.iloc[val_index]\n",
    "\n",
    "        train_generator_side = tf.keras.preprocessing.image.ImageDataGenerator(horizontal_flip=False,\n",
    "                                                                                preprocessing_function=preprocessing_function_chosen_side)\n",
    "        test_generator_side = tf.keras.preprocessing.image.ImageDataGenerator(preprocessing_function=preprocessing_function_chosen_side)\n",
    "\n",
    "        train_images_side = train_generator_side.flow_from_dataframe(\n",
    "            dataframe=k_fold_train_side,\n",
    "            x_col='Filepath',\n",
    "            y_col='Label',\n",
    "            target_size=(224, 224),\n",
    "            color_mode='rgb',\n",
    "            class_mode='categorical',\n",
    "            batch_size=64,\n",
    "            shuffle=False,\n",
    "            seed=42\n",
    "        )\n",
    "\n",
    "        val_images_side = train_generator_side.flow_from_dataframe(\n",
    "            dataframe=k_fold_val_side,\n",
    "            x_col='Filepath',\n",
    "            y_col='Label',\n",
    "            target_size=(224, 224),\n",
    "            color_mode='rgb',\n",
    "            class_mode='categorical',\n",
    "            batch_size=64,\n",
    "            shuffle=False,\n",
    "            seed=42\n",
    "        )\n",
    "\n",
    "        test_images_side = test_generator_side.flow_from_dataframe(\n",
    "            dataframe=test_df_side,\n",
    "            x_col='Filepath',\n",
    "            y_col='Label',\n",
    "            target_size=(224, 224),\n",
    "            color_mode='rgb',\n",
    "            class_mode='categorical',\n",
    "            batch_size=32,\n",
    "            shuffle=False\n",
    "        )\n",
    "        # ========================= \n",
    "        \n",
    "        # load model\n",
    "        # =========================\n",
    "        # input \n",
    "        input_front = Input(shape=(224, 224, 3), name=\"AP(Mortise)\")\n",
    "        input_side = Input(shape=(224, 224, 3), name=\"Lateral\")\n",
    "\n",
    "        # model\n",
    "        model_front = create_front_extract()\n",
    "        model_side = create_side_extract()\n",
    "\n",
    "        features_front = model_front(input_front)\n",
    "        features_side = model_side(input_side)\n",
    "\n",
    "        features_front_x = tf.keras.layers.Dense(128, activation='relu', name='AP_dense_128')(features_front)\n",
    "        features_front_x = tf.keras.layers.Dense(50, activation='relu', name='AP_dense_50')(features_front_x)\n",
    "\n",
    "        features_side_x = tf.keras.layers.Dense(128, activation='relu', name='Lateral_dense_128')(features_side)\n",
    "        features_side_x = tf.keras.layers.Dense(50, activation='relu', name='Lateral_dense_50')(features_side_x)\n",
    "\n",
    "        fused_features = Concatenate(name=\"feature_fusion\")([features_front_x, features_side_x])\n",
    "        # fused_features = tf.keras.layers.Dense(50, activation='relu', name='fusion_dense_50')(fused_features)\n",
    "        fused_features = Dropout(0.1)(fused_features)\n",
    "\n",
    "        final_output = Dense(class_count, activation='sigmoid', name='output_layer')(fused_features)\n",
    "        multi_view_model = None\n",
    "        multi_view_model = Model(\n",
    "            inputs=[input_front, input_side],\n",
    "            outputs=final_output\n",
    "        )\n",
    "        multi_view_model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        multi_view_model.summary()\n",
    "        # print(model.summary())\n",
    "        # =========================\n",
    "\n",
    "        train_generator = multi_input_generator(train_images_front, train_images_side)\n",
    "        val_generator = multi_input_generator(val_images_front, val_images_side)\n",
    "        \n",
    "        ## compile and evaluate\n",
    "        # =========================\n",
    "\n",
    "        print(\"-------Training_\" + concat_type + \"-------\")\n",
    "        multi_view_model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "        batch_size = 64\n",
    "        ## early stop \n",
    "        early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)\n",
    "        multi_view_model.fit(train_generator, validation_data=val_generator, callbacks=[early_stopping], epochs=30,\n",
    "                                    steps_per_epoch= math.ceil(train_images_front.samples / batch_size), \n",
    "                                    validation_steps= math.ceil(val_images_front.samples / batch_size))\n",
    "        ## no early stop\n",
    "        # multi_view_model.fit(train_generator, validation_data=val_generator, epochs=30,\n",
    "        #                     steps_per_epoch= math.ceil(train_images_front.samples / batch_size), \n",
    "        #                     validation_steps= math.ceil(val_images_front.samples / batch_size))\n",
    "\n",
    "        # =========================\n",
    "\n",
    "        test_generator = multi_input_generator(test_images_front, test_images_side)\n",
    "        batch_size=32\n",
    "        pred = multi_view_model.predict(test_generator,  steps=math.ceil(test_images_front.samples / batch_size))\n",
    "        predicted_labels = np.argmax(pred, axis=1)\n",
    "\n",
    "        # =========================\n",
    "            \n",
    "        ## print results\n",
    "        # =========================\n",
    "        acc = accuracy_score(test_images_front.labels, predicted_labels)\n",
    "\n",
    "        test_acc.append(np.round(acc, 2))\n",
    "        f1 = f1_score(test_images_front.labels, predicted_labels, average='macro')\n",
    "        test_f1.append(np.round(f1, 2))\n",
    "        fold_no += 1\n",
    "        # =========================\n",
    "    # ==================================================\n",
    "        \n",
    "    ## print  mean results\n",
    "    # =========================\n",
    "    acc_mean  = np.round(np.mean(test_acc), 2)\n",
    "    acc_std = np.round(np.std(test_acc), 2)\n",
    "    f1_mean  = np.round(np.mean(test_f1), 2)\n",
    "    f1_std = np.round(np.std(test_f1), 2)\n",
    "    # print(f\"acc mean = {acc_mean}, std = {acc_std}\")\n",
    "    # print(test_acc)\n",
    "    # print(f\"f1  mean = {f1_mean}, std = {f1_std}\")\n",
    "    # print(test_f1)\n",
    "    # =========================\n",
    "\n",
    "    return {'acc_mean':acc_mean, 'acc_std':acc_std, 'test_acc':test_acc, 'f1_mean':f1_mean, 'f1_std':f1_std, 'test_f1':test_f1}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# =========================\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "results = []\n",
    "results = train_cross_validation(image_dir=path, class_count=3)\n",
    "\n",
    "\n",
    "print(f\"acc mean = {results['acc_mean']}, std = {results['acc_std']}, test_acc = {results['test_acc']}\")\n",
    "print(f\"f1  mean = {results['f1_mean']}, std = {results['f1_std']}, test_f1 = {results['test_f1']}\")\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bone_20240719",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
