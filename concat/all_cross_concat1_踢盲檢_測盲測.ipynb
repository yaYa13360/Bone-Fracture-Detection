{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"E:\\\\data_bone\\\\11-a+b_swift_cut_正確_V2_踢盲檢\\\\front\"\n",
    "path2 = \"E:\\\\data_bone\\\\11-只有盲檢\\\\front\"\n",
    "concat_type = \"concat1_踢盲檢_測盲檢\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set label distribution:\n",
      " 0    126\n",
      "2     87\n",
      "1     84\n",
      "Name: Label, dtype: int64\n",
      "Test set label distribution:\n",
      " 2    35\n",
      "0    34\n",
      "1    31\n",
      "Name: Label, dtype: int64\n",
      "Found 237 validated image filenames belonging to 3 classes.\n",
      "Found 60 validated image filenames belonging to 3 classes.\n",
      "Found 100 validated image filenames belonging to 3 classes.\n",
      "Found 237 validated image filenames belonging to 3 classes.\n",
      "Found 60 validated image filenames belonging to 3 classes.\n",
      "Found 100 validated image filenames belonging to 3 classes.\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "AP(Mortise) (InputLayer)        [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Lateral (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "resnet50 (Functional)           (None, 2048)         23587712    AP(Mortise)[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "efficientnetb0 (Functional)     (None, 1280)         4049571     Lateral[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "AP_dense_128 (Dense)            (None, 128)          262272      resnet50[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Lateral_dense_128 (Dense)       (None, 128)          163968      efficientnetb0[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "AP_dense_50 (Dense)             (None, 50)           6450        AP_dense_128[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Lateral_dense_50 (Dense)        (None, 50)           6450        Lateral_dense_128[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "feature_fusion (Concatenate)    (None, 100)          0           AP_dense_50[0][0]                \n",
      "                                                                 Lateral_dense_50[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 100)          0           feature_fusion[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "output_layer (Dense)            (None, 3)            303         dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 28,076,726\n",
      "Trainable params: 439,443\n",
      "Non-trainable params: 27,637,283\n",
      "__________________________________________________________________________________________________\n",
      "-------Training_concat1_踢盲檢_測盲檢-------\n",
      "Epoch 1/30\n",
      "4/4 [==============================] - 9s 1s/step - loss: 1.4703 - accuracy: 0.2574 - val_loss: 1.1865 - val_accuracy: 0.2500\n",
      "Epoch 2/30\n",
      "4/4 [==============================] - 2s 548ms/step - loss: 1.1419 - accuracy: 0.3713 - val_loss: 1.0583 - val_accuracy: 0.4833\n",
      "Epoch 3/30\n",
      "4/4 [==============================] - 2s 527ms/step - loss: 1.0459 - accuracy: 0.4895 - val_loss: 0.9766 - val_accuracy: 0.5167\n",
      "Epoch 4/30\n",
      "4/4 [==============================] - 2s 521ms/step - loss: 0.9256 - accuracy: 0.5443 - val_loss: 0.9163 - val_accuracy: 0.5833\n",
      "Epoch 5/30\n",
      "4/4 [==============================] - 2s 519ms/step - loss: 0.8594 - accuracy: 0.6540 - val_loss: 0.8813 - val_accuracy: 0.5833\n",
      "Epoch 6/30\n",
      "4/4 [==============================] - 2s 518ms/step - loss: 0.8071 - accuracy: 0.7046 - val_loss: 0.8332 - val_accuracy: 0.6167\n",
      "Epoch 7/30\n",
      "4/4 [==============================] - 2s 521ms/step - loss: 0.7288 - accuracy: 0.7595 - val_loss: 0.7893 - val_accuracy: 0.6333\n",
      "Epoch 8/30\n",
      "4/4 [==============================] - 2s 523ms/step - loss: 0.6991 - accuracy: 0.7637 - val_loss: 0.7530 - val_accuracy: 0.6500\n",
      "Epoch 9/30\n",
      "4/4 [==============================] - 2s 519ms/step - loss: 0.6390 - accuracy: 0.8101 - val_loss: 0.7185 - val_accuracy: 0.6667\n",
      "Epoch 10/30\n",
      "4/4 [==============================] - 2s 523ms/step - loss: 0.5901 - accuracy: 0.8228 - val_loss: 0.6925 - val_accuracy: 0.6333\n",
      "Epoch 11/30\n",
      "4/4 [==============================] - 2s 527ms/step - loss: 0.5585 - accuracy: 0.8101 - val_loss: 0.6739 - val_accuracy: 0.6500\n",
      "Epoch 12/30\n",
      "4/4 [==============================] - 2s 528ms/step - loss: 0.5367 - accuracy: 0.8143 - val_loss: 0.6564 - val_accuracy: 0.6833\n",
      "Epoch 13/30\n",
      "4/4 [==============================] - 2s 522ms/step - loss: 0.5247 - accuracy: 0.8481 - val_loss: 0.6387 - val_accuracy: 0.7000\n",
      "Epoch 14/30\n",
      "4/4 [==============================] - 2s 525ms/step - loss: 0.4947 - accuracy: 0.8439 - val_loss: 0.6235 - val_accuracy: 0.6833\n",
      "Epoch 15/30\n",
      "4/4 [==============================] - 2s 525ms/step - loss: 0.4607 - accuracy: 0.8354 - val_loss: 0.6091 - val_accuracy: 0.7000\n",
      "Epoch 16/30\n",
      "4/4 [==============================] - 2s 524ms/step - loss: 0.4610 - accuracy: 0.8312 - val_loss: 0.5968 - val_accuracy: 0.7000\n",
      "Epoch 17/30\n",
      "4/4 [==============================] - 2s 525ms/step - loss: 0.4210 - accuracy: 0.8692 - val_loss: 0.5871 - val_accuracy: 0.7000\n",
      "Epoch 18/30\n",
      "4/4 [==============================] - 2s 522ms/step - loss: 0.4113 - accuracy: 0.8734 - val_loss: 0.5803 - val_accuracy: 0.7000\n",
      "Epoch 19/30\n",
      "4/4 [==============================] - 2s 525ms/step - loss: 0.3852 - accuracy: 0.8650 - val_loss: 0.5737 - val_accuracy: 0.7000\n",
      "Epoch 20/30\n",
      "4/4 [==============================] - 2s 529ms/step - loss: 0.3832 - accuracy: 0.8903 - val_loss: 0.5632 - val_accuracy: 0.7333\n",
      "Epoch 21/30\n",
      "4/4 [==============================] - 2s 526ms/step - loss: 0.3646 - accuracy: 0.8903 - val_loss: 0.5574 - val_accuracy: 0.7333\n",
      "Epoch 22/30\n",
      "4/4 [==============================] - 2s 527ms/step - loss: 0.3531 - accuracy: 0.8903 - val_loss: 0.5552 - val_accuracy: 0.7000\n",
      "Epoch 23/30\n",
      "4/4 [==============================] - 2s 528ms/step - loss: 0.3198 - accuracy: 0.9072 - val_loss: 0.5516 - val_accuracy: 0.7167\n",
      "Epoch 24/30\n",
      "4/4 [==============================] - 2s 527ms/step - loss: 0.3314 - accuracy: 0.9114 - val_loss: 0.5487 - val_accuracy: 0.7333\n",
      "Epoch 25/30\n",
      "4/4 [==============================] - 2s 520ms/step - loss: 0.2961 - accuracy: 0.9030 - val_loss: 0.5459 - val_accuracy: 0.7167\n",
      "Epoch 26/30\n",
      "4/4 [==============================] - 2s 521ms/step - loss: 0.2969 - accuracy: 0.9241 - val_loss: 0.5397 - val_accuracy: 0.7333\n",
      "Epoch 27/30\n",
      "4/4 [==============================] - 2s 522ms/step - loss: 0.2993 - accuracy: 0.9198 - val_loss: 0.5354 - val_accuracy: 0.7500\n",
      "Epoch 28/30\n",
      "4/4 [==============================] - 2s 515ms/step - loss: 0.3009 - accuracy: 0.9030 - val_loss: 0.5329 - val_accuracy: 0.7167\n",
      "Epoch 29/30\n",
      "4/4 [==============================] - 2s 529ms/step - loss: 0.2637 - accuracy: 0.9367 - val_loss: 0.5304 - val_accuracy: 0.7167\n",
      "Epoch 30/30\n",
      "4/4 [==============================] - 2s 525ms/step - loss: 0.2678 - accuracy: 0.9241 - val_loss: 0.5264 - val_accuracy: 0.7500\n",
      "Found 237 validated image filenames belonging to 3 classes.\n",
      "Found 60 validated image filenames belonging to 3 classes.\n",
      "Found 100 validated image filenames belonging to 3 classes.\n",
      "Found 237 validated image filenames belonging to 3 classes.\n",
      "Found 60 validated image filenames belonging to 3 classes.\n",
      "Found 100 validated image filenames belonging to 3 classes.\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "AP(Mortise) (InputLayer)        [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Lateral (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "resnet50 (Functional)           (None, 2048)         23587712    AP(Mortise)[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "efficientnetb0 (Functional)     (None, 1280)         4049571     Lateral[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "AP_dense_128 (Dense)            (None, 128)          262272      resnet50[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Lateral_dense_128 (Dense)       (None, 128)          163968      efficientnetb0[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "AP_dense_50 (Dense)             (None, 50)           6450        AP_dense_128[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Lateral_dense_50 (Dense)        (None, 50)           6450        Lateral_dense_128[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "feature_fusion (Concatenate)    (None, 100)          0           AP_dense_50[0][0]                \n",
      "                                                                 Lateral_dense_50[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 100)          0           feature_fusion[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "output_layer (Dense)            (None, 3)            303         dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 28,076,726\n",
      "Trainable params: 439,443\n",
      "Non-trainable params: 27,637,283\n",
      "__________________________________________________________________________________________________\n",
      "-------Training_concat1_踢盲檢_測盲檢-------\n",
      "Epoch 1/30\n",
      "4/4 [==============================] - 6s 810ms/step - loss: 1.1364 - accuracy: 0.3671 - val_loss: 0.9509 - val_accuracy: 0.6167\n",
      "Epoch 2/30\n",
      "4/4 [==============================] - 2s 587ms/step - loss: 0.9825 - accuracy: 0.5148 - val_loss: 0.8773 - val_accuracy: 0.6000\n",
      "Epoch 3/30\n",
      "4/4 [==============================] - 2s 530ms/step - loss: 0.8488 - accuracy: 0.6498 - val_loss: 0.7651 - val_accuracy: 0.7000\n",
      "Epoch 4/30\n",
      "4/4 [==============================] - 2s 534ms/step - loss: 0.7836 - accuracy: 0.6878 - val_loss: 0.7032 - val_accuracy: 0.7167\n",
      "Epoch 5/30\n",
      "4/4 [==============================] - 2s 526ms/step - loss: 0.6996 - accuracy: 0.7553 - val_loss: 0.6534 - val_accuracy: 0.7167\n",
      "Epoch 6/30\n",
      "4/4 [==============================] - 2s 532ms/step - loss: 0.6357 - accuracy: 0.7595 - val_loss: 0.6251 - val_accuracy: 0.7333\n",
      "Epoch 7/30\n",
      "4/4 [==============================] - 2s 527ms/step - loss: 0.6006 - accuracy: 0.7679 - val_loss: 0.5981 - val_accuracy: 0.7500\n",
      "Epoch 8/30\n",
      "4/4 [==============================] - 2s 524ms/step - loss: 0.5522 - accuracy: 0.7848 - val_loss: 0.5791 - val_accuracy: 0.7500\n",
      "Epoch 9/30\n",
      "4/4 [==============================] - 2s 530ms/step - loss: 0.5088 - accuracy: 0.8059 - val_loss: 0.5662 - val_accuracy: 0.7500\n",
      "Epoch 10/30\n",
      "4/4 [==============================] - 2s 537ms/step - loss: 0.4961 - accuracy: 0.8186 - val_loss: 0.5575 - val_accuracy: 0.7500\n",
      "Epoch 11/30\n",
      "4/4 [==============================] - 2s 533ms/step - loss: 0.4813 - accuracy: 0.8312 - val_loss: 0.5538 - val_accuracy: 0.7167\n",
      "Epoch 12/30\n",
      "4/4 [==============================] - 2s 532ms/step - loss: 0.4518 - accuracy: 0.8186 - val_loss: 0.5484 - val_accuracy: 0.7167\n",
      "Epoch 13/30\n",
      "4/4 [==============================] - 2s 530ms/step - loss: 0.4269 - accuracy: 0.8312 - val_loss: 0.5322 - val_accuracy: 0.7333\n",
      "Epoch 14/30\n",
      "4/4 [==============================] - 2s 528ms/step - loss: 0.4060 - accuracy: 0.8439 - val_loss: 0.5213 - val_accuracy: 0.7500\n",
      "Epoch 15/30\n",
      "4/4 [==============================] - 2s 526ms/step - loss: 0.4007 - accuracy: 0.8397 - val_loss: 0.5223 - val_accuracy: 0.7167\n",
      "Epoch 16/30\n",
      "4/4 [==============================] - 2s 534ms/step - loss: 0.3965 - accuracy: 0.8819 - val_loss: 0.5265 - val_accuracy: 0.7000\n",
      "Epoch 17/30\n",
      "4/4 [==============================] - 2s 529ms/step - loss: 0.3584 - accuracy: 0.8903 - val_loss: 0.5163 - val_accuracy: 0.7500\n",
      "Epoch 18/30\n",
      "4/4 [==============================] - 2s 533ms/step - loss: 0.3326 - accuracy: 0.9114 - val_loss: 0.5054 - val_accuracy: 0.7500\n",
      "Epoch 19/30\n",
      "4/4 [==============================] - 2s 539ms/step - loss: 0.3364 - accuracy: 0.9114 - val_loss: 0.5093 - val_accuracy: 0.7167\n",
      "Epoch 20/30\n",
      "4/4 [==============================] - 2s 533ms/step - loss: 0.3185 - accuracy: 0.9072 - val_loss: 0.5095 - val_accuracy: 0.7333\n",
      "Epoch 21/30\n",
      "4/4 [==============================] - 2s 532ms/step - loss: 0.3035 - accuracy: 0.9114 - val_loss: 0.5018 - val_accuracy: 0.7500\n",
      "Epoch 22/30\n",
      "4/4 [==============================] - 2s 534ms/step - loss: 0.2961 - accuracy: 0.9156 - val_loss: 0.5035 - val_accuracy: 0.7333\n",
      "Epoch 23/30\n",
      "4/4 [==============================] - 2s 538ms/step - loss: 0.2829 - accuracy: 0.9325 - val_loss: 0.5014 - val_accuracy: 0.7500\n",
      "Epoch 24/30\n",
      "4/4 [==============================] - 2s 533ms/step - loss: 0.2735 - accuracy: 0.9198 - val_loss: 0.5002 - val_accuracy: 0.7500\n",
      "Epoch 25/30\n",
      "4/4 [==============================] - 2s 534ms/step - loss: 0.2537 - accuracy: 0.9494 - val_loss: 0.5042 - val_accuracy: 0.7333\n",
      "Epoch 26/30\n",
      "4/4 [==============================] - 2s 532ms/step - loss: 0.2651 - accuracy: 0.9367 - val_loss: 0.4994 - val_accuracy: 0.7500\n",
      "Epoch 27/30\n",
      "4/4 [==============================] - 2s 536ms/step - loss: 0.2322 - accuracy: 0.9536 - val_loss: 0.4960 - val_accuracy: 0.7500\n",
      "Epoch 28/30\n",
      "4/4 [==============================] - 2s 531ms/step - loss: 0.2400 - accuracy: 0.9283 - val_loss: 0.4901 - val_accuracy: 0.7500\n",
      "Epoch 29/30\n",
      "4/4 [==============================] - 2s 531ms/step - loss: 0.2224 - accuracy: 0.9578 - val_loss: 0.4889 - val_accuracy: 0.7667\n",
      "Epoch 30/30\n",
      "4/4 [==============================] - 2s 532ms/step - loss: 0.2219 - accuracy: 0.9705 - val_loss: 0.5003 - val_accuracy: 0.7500\n",
      "Found 238 validated image filenames belonging to 3 classes.\n",
      "Found 59 validated image filenames belonging to 3 classes.\n",
      "Found 100 validated image filenames belonging to 3 classes.\n",
      "Found 238 validated image filenames belonging to 3 classes.\n",
      "Found 59 validated image filenames belonging to 3 classes.\n",
      "Found 100 validated image filenames belonging to 3 classes.\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "AP(Mortise) (InputLayer)        [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Lateral (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "resnet50 (Functional)           (None, 2048)         23587712    AP(Mortise)[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "efficientnetb0 (Functional)     (None, 1280)         4049571     Lateral[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "AP_dense_128 (Dense)            (None, 128)          262272      resnet50[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Lateral_dense_128 (Dense)       (None, 128)          163968      efficientnetb0[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "AP_dense_50 (Dense)             (None, 50)           6450        AP_dense_128[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Lateral_dense_50 (Dense)        (None, 50)           6450        Lateral_dense_128[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "feature_fusion (Concatenate)    (None, 100)          0           AP_dense_50[0][0]                \n",
      "                                                                 Lateral_dense_50[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 100)          0           feature_fusion[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "output_layer (Dense)            (None, 3)            303         dropout_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 28,076,726\n",
      "Trainable params: 439,443\n",
      "Non-trainable params: 27,637,283\n",
      "__________________________________________________________________________________________________\n",
      "-------Training_concat1_踢盲檢_測盲檢-------\n",
      "Epoch 1/30\n",
      "4/4 [==============================] - 8s 1s/step - loss: 1.1124 - accuracy: 0.4118 - val_loss: 0.9777 - val_accuracy: 0.5932\n",
      "Epoch 2/30\n",
      "4/4 [==============================] - 2s 615ms/step - loss: 0.9782 - accuracy: 0.5798 - val_loss: 0.8786 - val_accuracy: 0.6949\n",
      "Epoch 3/30\n",
      "4/4 [==============================] - 2s 539ms/step - loss: 0.8509 - accuracy: 0.6429 - val_loss: 0.8179 - val_accuracy: 0.6610\n",
      "Epoch 4/30\n",
      "4/4 [==============================] - 2s 542ms/step - loss: 0.8360 - accuracy: 0.6429 - val_loss: 0.7593 - val_accuracy: 0.7288\n",
      "Epoch 5/30\n",
      "4/4 [==============================] - 2s 537ms/step - loss: 0.7573 - accuracy: 0.7101 - val_loss: 0.7109 - val_accuracy: 0.7797\n",
      "Epoch 6/30\n",
      "4/4 [==============================] - 2s 544ms/step - loss: 0.7033 - accuracy: 0.7353 - val_loss: 0.6669 - val_accuracy: 0.8136\n",
      "Epoch 7/30\n",
      "4/4 [==============================] - 2s 538ms/step - loss: 0.6809 - accuracy: 0.7185 - val_loss: 0.6248 - val_accuracy: 0.7966\n",
      "Epoch 8/30\n",
      "4/4 [==============================] - 2s 538ms/step - loss: 0.6398 - accuracy: 0.7479 - val_loss: 0.5904 - val_accuracy: 0.7966\n",
      "Epoch 9/30\n",
      "4/4 [==============================] - 2s 535ms/step - loss: 0.5922 - accuracy: 0.7731 - val_loss: 0.5650 - val_accuracy: 0.8136\n",
      "Epoch 10/30\n",
      "4/4 [==============================] - 2s 541ms/step - loss: 0.5544 - accuracy: 0.8151 - val_loss: 0.5417 - val_accuracy: 0.8136\n",
      "Epoch 11/30\n",
      "4/4 [==============================] - 2s 535ms/step - loss: 0.5217 - accuracy: 0.8235 - val_loss: 0.5168 - val_accuracy: 0.8136\n",
      "Epoch 12/30\n",
      "4/4 [==============================] - 2s 547ms/step - loss: 0.5033 - accuracy: 0.8319 - val_loss: 0.4994 - val_accuracy: 0.8475\n",
      "Epoch 13/30\n",
      "4/4 [==============================] - 2s 538ms/step - loss: 0.4841 - accuracy: 0.8613 - val_loss: 0.4850 - val_accuracy: 0.8305\n",
      "Epoch 14/30\n",
      "4/4 [==============================] - 2s 542ms/step - loss: 0.4712 - accuracy: 0.8655 - val_loss: 0.4674 - val_accuracy: 0.8305\n",
      "Epoch 15/30\n",
      "4/4 [==============================] - 2s 538ms/step - loss: 0.4607 - accuracy: 0.8361 - val_loss: 0.4531 - val_accuracy: 0.8644\n",
      "Epoch 16/30\n",
      "4/4 [==============================] - 2s 536ms/step - loss: 0.4179 - accuracy: 0.8782 - val_loss: 0.4420 - val_accuracy: 0.8136\n",
      "Epoch 17/30\n",
      "4/4 [==============================] - 2s 540ms/step - loss: 0.4117 - accuracy: 0.8697 - val_loss: 0.4360 - val_accuracy: 0.8305\n",
      "Epoch 18/30\n",
      "4/4 [==============================] - 2s 540ms/step - loss: 0.3919 - accuracy: 0.8866 - val_loss: 0.4258 - val_accuracy: 0.8305\n",
      "Epoch 19/30\n",
      "4/4 [==============================] - 2s 537ms/step - loss: 0.4014 - accuracy: 0.8613 - val_loss: 0.4181 - val_accuracy: 0.8644\n",
      "Epoch 20/30\n",
      "4/4 [==============================] - 2s 537ms/step - loss: 0.3902 - accuracy: 0.8613 - val_loss: 0.4112 - val_accuracy: 0.8136\n",
      "Epoch 21/30\n",
      "4/4 [==============================] - 2s 535ms/step - loss: 0.3759 - accuracy: 0.8697 - val_loss: 0.4028 - val_accuracy: 0.8305\n",
      "Epoch 22/30\n",
      "4/4 [==============================] - 2s 533ms/step - loss: 0.3548 - accuracy: 0.8950 - val_loss: 0.3942 - val_accuracy: 0.8136\n",
      "Epoch 23/30\n",
      "4/4 [==============================] - 2s 533ms/step - loss: 0.3411 - accuracy: 0.9076 - val_loss: 0.3904 - val_accuracy: 0.8305\n",
      "Epoch 24/30\n",
      "4/4 [==============================] - 2s 533ms/step - loss: 0.3196 - accuracy: 0.9286 - val_loss: 0.3860 - val_accuracy: 0.8305\n",
      "Epoch 25/30\n",
      "4/4 [==============================] - 2s 532ms/step - loss: 0.3152 - accuracy: 0.9286 - val_loss: 0.3759 - val_accuracy: 0.8644\n",
      "Epoch 26/30\n",
      "4/4 [==============================] - 2s 540ms/step - loss: 0.3083 - accuracy: 0.9244 - val_loss: 0.3720 - val_accuracy: 0.8644\n",
      "Epoch 27/30\n",
      "4/4 [==============================] - 2s 532ms/step - loss: 0.2854 - accuracy: 0.9328 - val_loss: 0.3716 - val_accuracy: 0.8136\n",
      "Epoch 28/30\n",
      "4/4 [==============================] - 2s 534ms/step - loss: 0.2875 - accuracy: 0.9286 - val_loss: 0.3680 - val_accuracy: 0.8305\n",
      "Epoch 29/30\n",
      "4/4 [==============================] - 2s 540ms/step - loss: 0.2903 - accuracy: 0.9202 - val_loss: 0.3626 - val_accuracy: 0.8475\n",
      "Epoch 30/30\n",
      "4/4 [==============================] - 2s 538ms/step - loss: 0.2813 - accuracy: 0.9370 - val_loss: 0.3594 - val_accuracy: 0.8475\n",
      "Found 238 validated image filenames belonging to 3 classes.\n",
      "Found 59 validated image filenames belonging to 3 classes.\n",
      "Found 100 validated image filenames belonging to 3 classes.\n",
      "Found 238 validated image filenames belonging to 3 classes.\n",
      "Found 59 validated image filenames belonging to 3 classes.\n",
      "Found 100 validated image filenames belonging to 3 classes.\n",
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "AP(Mortise) (InputLayer)        [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Lateral (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "resnet50 (Functional)           (None, 2048)         23587712    AP(Mortise)[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "efficientnetb0 (Functional)     (None, 1280)         4049571     Lateral[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "AP_dense_128 (Dense)            (None, 128)          262272      resnet50[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Lateral_dense_128 (Dense)       (None, 128)          163968      efficientnetb0[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "AP_dense_50 (Dense)             (None, 50)           6450        AP_dense_128[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Lateral_dense_50 (Dense)        (None, 50)           6450        Lateral_dense_128[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "feature_fusion (Concatenate)    (None, 100)          0           AP_dense_50[0][0]                \n",
      "                                                                 Lateral_dense_50[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 100)          0           feature_fusion[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "output_layer (Dense)            (None, 3)            303         dropout_4[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 28,076,726\n",
      "Trainable params: 439,443\n",
      "Non-trainable params: 27,637,283\n",
      "__________________________________________________________________________________________________\n",
      "-------Training_concat1_踢盲檢_測盲檢-------\n",
      "Epoch 1/30\n",
      "4/4 [==============================] - 6s 803ms/step - loss: 1.1584 - accuracy: 0.3950 - val_loss: 1.0234 - val_accuracy: 0.4915\n",
      "Epoch 2/30\n",
      "4/4 [==============================] - 2s 602ms/step - loss: 0.9811 - accuracy: 0.4832 - val_loss: 0.9238 - val_accuracy: 0.5763\n",
      "Epoch 3/30\n",
      "4/4 [==============================] - 2s 539ms/step - loss: 0.8893 - accuracy: 0.6134 - val_loss: 0.8587 - val_accuracy: 0.6441\n",
      "Epoch 4/30\n",
      "4/4 [==============================] - 2s 541ms/step - loss: 0.8255 - accuracy: 0.6597 - val_loss: 0.7993 - val_accuracy: 0.6610\n",
      "Epoch 5/30\n",
      "4/4 [==============================] - 2s 542ms/step - loss: 0.7698 - accuracy: 0.6681 - val_loss: 0.7433 - val_accuracy: 0.6949\n",
      "Epoch 6/30\n",
      "4/4 [==============================] - 2s 542ms/step - loss: 0.7161 - accuracy: 0.7395 - val_loss: 0.6982 - val_accuracy: 0.6610\n",
      "Epoch 7/30\n",
      "4/4 [==============================] - 2s 538ms/step - loss: 0.6798 - accuracy: 0.7353 - val_loss: 0.6617 - val_accuracy: 0.6441\n",
      "Epoch 8/30\n",
      "4/4 [==============================] - 2s 544ms/step - loss: 0.6046 - accuracy: 0.7857 - val_loss: 0.6375 - val_accuracy: 0.6610\n",
      "Epoch 9/30\n",
      "4/4 [==============================] - 2s 543ms/step - loss: 0.5731 - accuracy: 0.7983 - val_loss: 0.6103 - val_accuracy: 0.6441\n",
      "Epoch 10/30\n",
      "4/4 [==============================] - 2s 541ms/step - loss: 0.5487 - accuracy: 0.8109 - val_loss: 0.5824 - val_accuracy: 0.6610\n",
      "Epoch 11/30\n",
      "4/4 [==============================] - 2s 542ms/step - loss: 0.5166 - accuracy: 0.8487 - val_loss: 0.5608 - val_accuracy: 0.6780\n",
      "Epoch 12/30\n",
      "4/4 [==============================] - 2s 544ms/step - loss: 0.4981 - accuracy: 0.8235 - val_loss: 0.5471 - val_accuracy: 0.6949\n",
      "Epoch 13/30\n",
      "4/4 [==============================] - 2s 540ms/step - loss: 0.4722 - accuracy: 0.8403 - val_loss: 0.5352 - val_accuracy: 0.7119\n",
      "Epoch 14/30\n",
      "4/4 [==============================] - 2s 540ms/step - loss: 0.4529 - accuracy: 0.8445 - val_loss: 0.5224 - val_accuracy: 0.7458\n",
      "Epoch 15/30\n",
      "4/4 [==============================] - 2s 547ms/step - loss: 0.4336 - accuracy: 0.8571 - val_loss: 0.5096 - val_accuracy: 0.7288\n",
      "Epoch 16/30\n",
      "4/4 [==============================] - 2s 541ms/step - loss: 0.3936 - accuracy: 0.8824 - val_loss: 0.4978 - val_accuracy: 0.7458\n",
      "Epoch 17/30\n",
      "4/4 [==============================] - 2s 538ms/step - loss: 0.4026 - accuracy: 0.8866 - val_loss: 0.4882 - val_accuracy: 0.7627\n",
      "Epoch 18/30\n",
      "4/4 [==============================] - 2s 538ms/step - loss: 0.3934 - accuracy: 0.8782 - val_loss: 0.4800 - val_accuracy: 0.7797\n",
      "Epoch 19/30\n",
      "4/4 [==============================] - 2s 541ms/step - loss: 0.3643 - accuracy: 0.8697 - val_loss: 0.4737 - val_accuracy: 0.7458\n",
      "Epoch 20/30\n",
      "4/4 [==============================] - 2s 539ms/step - loss: 0.3571 - accuracy: 0.9160 - val_loss: 0.4676 - val_accuracy: 0.7797\n",
      "Epoch 21/30\n",
      "4/4 [==============================] - 2s 543ms/step - loss: 0.3414 - accuracy: 0.8866 - val_loss: 0.4638 - val_accuracy: 0.7966\n",
      "Epoch 22/30\n",
      "4/4 [==============================] - 2s 541ms/step - loss: 0.3298 - accuracy: 0.9118 - val_loss: 0.4590 - val_accuracy: 0.7627\n",
      "Epoch 23/30\n",
      "4/4 [==============================] - 2s 545ms/step - loss: 0.3138 - accuracy: 0.9076 - val_loss: 0.4529 - val_accuracy: 0.7797\n",
      "Epoch 24/30\n",
      "4/4 [==============================] - 2s 543ms/step - loss: 0.3019 - accuracy: 0.9286 - val_loss: 0.4487 - val_accuracy: 0.7966\n",
      "Epoch 25/30\n",
      "4/4 [==============================] - 2s 548ms/step - loss: 0.2988 - accuracy: 0.9286 - val_loss: 0.4448 - val_accuracy: 0.7797\n",
      "Epoch 26/30\n",
      "4/4 [==============================] - 2s 542ms/step - loss: 0.2968 - accuracy: 0.9370 - val_loss: 0.4442 - val_accuracy: 0.7627\n",
      "Epoch 27/30\n",
      "4/4 [==============================] - 2s 542ms/step - loss: 0.2994 - accuracy: 0.9202 - val_loss: 0.4413 - val_accuracy: 0.7966\n",
      "Epoch 28/30\n",
      "4/4 [==============================] - 2s 537ms/step - loss: 0.2816 - accuracy: 0.9244 - val_loss: 0.4382 - val_accuracy: 0.7966\n",
      "Epoch 29/30\n",
      "4/4 [==============================] - 2s 538ms/step - loss: 0.2726 - accuracy: 0.9160 - val_loss: 0.4366 - val_accuracy: 0.7797\n",
      "Epoch 30/30\n",
      "4/4 [==============================] - 2s 545ms/step - loss: 0.2482 - accuracy: 0.9538 - val_loss: 0.4317 - val_accuracy: 0.7966\n",
      "Found 238 validated image filenames belonging to 3 classes.\n",
      "Found 59 validated image filenames belonging to 3 classes.\n",
      "Found 100 validated image filenames belonging to 3 classes.\n",
      "Found 238 validated image filenames belonging to 3 classes.\n",
      "Found 59 validated image filenames belonging to 3 classes.\n",
      "Found 100 validated image filenames belonging to 3 classes.\n",
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "AP(Mortise) (InputLayer)        [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Lateral (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "resnet50 (Functional)           (None, 2048)         23587712    AP(Mortise)[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "efficientnetb0 (Functional)     (None, 1280)         4049571     Lateral[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "AP_dense_128 (Dense)            (None, 128)          262272      resnet50[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Lateral_dense_128 (Dense)       (None, 128)          163968      efficientnetb0[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "AP_dense_50 (Dense)             (None, 50)           6450        AP_dense_128[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Lateral_dense_50 (Dense)        (None, 50)           6450        Lateral_dense_128[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "feature_fusion (Concatenate)    (None, 100)          0           AP_dense_50[0][0]                \n",
      "                                                                 Lateral_dense_50[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 100)          0           feature_fusion[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "output_layer (Dense)            (None, 3)            303         dropout_5[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 28,076,726\n",
      "Trainable params: 439,443\n",
      "Non-trainable params: 27,637,283\n",
      "__________________________________________________________________________________________________\n",
      "-------Training_concat1_踢盲檢_測盲檢-------\n",
      "Epoch 1/30\n",
      "4/4 [==============================] - 6s 787ms/step - loss: 1.2512 - accuracy: 0.2941 - val_loss: 1.0757 - val_accuracy: 0.4915\n",
      "Epoch 2/30\n",
      "4/4 [==============================] - 2s 611ms/step - loss: 1.0680 - accuracy: 0.4832 - val_loss: 1.0047 - val_accuracy: 0.4915\n",
      "Epoch 3/30\n",
      "4/4 [==============================] - 2s 547ms/step - loss: 0.9449 - accuracy: 0.5714 - val_loss: 0.9202 - val_accuracy: 0.6271\n",
      "Epoch 4/30\n",
      "4/4 [==============================] - 2s 550ms/step - loss: 0.8531 - accuracy: 0.6513 - val_loss: 0.8573 - val_accuracy: 0.6949\n",
      "Epoch 5/30\n",
      "4/4 [==============================] - 2s 543ms/step - loss: 0.7941 - accuracy: 0.6849 - val_loss: 0.8086 - val_accuracy: 0.6780\n",
      "Epoch 6/30\n",
      "4/4 [==============================] - 2s 545ms/step - loss: 0.7192 - accuracy: 0.7563 - val_loss: 0.7677 - val_accuracy: 0.6610\n",
      "Epoch 7/30\n",
      "4/4 [==============================] - 2s 546ms/step - loss: 0.6678 - accuracy: 0.7437 - val_loss: 0.7393 - val_accuracy: 0.6441\n",
      "Epoch 8/30\n",
      "4/4 [==============================] - 2s 546ms/step - loss: 0.6333 - accuracy: 0.7227 - val_loss: 0.7132 - val_accuracy: 0.6610\n",
      "Epoch 9/30\n",
      "4/4 [==============================] - 2s 551ms/step - loss: 0.5873 - accuracy: 0.7731 - val_loss: 0.6894 - val_accuracy: 0.6441\n",
      "Epoch 10/30\n",
      "4/4 [==============================] - 2s 544ms/step - loss: 0.5425 - accuracy: 0.8067 - val_loss: 0.6720 - val_accuracy: 0.6441\n",
      "Epoch 11/30\n",
      "4/4 [==============================] - 2s 544ms/step - loss: 0.5182 - accuracy: 0.8025 - val_loss: 0.6615 - val_accuracy: 0.6441\n",
      "Epoch 12/30\n",
      "4/4 [==============================] - 2s 542ms/step - loss: 0.4881 - accuracy: 0.8319 - val_loss: 0.6518 - val_accuracy: 0.6271\n",
      "Epoch 13/30\n",
      "4/4 [==============================] - 2s 543ms/step - loss: 0.4634 - accuracy: 0.8571 - val_loss: 0.6410 - val_accuracy: 0.6610\n",
      "Epoch 14/30\n",
      "4/4 [==============================] - 2s 546ms/step - loss: 0.4608 - accuracy: 0.8529 - val_loss: 0.6351 - val_accuracy: 0.6441\n",
      "Epoch 15/30\n",
      "4/4 [==============================] - 2s 547ms/step - loss: 0.4248 - accuracy: 0.8613 - val_loss: 0.6299 - val_accuracy: 0.6441\n",
      "Epoch 16/30\n",
      "4/4 [==============================] - 2s 548ms/step - loss: 0.4154 - accuracy: 0.8908 - val_loss: 0.6223 - val_accuracy: 0.6610\n",
      "Epoch 17/30\n",
      "4/4 [==============================] - 2s 548ms/step - loss: 0.3870 - accuracy: 0.8950 - val_loss: 0.6166 - val_accuracy: 0.6610\n",
      "Epoch 18/30\n",
      "4/4 [==============================] - 2s 548ms/step - loss: 0.3724 - accuracy: 0.8739 - val_loss: 0.6106 - val_accuracy: 0.6610\n",
      "Epoch 19/30\n",
      "4/4 [==============================] - 2s 547ms/step - loss: 0.3792 - accuracy: 0.8866 - val_loss: 0.6075 - val_accuracy: 0.6610\n",
      "Epoch 20/30\n",
      "4/4 [==============================] - 2s 544ms/step - loss: 0.3596 - accuracy: 0.8824 - val_loss: 0.6079 - val_accuracy: 0.6271\n",
      "Epoch 21/30\n",
      "4/4 [==============================] - 2s 544ms/step - loss: 0.3594 - accuracy: 0.8992 - val_loss: 0.6105 - val_accuracy: 0.6271\n",
      "Epoch 22/30\n",
      "4/4 [==============================] - 2s 543ms/step - loss: 0.3448 - accuracy: 0.8824 - val_loss: 0.6108 - val_accuracy: 0.6441\n",
      "Epoch 23/30\n",
      "4/4 [==============================] - 2s 544ms/step - loss: 0.3299 - accuracy: 0.9202 - val_loss: 0.6036 - val_accuracy: 0.6441\n",
      "Epoch 24/30\n",
      "4/4 [==============================] - 2s 543ms/step - loss: 0.3099 - accuracy: 0.9370 - val_loss: 0.5999 - val_accuracy: 0.6441\n",
      "Epoch 25/30\n",
      "4/4 [==============================] - 2s 542ms/step - loss: 0.3058 - accuracy: 0.9160 - val_loss: 0.5974 - val_accuracy: 0.6441\n",
      "Epoch 26/30\n",
      "4/4 [==============================] - 2s 543ms/step - loss: 0.2908 - accuracy: 0.9286 - val_loss: 0.5942 - val_accuracy: 0.6441\n",
      "Epoch 27/30\n",
      "4/4 [==============================] - 2s 549ms/step - loss: 0.2829 - accuracy: 0.9244 - val_loss: 0.5915 - val_accuracy: 0.6441\n",
      "Epoch 28/30\n",
      "4/4 [==============================] - 2s 552ms/step - loss: 0.2786 - accuracy: 0.9244 - val_loss: 0.5907 - val_accuracy: 0.6441\n",
      "Epoch 29/30\n",
      "4/4 [==============================] - 2s 551ms/step - loss: 0.2822 - accuracy: 0.9328 - val_loss: 0.5919 - val_accuracy: 0.6441\n",
      "Epoch 30/30\n",
      "4/4 [==============================] - 2s 547ms/step - loss: 0.2799 - accuracy: 0.9244 - val_loss: 0.5919 - val_accuracy: 0.6441\n",
      "acc mean = 0.75, std = 0.02, test_acc = [0.74, 0.75, 0.75, 0.72, 0.77]\n",
      "f1  mean = 0.74, std = 0.01, test_f1 = [0.73, 0.74, 0.74, 0.72, 0.76]\n"
     ]
    }
   ],
   "source": [
    "# import\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path\n",
    "# import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import os\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from tensorflow.keras.layers import Input, Dense, Concatenate, Dropout\n",
    "import math\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "## label\n",
    "# =========================\n",
    "def class_2_type(root):\n",
    "    label = \"\"\n",
    "    if \"正常\" in root:\n",
    "        label = \"0\"\n",
    "    else:\n",
    "        label = \"1\"\n",
    "    return label\n",
    "\n",
    "def class_3_type(root):\n",
    "    label = \"\"\n",
    "    if \"正常\" in root:\n",
    "        label = \"0\"\n",
    "    elif \"雙踝\" in root:\n",
    "        label = \"1\"\n",
    "    elif \"三踝\" in root:\n",
    "        label = \"2\"\n",
    "    return label\n",
    "# =========================\n",
    "\n",
    "\n",
    "def load_path(path, class_count):\n",
    "    dataset = []\n",
    "    class_type = ''\n",
    "    if class_count == 2:\n",
    "        class_type = class_2_type\n",
    "    elif class_count == 3:\n",
    "        class_type = class_3_type  \n",
    "\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            label = class_type(root)\n",
    "            # if label != \"\":\n",
    "            dataset.append(\n",
    "                            {   \n",
    "                                'uuid': root.split(\"\\\\\")[-1],\n",
    "                                'label': label,\n",
    "                                'image_path': os.path.join(root, file)\n",
    "                            }\n",
    "                        )\n",
    "\n",
    "    return dataset\n",
    "\n",
    "def create_front_extract():\n",
    "    pretrained_model_chosen = tf.keras.applications.resnet50.ResNet50\n",
    "    pretrained_model = pretrained_model_chosen(\n",
    "        input_shape=(224, 224, 3),\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        pooling='avg')\n",
    "    pretrained_model.trainable = False\n",
    "    return pretrained_model\n",
    "\n",
    "def create_side_extract():\n",
    "    pretrained_model_chosen = tf.keras.applications.efficientnet.EfficientNetB0\n",
    "    pretrained_model = pretrained_model_chosen(\n",
    "        input_shape=(224, 224, 3),\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        pooling='avg')\n",
    "    pretrained_model.trainable = False\n",
    "    return pretrained_model\n",
    "\n",
    "def multi_input_generator(front_gen, side_gen):\n",
    "    while True:\n",
    "        front_batch, y1 = next(front_gen)\n",
    "        side_batch, y2 = next(side_gen)\n",
    "        assert (y1 == y2).all(), \"Label mismatch!\"  # 確保標籤一致\n",
    "        yield ([front_batch, side_batch], y1)\n",
    "\n",
    "\n",
    "# def train_cross_validation(image_dir, n_splits=5, class_count=2, maru_part=None,  chosen_model='resnet50'):\n",
    "def train_cross_validation(image_dir, image_dir2, n_splits=5, class_count=2):\n",
    "\n",
    "\n",
    "    ## load data and  labels\n",
    "    # =========================\n",
    "    labels = []\n",
    "    filepaths = []\n",
    "    data = load_path(image_dir, class_count)\n",
    "    for row in data:\n",
    "        labels.append(row['label'])\n",
    "        filepaths.append(row['image_path'])\n",
    "\n",
    "    filepaths = pd.Series(filepaths, name='Filepath').astype(str)\n",
    "    labels = pd.Series(labels, name='Label')\n",
    "\n",
    "    images = pd.concat([filepaths, labels], axis=1)\n",
    "    # =========================\n",
    "\n",
    "    ## load data and  labels\n",
    "    # =========================\n",
    "    data2 = load_path(image_dir2, class_count)\n",
    "    labels = []\n",
    "    filepaths = []\n",
    "    for row in data2:\n",
    "        labels.append(row['label'])\n",
    "        filepaths.append(row['image_path'])\n",
    "\n",
    "    filepaths = pd.Series(filepaths, name='Filepath').astype(str)\n",
    "    labels = pd.Series(labels, name='Label')\n",
    "\n",
    "    images2 = pd.concat([filepaths, labels], axis=1)\n",
    "    # =========================\n",
    "\n",
    "    ## split image\n",
    "    # =========================\n",
    "    # train_df_front, val_df_front = train_test_split(images, train_size=0.8, shuffle=True, random_state=1, stratify=images['Label'])\n",
    "    # train_df_front, test_df_front = train_test_split(images, train_size=0.8, shuffle=True, random_state=1, stratify=images['Label'])\n",
    "    train_df_front = images.sample(frac=1, random_state=42)\n",
    "    test_df_front = images2\n",
    "    print(\"Training set label distribution:\\n\", train_df_front['Label'].value_counts(normalize=False))\n",
    "    print(\"Test set label distribution:\\n\", test_df_front['Label'].value_counts(normalize=False))\n",
    "    # =========================\n",
    "\n",
    "    preprocessing_function_chosen_front = tf.keras.applications.resnet50.preprocess_input\n",
    "    preprocessing_function_chosen_side = tf.keras.applications.efficientnet.preprocess_input\n",
    "\n",
    "\n",
    "    ## train model, k fold cross validation\n",
    "    # ==================================================\n",
    "    fold_no = 1\n",
    "    test_acc = []\n",
    "    test_f1 = []\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=1)\n",
    "    for train_index, val_index in kfold.split(train_df_front, train_df_front['Label']):\n",
    "        k_fold_train_front = train_df_front.iloc[train_index]\n",
    "        k_fold_val_front = train_df_front.iloc[val_index]\n",
    "\n",
    "        # front images\n",
    "        # =========================\n",
    "        train_generator_front = tf.keras.preprocessing.image.ImageDataGenerator(horizontal_flip=False,\n",
    "                                                                                preprocessing_function=preprocessing_function_chosen_front)\n",
    "        test_generator_front = tf.keras.preprocessing.image.ImageDataGenerator(preprocessing_function=preprocessing_function_chosen_front)\n",
    "\n",
    "        train_images_front = train_generator_front.flow_from_dataframe(\n",
    "            dataframe=k_fold_train_front,\n",
    "            x_col='Filepath',\n",
    "            y_col='Label',\n",
    "            target_size=(224, 224),\n",
    "            color_mode='rgb',\n",
    "            class_mode='categorical',\n",
    "            batch_size=64,\n",
    "            shuffle=False,\n",
    "            seed=42\n",
    "        )\n",
    "\n",
    "        val_images_front = train_generator_front.flow_from_dataframe(\n",
    "            dataframe=k_fold_val_front,\n",
    "            x_col='Filepath',\n",
    "            y_col='Label',\n",
    "            target_size=(224, 224),\n",
    "            color_mode='rgb',\n",
    "            class_mode='categorical',\n",
    "            batch_size=64,\n",
    "            shuffle=False,\n",
    "            seed=42\n",
    "        )\n",
    "\n",
    "        test_images_front = test_generator_front.flow_from_dataframe(\n",
    "            dataframe=test_df_front,\n",
    "            x_col='Filepath',\n",
    "            y_col='Label',\n",
    "            target_size=(224, 224),\n",
    "            color_mode='rgb',\n",
    "            class_mode='categorical',\n",
    "            batch_size=32,\n",
    "            shuffle=False\n",
    "        )\n",
    "        # =========================   \n",
    "\n",
    "        # side images\n",
    "        # =========================\n",
    "        train_df_side = train_df_front.copy()\n",
    "        test_df_side = test_df_front.copy()\n",
    "        train_df_side.loc[:, \"Filepath\"] = train_df_front[\"Filepath\"].str.replace(\"front\", \"side\")\n",
    "        test_df_side.loc[:, \"Filepath\"] = test_df_side[\"Filepath\"].str.replace(\"front\", \"side\")\n",
    "\n",
    "        k_fold_train_side = train_df_side.iloc[train_index]\n",
    "        k_fold_val_side = train_df_side.iloc[val_index]\n",
    "\n",
    "        train_generator_side = tf.keras.preprocessing.image.ImageDataGenerator(horizontal_flip=False,\n",
    "                                                                                preprocessing_function=preprocessing_function_chosen_side)\n",
    "        test_generator_side = tf.keras.preprocessing.image.ImageDataGenerator(preprocessing_function=preprocessing_function_chosen_side)\n",
    "\n",
    "        train_images_side = train_generator_side.flow_from_dataframe(\n",
    "            dataframe=k_fold_train_side,\n",
    "            x_col='Filepath',\n",
    "            y_col='Label',\n",
    "            target_size=(224, 224),\n",
    "            color_mode='rgb',\n",
    "            class_mode='categorical',\n",
    "            batch_size=64,\n",
    "            shuffle=False,\n",
    "            seed=42\n",
    "        )\n",
    "\n",
    "        val_images_side = train_generator_side.flow_from_dataframe(\n",
    "            dataframe=k_fold_val_side,\n",
    "            x_col='Filepath',\n",
    "            y_col='Label',\n",
    "            target_size=(224, 224),\n",
    "            color_mode='rgb',\n",
    "            class_mode='categorical',\n",
    "            batch_size=64,\n",
    "            shuffle=False,\n",
    "            seed=42\n",
    "        )\n",
    "\n",
    "        test_images_side = test_generator_side.flow_from_dataframe(\n",
    "            dataframe=test_df_side,\n",
    "            x_col='Filepath',\n",
    "            y_col='Label',\n",
    "            target_size=(224, 224),\n",
    "            color_mode='rgb',\n",
    "            class_mode='categorical',\n",
    "            batch_size=32,\n",
    "            shuffle=False\n",
    "        )\n",
    "        # ========================= \n",
    "        \n",
    "        # load model\n",
    "        # =========================\n",
    "        # input \n",
    "        input_front = Input(shape=(224, 224, 3), name=\"AP(Mortise)\")\n",
    "        input_side = Input(shape=(224, 224, 3), name=\"Lateral\")\n",
    "\n",
    "        # model\n",
    "        model_front = create_front_extract()\n",
    "        model_side = create_side_extract()\n",
    "\n",
    "        features_front = model_front(input_front)\n",
    "        features_side = model_side(input_side)\n",
    "\n",
    "        features_front_x = tf.keras.layers.Dense(128, activation='relu', name='AP_dense_128')(features_front)\n",
    "        features_front_x = tf.keras.layers.Dense(50, activation='relu', name='AP_dense_50')(features_front_x)\n",
    "\n",
    "        features_side_x = tf.keras.layers.Dense(128, activation='relu', name='Lateral_dense_128')(features_side)\n",
    "        features_side_x = tf.keras.layers.Dense(50, activation='relu', name='Lateral_dense_50')(features_side_x)\n",
    "\n",
    "        fused_features = Concatenate(name=\"feature_fusion\")([features_front_x, features_side_x])\n",
    "        # fused_features = tf.keras.layers.Dense(50, activation='relu', name='fusion_dense_50')(fused_features)\n",
    "        fused_features = Dropout(0.1)(fused_features)\n",
    "\n",
    "        final_output = Dense(class_count, activation='sigmoid', name='output_layer')(fused_features)\n",
    "        multi_view_model = None\n",
    "        multi_view_model = Model(\n",
    "            inputs=[input_front, input_side],\n",
    "            outputs=final_output\n",
    "        )\n",
    "        multi_view_model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        multi_view_model.summary()\n",
    "        # print(model.summary())\n",
    "        # =========================\n",
    "\n",
    "        train_generator = multi_input_generator(train_images_front, train_images_side)\n",
    "        val_generator = multi_input_generator(val_images_front, val_images_side)\n",
    "        \n",
    "        ## compile and evaluate\n",
    "        # =========================\n",
    "\n",
    "        print(\"-------Training_\" + concat_type + \"-------\")\n",
    "        multi_view_model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "        batch_size = 64\n",
    "        ## early stop \n",
    "        # early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)\n",
    "        # multi_view_model.fit(train_generator, validation_data=val_generator, callbacks=[early_stopping], epochs=30,\n",
    "        #                             steps_per_epoch= math.ceil(train_images_front.samples / batch_size), \n",
    "        #                             validation_steps= math.ceil(val_images_front.samples / batch_size))\n",
    "        ## no early stop\n",
    "        multi_view_model.fit(train_generator, validation_data=val_generator, epochs=30,\n",
    "                            steps_per_epoch= math.ceil(train_images_front.samples / batch_size), \n",
    "                            validation_steps= math.ceil(val_images_front.samples / batch_size))\n",
    "\n",
    "        # =========================\n",
    "\n",
    "        test_generator = multi_input_generator(test_images_front, test_images_side)\n",
    "        batch_size=32\n",
    "        pred = multi_view_model.predict(test_generator,  steps=math.ceil(test_images_front.samples / batch_size))\n",
    "        predicted_labels = np.argmax(pred, axis=1)\n",
    "\n",
    "        # =========================\n",
    "            \n",
    "        ## print results\n",
    "        # =========================\n",
    "        acc = accuracy_score(test_images_front.labels, predicted_labels)\n",
    "\n",
    "        test_acc.append(np.round(acc, 2))\n",
    "        f1 = f1_score(test_images_front.labels, predicted_labels, average='macro')\n",
    "        test_f1.append(np.round(f1, 2))\n",
    "        fold_no += 1\n",
    "        # =========================\n",
    "    # ==================================================\n",
    "        \n",
    "    ## print  mean results\n",
    "    # =========================\n",
    "    acc_mean  = np.round(np.mean(test_acc), 2)\n",
    "    acc_std = np.round(np.std(test_acc), 2)\n",
    "    f1_mean  = np.round(np.mean(test_f1), 2)\n",
    "    f1_std = np.round(np.std(test_f1), 2)\n",
    "    # print(f\"acc mean = {acc_mean}, std = {acc_std}\")\n",
    "    # print(test_acc)\n",
    "    # print(f\"f1  mean = {f1_mean}, std = {f1_std}\")\n",
    "    # print(test_f1)\n",
    "    # =========================\n",
    "\n",
    "    return {'acc_mean':acc_mean, 'acc_std':acc_std, 'test_acc':test_acc, 'f1_mean':f1_mean, 'f1_std':f1_std, 'test_f1':test_f1}\n",
    "\n",
    "# =========================\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "results = []\n",
    "results = train_cross_validation(image_dir=path,image_dir2=path2, class_count=3)\n",
    "\n",
    "\n",
    "print(f\"acc mean = {results['acc_mean']}, std = {results['acc_std']}, test_acc = {results['test_acc']}\")\n",
    "print(f\"f1  mean = {results['f1_mean']}, std = {results['f1_std']}, test_f1 = {results['test_f1']}\")\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set label distribution:\n",
      " 0    126\n",
      "2     87\n",
      "1     84\n",
      "Name: Label, dtype: int64\n",
      "Test set label distribution:\n",
      " 2    35\n",
      "0    34\n",
      "1    31\n",
      "Name: Label, dtype: int64\n",
      "Found 237 validated image filenames belonging to 3 classes.\n",
      "Found 60 validated image filenames belonging to 3 classes.\n",
      "Found 100 validated image filenames belonging to 3 classes.\n",
      "Found 237 validated image filenames belonging to 3 classes.\n",
      "Found 60 validated image filenames belonging to 3 classes.\n",
      "Found 100 validated image filenames belonging to 3 classes.\n",
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "AP(Mortise) (InputLayer)        [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Lateral (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "resnet50 (Functional)           (None, 2048)         23587712    AP(Mortise)[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "efficientnetb0 (Functional)     (None, 1280)         4049571     Lateral[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "AP_dense_128 (Dense)            (None, 128)          262272      resnet50[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Lateral_dense_128 (Dense)       (None, 128)          163968      efficientnetb0[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "AP_dense_50 (Dense)             (None, 50)           6450        AP_dense_128[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Lateral_dense_50 (Dense)        (None, 50)           6450        Lateral_dense_128[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "feature_fusion (Concatenate)    (None, 100)          0           AP_dense_50[0][0]                \n",
      "                                                                 Lateral_dense_50[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 100)          0           feature_fusion[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "output_layer (Dense)            (None, 3)            303         dropout_6[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 28,076,726\n",
      "Trainable params: 439,443\n",
      "Non-trainable params: 27,637,283\n",
      "__________________________________________________________________________________________________\n",
      "-------Training_concat1_踢盲檢_測盲檢-------\n",
      "Epoch 1/30\n",
      "4/4 [==============================] - 6s 787ms/step - loss: 1.2578 - accuracy: 0.2616 - val_loss: 1.0749 - val_accuracy: 0.4667\n",
      "Epoch 2/30\n",
      "4/4 [==============================] - 2s 589ms/step - loss: 1.0626 - accuracy: 0.4557 - val_loss: 0.9775 - val_accuracy: 0.4833\n",
      "Epoch 3/30\n",
      "4/4 [==============================] - 2s 625ms/step - loss: 0.9575 - accuracy: 0.5190 - val_loss: 0.8962 - val_accuracy: 0.6667\n",
      "Epoch 4/30\n",
      "4/4 [==============================] - 2s 547ms/step - loss: 0.8783 - accuracy: 0.6076 - val_loss: 0.8466 - val_accuracy: 0.7000\n",
      "Epoch 5/30\n",
      "4/4 [==============================] - 2s 585ms/step - loss: 0.8149 - accuracy: 0.7257 - val_loss: 0.7931 - val_accuracy: 0.7333\n",
      "Epoch 6/30\n",
      "4/4 [==============================] - 2s 602ms/step - loss: 0.7534 - accuracy: 0.7215 - val_loss: 0.7424 - val_accuracy: 0.7167\n",
      "Epoch 7/30\n",
      "4/4 [==============================] - 2s 532ms/step - loss: 0.7129 - accuracy: 0.7300 - val_loss: 0.6996 - val_accuracy: 0.7333\n",
      "Epoch 8/30\n",
      "4/4 [==============================] - 2s 542ms/step - loss: 0.6334 - accuracy: 0.7848 - val_loss: 0.6636 - val_accuracy: 0.7333\n",
      "Epoch 9/30\n",
      "4/4 [==============================] - 2s 535ms/step - loss: 0.6184 - accuracy: 0.7553 - val_loss: 0.6347 - val_accuracy: 0.7500\n",
      "Epoch 10/30\n",
      "4/4 [==============================] - 2s 543ms/step - loss: 0.5619 - accuracy: 0.8228 - val_loss: 0.6127 - val_accuracy: 0.7333\n",
      "Epoch 11/30\n",
      "4/4 [==============================] - 2s 541ms/step - loss: 0.5308 - accuracy: 0.8228 - val_loss: 0.5931 - val_accuracy: 0.7333\n",
      "Epoch 12/30\n",
      "4/4 [==============================] - 2s 536ms/step - loss: 0.5184 - accuracy: 0.8143 - val_loss: 0.5770 - val_accuracy: 0.7500\n",
      "Epoch 13/30\n",
      "4/4 [==============================] - 2s 543ms/step - loss: 0.4900 - accuracy: 0.8143 - val_loss: 0.5660 - val_accuracy: 0.7500\n",
      "Epoch 14/30\n",
      "4/4 [==============================] - 2s 541ms/step - loss: 0.4545 - accuracy: 0.8650 - val_loss: 0.5560 - val_accuracy: 0.7667\n",
      "Epoch 15/30\n",
      "4/4 [==============================] - 2s 544ms/step - loss: 0.4423 - accuracy: 0.8481 - val_loss: 0.5472 - val_accuracy: 0.7833\n",
      "Epoch 16/30\n",
      "4/4 [==============================] - 2s 541ms/step - loss: 0.4246 - accuracy: 0.8776 - val_loss: 0.5406 - val_accuracy: 0.7833\n",
      "Epoch 17/30\n",
      "4/4 [==============================] - 2s 541ms/step - loss: 0.4008 - accuracy: 0.8650 - val_loss: 0.5329 - val_accuracy: 0.8000\n",
      "Epoch 18/30\n",
      "4/4 [==============================] - 2s 540ms/step - loss: 0.3937 - accuracy: 0.8776 - val_loss: 0.5228 - val_accuracy: 0.8167\n",
      "Epoch 19/30\n",
      "4/4 [==============================] - 2s 541ms/step - loss: 0.3711 - accuracy: 0.9030 - val_loss: 0.5175 - val_accuracy: 0.8167\n",
      "Epoch 20/30\n",
      "4/4 [==============================] - 2s 545ms/step - loss: 0.3685 - accuracy: 0.8945 - val_loss: 0.5137 - val_accuracy: 0.8167\n",
      "Epoch 21/30\n",
      "4/4 [==============================] - 2s 541ms/step - loss: 0.3480 - accuracy: 0.8903 - val_loss: 0.5082 - val_accuracy: 0.8167\n",
      "Epoch 22/30\n",
      "4/4 [==============================] - 2s 545ms/step - loss: 0.3393 - accuracy: 0.9072 - val_loss: 0.5045 - val_accuracy: 0.8167\n",
      "Epoch 23/30\n",
      "4/4 [==============================] - 2s 542ms/step - loss: 0.3274 - accuracy: 0.8987 - val_loss: 0.5020 - val_accuracy: 0.8167\n",
      "Found 237 validated image filenames belonging to 3 classes.\n",
      "Found 60 validated image filenames belonging to 3 classes.\n",
      "Found 100 validated image filenames belonging to 3 classes.\n",
      "Found 237 validated image filenames belonging to 3 classes.\n",
      "Found 60 validated image filenames belonging to 3 classes.\n",
      "Found 100 validated image filenames belonging to 3 classes.\n",
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "AP(Mortise) (InputLayer)        [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Lateral (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "resnet50 (Functional)           (None, 2048)         23587712    AP(Mortise)[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "efficientnetb0 (Functional)     (None, 1280)         4049571     Lateral[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "AP_dense_128 (Dense)            (None, 128)          262272      resnet50[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Lateral_dense_128 (Dense)       (None, 128)          163968      efficientnetb0[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "AP_dense_50 (Dense)             (None, 50)           6450        AP_dense_128[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Lateral_dense_50 (Dense)        (None, 50)           6450        Lateral_dense_128[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "feature_fusion (Concatenate)    (None, 100)          0           AP_dense_50[0][0]                \n",
      "                                                                 Lateral_dense_50[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 100)          0           feature_fusion[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "output_layer (Dense)            (None, 3)            303         dropout_7[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 28,076,726\n",
      "Trainable params: 439,443\n",
      "Non-trainable params: 27,637,283\n",
      "__________________________________________________________________________________________________\n",
      "-------Training_concat1_踢盲檢_測盲檢-------\n",
      "Epoch 1/30\n",
      "4/4 [==============================] - 6s 974ms/step - loss: 1.0180 - accuracy: 0.4641 - val_loss: 0.9501 - val_accuracy: 0.5333\n",
      "Epoch 2/30\n",
      "4/4 [==============================] - 2s 573ms/step - loss: 0.9059 - accuracy: 0.5738 - val_loss: 0.8564 - val_accuracy: 0.6000\n",
      "Epoch 3/30\n",
      "4/4 [==============================] - 2s 575ms/step - loss: 0.8216 - accuracy: 0.6540 - val_loss: 0.7864 - val_accuracy: 0.6333\n",
      "Epoch 4/30\n",
      "4/4 [==============================] - 2s 581ms/step - loss: 0.7592 - accuracy: 0.7257 - val_loss: 0.7332 - val_accuracy: 0.6667\n",
      "Epoch 5/30\n",
      "4/4 [==============================] - 2s 595ms/step - loss: 0.7032 - accuracy: 0.7342 - val_loss: 0.6893 - val_accuracy: 0.6667\n",
      "Epoch 6/30\n",
      "4/4 [==============================] - 2s 558ms/step - loss: 0.6511 - accuracy: 0.7553 - val_loss: 0.6571 - val_accuracy: 0.6833\n",
      "Epoch 7/30\n",
      "4/4 [==============================] - 2s 556ms/step - loss: 0.5780 - accuracy: 0.7764 - val_loss: 0.6284 - val_accuracy: 0.6667\n",
      "Epoch 8/30\n",
      "4/4 [==============================] - 2s 557ms/step - loss: 0.5574 - accuracy: 0.8059 - val_loss: 0.5970 - val_accuracy: 0.7167\n",
      "Epoch 9/30\n",
      "4/4 [==============================] - 2s 553ms/step - loss: 0.5331 - accuracy: 0.8186 - val_loss: 0.5751 - val_accuracy: 0.7167\n",
      "Epoch 10/30\n",
      "4/4 [==============================] - 2s 549ms/step - loss: 0.5064 - accuracy: 0.8143 - val_loss: 0.5600 - val_accuracy: 0.7167\n",
      "Epoch 11/30\n",
      "4/4 [==============================] - 2s 551ms/step - loss: 0.4758 - accuracy: 0.8397 - val_loss: 0.5524 - val_accuracy: 0.7000\n",
      "Epoch 12/30\n",
      "4/4 [==============================] - 2s 556ms/step - loss: 0.4570 - accuracy: 0.8523 - val_loss: 0.5395 - val_accuracy: 0.7167\n",
      "Epoch 13/30\n",
      "4/4 [==============================] - 2s 554ms/step - loss: 0.4415 - accuracy: 0.8481 - val_loss: 0.5274 - val_accuracy: 0.7500\n",
      "Epoch 14/30\n",
      "4/4 [==============================] - 2s 559ms/step - loss: 0.4100 - accuracy: 0.8776 - val_loss: 0.5223 - val_accuracy: 0.7667\n",
      "Epoch 15/30\n",
      "4/4 [==============================] - 2s 556ms/step - loss: 0.4116 - accuracy: 0.8861 - val_loss: 0.5177 - val_accuracy: 0.7667\n",
      "Epoch 16/30\n",
      "4/4 [==============================] - 2s 556ms/step - loss: 0.3955 - accuracy: 0.8776 - val_loss: 0.5181 - val_accuracy: 0.7667\n",
      "Epoch 17/30\n",
      "4/4 [==============================] - 2s 553ms/step - loss: 0.3670 - accuracy: 0.8819 - val_loss: 0.5196 - val_accuracy: 0.7667\n",
      "Epoch 18/30\n",
      "4/4 [==============================] - 2s 555ms/step - loss: 0.3721 - accuracy: 0.8819 - val_loss: 0.5123 - val_accuracy: 0.7500\n",
      "Epoch 19/30\n",
      "4/4 [==============================] - 2s 553ms/step - loss: 0.3581 - accuracy: 0.9072 - val_loss: 0.5067 - val_accuracy: 0.7833\n",
      "Epoch 20/30\n",
      "4/4 [==============================] - 2s 559ms/step - loss: 0.3499 - accuracy: 0.8819 - val_loss: 0.5031 - val_accuracy: 0.7667\n",
      "Epoch 21/30\n",
      "4/4 [==============================] - 2s 554ms/step - loss: 0.3294 - accuracy: 0.9072 - val_loss: 0.4995 - val_accuracy: 0.7500\n",
      "Epoch 22/30\n",
      "4/4 [==============================] - 2s 567ms/step - loss: 0.3034 - accuracy: 0.9409 - val_loss: 0.5065 - val_accuracy: 0.7500\n",
      "Epoch 23/30\n",
      "4/4 [==============================] - 2s 559ms/step - loss: 0.3012 - accuracy: 0.9114 - val_loss: 0.5071 - val_accuracy: 0.7500\n",
      "Epoch 24/30\n",
      "4/4 [==============================] - 2s 556ms/step - loss: 0.3031 - accuracy: 0.9241 - val_loss: 0.4973 - val_accuracy: 0.7500\n",
      "Found 238 validated image filenames belonging to 3 classes.\n",
      "Found 59 validated image filenames belonging to 3 classes.\n",
      "Found 100 validated image filenames belonging to 3 classes.\n",
      "Found 238 validated image filenames belonging to 3 classes.\n",
      "Found 59 validated image filenames belonging to 3 classes.\n",
      "Found 100 validated image filenames belonging to 3 classes.\n",
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "AP(Mortise) (InputLayer)        [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Lateral (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "resnet50 (Functional)           (None, 2048)         23587712    AP(Mortise)[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "efficientnetb0 (Functional)     (None, 1280)         4049571     Lateral[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "AP_dense_128 (Dense)            (None, 128)          262272      resnet50[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Lateral_dense_128 (Dense)       (None, 128)          163968      efficientnetb0[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "AP_dense_50 (Dense)             (None, 50)           6450        AP_dense_128[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Lateral_dense_50 (Dense)        (None, 50)           6450        Lateral_dense_128[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "feature_fusion (Concatenate)    (None, 100)          0           AP_dense_50[0][0]                \n",
      "                                                                 Lateral_dense_50[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 100)          0           feature_fusion[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "output_layer (Dense)            (None, 3)            303         dropout_8[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 28,076,726\n",
      "Trainable params: 439,443\n",
      "Non-trainable params: 27,637,283\n",
      "__________________________________________________________________________________________________\n",
      "-------Training_concat1_踢盲檢_測盲檢-------\n",
      "Epoch 1/30\n",
      "4/4 [==============================] - 6s 871ms/step - loss: 1.0412 - accuracy: 0.4664 - val_loss: 0.9663 - val_accuracy: 0.5932\n",
      "Epoch 2/30\n",
      "4/4 [==============================] - 2s 529ms/step - loss: 0.9503 - accuracy: 0.5840 - val_loss: 0.8665 - val_accuracy: 0.5932\n",
      "Epoch 3/30\n",
      "4/4 [==============================] - 2s 554ms/step - loss: 0.8453 - accuracy: 0.6345 - val_loss: 0.7743 - val_accuracy: 0.6949\n",
      "Epoch 4/30\n",
      "4/4 [==============================] - 2s 564ms/step - loss: 0.7933 - accuracy: 0.6891 - val_loss: 0.7081 - val_accuracy: 0.7966\n",
      "Epoch 5/30\n",
      "4/4 [==============================] - 2s 558ms/step - loss: 0.7425 - accuracy: 0.7017 - val_loss: 0.6538 - val_accuracy: 0.7797\n",
      "Epoch 6/30\n",
      "4/4 [==============================] - 2s 560ms/step - loss: 0.6465 - accuracy: 0.7437 - val_loss: 0.6173 - val_accuracy: 0.7966\n",
      "Epoch 7/30\n",
      "4/4 [==============================] - 2s 582ms/step - loss: 0.6179 - accuracy: 0.7563 - val_loss: 0.5836 - val_accuracy: 0.7966\n",
      "Epoch 8/30\n",
      "4/4 [==============================] - 2s 650ms/step - loss: 0.5700 - accuracy: 0.8109 - val_loss: 0.5602 - val_accuracy: 0.8136\n",
      "Epoch 9/30\n",
      "4/4 [==============================] - 2s 559ms/step - loss: 0.5763 - accuracy: 0.7815 - val_loss: 0.5378 - val_accuracy: 0.8136\n",
      "Epoch 10/30\n",
      "4/4 [==============================] - 2s 554ms/step - loss: 0.5175 - accuracy: 0.8025 - val_loss: 0.5180 - val_accuracy: 0.7966\n",
      "Epoch 11/30\n",
      "4/4 [==============================] - 2s 552ms/step - loss: 0.5022 - accuracy: 0.8235 - val_loss: 0.5040 - val_accuracy: 0.7966\n",
      "Epoch 12/30\n",
      "4/4 [==============================] - 2s 555ms/step - loss: 0.4901 - accuracy: 0.8193 - val_loss: 0.4963 - val_accuracy: 0.7627\n",
      "Epoch 13/30\n",
      "4/4 [==============================] - 2s 547ms/step - loss: 0.4485 - accuracy: 0.8529 - val_loss: 0.4861 - val_accuracy: 0.7966\n",
      "Found 238 validated image filenames belonging to 3 classes.\n",
      "Found 59 validated image filenames belonging to 3 classes.\n",
      "Found 100 validated image filenames belonging to 3 classes.\n",
      "Found 238 validated image filenames belonging to 3 classes.\n",
      "Found 59 validated image filenames belonging to 3 classes.\n",
      "Found 100 validated image filenames belonging to 3 classes.\n",
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "AP(Mortise) (InputLayer)        [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Lateral (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "resnet50 (Functional)           (None, 2048)         23587712    AP(Mortise)[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "efficientnetb0 (Functional)     (None, 1280)         4049571     Lateral[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "AP_dense_128 (Dense)            (None, 128)          262272      resnet50[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Lateral_dense_128 (Dense)       (None, 128)          163968      efficientnetb0[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "AP_dense_50 (Dense)             (None, 50)           6450        AP_dense_128[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Lateral_dense_50 (Dense)        (None, 50)           6450        Lateral_dense_128[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "feature_fusion (Concatenate)    (None, 100)          0           AP_dense_50[0][0]                \n",
      "                                                                 Lateral_dense_50[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 100)          0           feature_fusion[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "output_layer (Dense)            (None, 3)            303         dropout_9[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 28,076,726\n",
      "Trainable params: 439,443\n",
      "Non-trainable params: 27,637,283\n",
      "__________________________________________________________________________________________________\n",
      "-------Training_concat1_踢盲檢_測盲檢-------\n",
      "Epoch 1/30\n",
      "4/4 [==============================] - 6s 830ms/step - loss: 1.2982 - accuracy: 0.3403 - val_loss: 1.0631 - val_accuracy: 0.4746\n",
      "Epoch 2/30\n",
      "4/4 [==============================] - 2s 572ms/step - loss: 1.0844 - accuracy: 0.4328 - val_loss: 1.0218 - val_accuracy: 0.5932\n",
      "Epoch 3/30\n",
      "4/4 [==============================] - 2s 664ms/step - loss: 1.0251 - accuracy: 0.5210 - val_loss: 0.9314 - val_accuracy: 0.5763\n",
      "Epoch 4/30\n",
      "4/4 [==============================] - 2s 579ms/step - loss: 0.9163 - accuracy: 0.5924 - val_loss: 0.8543 - val_accuracy: 0.5932\n",
      "Epoch 5/30\n",
      "4/4 [==============================] - 2s 568ms/step - loss: 0.8393 - accuracy: 0.6387 - val_loss: 0.8032 - val_accuracy: 0.6271\n",
      "Epoch 6/30\n",
      "4/4 [==============================] - 2s 571ms/step - loss: 0.7847 - accuracy: 0.6807 - val_loss: 0.7597 - val_accuracy: 0.6441\n",
      "Epoch 7/30\n",
      "4/4 [==============================] - 2s 568ms/step - loss: 0.7139 - accuracy: 0.7815 - val_loss: 0.7167 - val_accuracy: 0.6949\n",
      "Epoch 8/30\n",
      "4/4 [==============================] - 2s 569ms/step - loss: 0.7120 - accuracy: 0.7101 - val_loss: 0.6811 - val_accuracy: 0.7458\n",
      "Epoch 9/30\n",
      "4/4 [==============================] - 2s 571ms/step - loss: 0.6553 - accuracy: 0.7899 - val_loss: 0.6501 - val_accuracy: 0.7458\n",
      "Epoch 10/30\n",
      "4/4 [==============================] - 2s 569ms/step - loss: 0.5941 - accuracy: 0.7899 - val_loss: 0.6217 - val_accuracy: 0.6780\n",
      "Epoch 11/30\n",
      "4/4 [==============================] - 2s 571ms/step - loss: 0.5758 - accuracy: 0.8361 - val_loss: 0.5993 - val_accuracy: 0.7119\n",
      "Epoch 12/30\n",
      "4/4 [==============================] - 2s 566ms/step - loss: 0.5367 - accuracy: 0.8361 - val_loss: 0.5807 - val_accuracy: 0.6949\n",
      "Epoch 13/30\n",
      "4/4 [==============================] - 2s 571ms/step - loss: 0.4924 - accuracy: 0.8571 - val_loss: 0.5627 - val_accuracy: 0.6949\n",
      "Found 238 validated image filenames belonging to 3 classes.\n",
      "Found 59 validated image filenames belonging to 3 classes.\n",
      "Found 100 validated image filenames belonging to 3 classes.\n",
      "Found 238 validated image filenames belonging to 3 classes.\n",
      "Found 59 validated image filenames belonging to 3 classes.\n",
      "Found 100 validated image filenames belonging to 3 classes.\n",
      "Model: \"model_10\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "AP(Mortise) (InputLayer)        [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Lateral (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "resnet50 (Functional)           (None, 2048)         23587712    AP(Mortise)[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "efficientnetb0 (Functional)     (None, 1280)         4049571     Lateral[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "AP_dense_128 (Dense)            (None, 128)          262272      resnet50[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Lateral_dense_128 (Dense)       (None, 128)          163968      efficientnetb0[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "AP_dense_50 (Dense)             (None, 50)           6450        AP_dense_128[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Lateral_dense_50 (Dense)        (None, 50)           6450        Lateral_dense_128[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "feature_fusion (Concatenate)    (None, 100)          0           AP_dense_50[0][0]                \n",
      "                                                                 Lateral_dense_50[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 100)          0           feature_fusion[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "output_layer (Dense)            (None, 3)            303         dropout_10[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 28,076,726\n",
      "Trainable params: 439,443\n",
      "Non-trainable params: 27,637,283\n",
      "__________________________________________________________________________________________________\n",
      "-------Training_concat1_踢盲檢_測盲檢-------\n",
      "Epoch 1/30\n",
      "4/4 [==============================] - 6s 893ms/step - loss: 1.1965 - accuracy: 0.3025 - val_loss: 1.0749 - val_accuracy: 0.5254\n",
      "Epoch 2/30\n",
      "4/4 [==============================] - 2s 588ms/step - loss: 1.0098 - accuracy: 0.5336 - val_loss: 1.0245 - val_accuracy: 0.5593\n",
      "Epoch 3/30\n",
      "4/4 [==============================] - 2s 680ms/step - loss: 0.9158 - accuracy: 0.6092 - val_loss: 0.9539 - val_accuracy: 0.5763\n",
      "Epoch 4/30\n",
      "4/4 [==============================] - 2s 680ms/step - loss: 0.7965 - accuracy: 0.7017 - val_loss: 0.8886 - val_accuracy: 0.5763\n",
      "Epoch 5/30\n",
      "4/4 [==============================] - 2s 559ms/step - loss: 0.7474 - accuracy: 0.7185 - val_loss: 0.8508 - val_accuracy: 0.5593\n",
      "Epoch 6/30\n",
      "4/4 [==============================] - 2s 563ms/step - loss: 0.7332 - accuracy: 0.7269 - val_loss: 0.8191 - val_accuracy: 0.5932\n",
      "Epoch 7/30\n",
      "4/4 [==============================] - 2s 573ms/step - loss: 0.6625 - accuracy: 0.7647 - val_loss: 0.7981 - val_accuracy: 0.5932\n",
      "Epoch 8/30\n",
      "4/4 [==============================] - 2s 567ms/step - loss: 0.6136 - accuracy: 0.8067 - val_loss: 0.7783 - val_accuracy: 0.6102\n",
      "Epoch 9/30\n",
      "4/4 [==============================] - 2s 559ms/step - loss: 0.5868 - accuracy: 0.8067 - val_loss: 0.7562 - val_accuracy: 0.6271\n",
      "Epoch 10/30\n",
      "4/4 [==============================] - 2s 573ms/step - loss: 0.5504 - accuracy: 0.8151 - val_loss: 0.7324 - val_accuracy: 0.6102\n",
      "Epoch 11/30\n",
      "4/4 [==============================] - 2s 564ms/step - loss: 0.5237 - accuracy: 0.8067 - val_loss: 0.7152 - val_accuracy: 0.6271\n",
      "Epoch 12/30\n",
      "4/4 [==============================] - 2s 569ms/step - loss: 0.5007 - accuracy: 0.8361 - val_loss: 0.7023 - val_accuracy: 0.6102\n",
      "Epoch 13/30\n",
      "4/4 [==============================] - 2s 561ms/step - loss: 0.4730 - accuracy: 0.8487 - val_loss: 0.6930 - val_accuracy: 0.6780\n",
      "Epoch 14/30\n",
      "4/4 [==============================] - 2s 561ms/step - loss: 0.4665 - accuracy: 0.8361 - val_loss: 0.6853 - val_accuracy: 0.6610\n",
      "Epoch 15/30\n",
      "4/4 [==============================] - 2s 560ms/step - loss: 0.4345 - accuracy: 0.8613 - val_loss: 0.6719 - val_accuracy: 0.6610\n",
      "Epoch 16/30\n",
      "4/4 [==============================] - 2s 562ms/step - loss: 0.4383 - accuracy: 0.8445 - val_loss: 0.6623 - val_accuracy: 0.6780\n",
      "Epoch 17/30\n",
      "4/4 [==============================] - 2s 564ms/step - loss: 0.4132 - accuracy: 0.8782 - val_loss: 0.6569 - val_accuracy: 0.7119\n",
      "Epoch 18/30\n",
      "4/4 [==============================] - 2s 561ms/step - loss: 0.3926 - accuracy: 0.8866 - val_loss: 0.6555 - val_accuracy: 0.6949\n",
      "Epoch 19/30\n",
      "4/4 [==============================] - 2s 565ms/step - loss: 0.3753 - accuracy: 0.8782 - val_loss: 0.6533 - val_accuracy: 0.6780\n",
      "Epoch 20/30\n",
      "4/4 [==============================] - 2s 568ms/step - loss: 0.3562 - accuracy: 0.8992 - val_loss: 0.6459 - val_accuracy: 0.6949\n",
      "Epoch 21/30\n",
      "4/4 [==============================] - 2s 567ms/step - loss: 0.3492 - accuracy: 0.8950 - val_loss: 0.6419 - val_accuracy: 0.6610\n",
      "Epoch 22/30\n",
      "4/4 [==============================] - 2s 560ms/step - loss: 0.3222 - accuracy: 0.9244 - val_loss: 0.6403 - val_accuracy: 0.6780\n",
      "acc mean = 0.7, std = 0.05, test_acc = [0.78, 0.65, 0.69, 0.65, 0.74]\n",
      "f1  mean = 0.69, std = 0.05, test_f1 = [0.77, 0.64, 0.67, 0.63, 0.73]\n"
     ]
    }
   ],
   "source": [
    "# import\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path\n",
    "# import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import os\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from tensorflow.keras.layers import Input, Dense, Concatenate, Dropout\n",
    "import math\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "## label\n",
    "# =========================\n",
    "def class_2_type(root):\n",
    "    label = \"\"\n",
    "    if \"正常\" in root:\n",
    "        label = \"0\"\n",
    "    else:\n",
    "        label = \"1\"\n",
    "    return label\n",
    "\n",
    "def class_3_type(root):\n",
    "    label = \"\"\n",
    "    if \"正常\" in root:\n",
    "        label = \"0\"\n",
    "    elif \"雙踝\" in root:\n",
    "        label = \"1\"\n",
    "    elif \"三踝\" in root:\n",
    "        label = \"2\"\n",
    "    return label\n",
    "# =========================\n",
    "\n",
    "\n",
    "def load_path(path, class_count):\n",
    "    dataset = []\n",
    "    class_type = ''\n",
    "    if class_count == 2:\n",
    "        class_type = class_2_type\n",
    "    elif class_count == 3:\n",
    "        class_type = class_3_type  \n",
    "\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            label = class_type(root)\n",
    "            # if label != \"\":\n",
    "            dataset.append(\n",
    "                            {   \n",
    "                                'uuid': root.split(\"\\\\\")[-1],\n",
    "                                'label': label,\n",
    "                                'image_path': os.path.join(root, file)\n",
    "                            }\n",
    "                        )\n",
    "\n",
    "    return dataset\n",
    "\n",
    "def create_front_extract():\n",
    "    pretrained_model_chosen = tf.keras.applications.resnet50.ResNet50\n",
    "    pretrained_model = pretrained_model_chosen(\n",
    "        input_shape=(224, 224, 3),\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        pooling='avg')\n",
    "    pretrained_model.trainable = False\n",
    "    return pretrained_model\n",
    "\n",
    "def create_side_extract():\n",
    "    pretrained_model_chosen = tf.keras.applications.efficientnet.EfficientNetB0\n",
    "    pretrained_model = pretrained_model_chosen(\n",
    "        input_shape=(224, 224, 3),\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        pooling='avg')\n",
    "    pretrained_model.trainable = False\n",
    "    return pretrained_model\n",
    "\n",
    "def multi_input_generator(front_gen, side_gen):\n",
    "    while True:\n",
    "        front_batch, y1 = next(front_gen)\n",
    "        side_batch, y2 = next(side_gen)\n",
    "        assert (y1 == y2).all(), \"Label mismatch!\"  # 確保標籤一致\n",
    "        yield ([front_batch, side_batch], y1)\n",
    "\n",
    "\n",
    "# def train_cross_validation(image_dir, n_splits=5, class_count=2, maru_part=None,  chosen_model='resnet50'):\n",
    "def train_cross_validation(image_dir, image_dir2, n_splits=5, class_count=2):\n",
    "\n",
    "\n",
    "    ## load data and  labels\n",
    "    # =========================\n",
    "    labels = []\n",
    "    filepaths = []\n",
    "    data = load_path(image_dir, class_count)\n",
    "    for row in data:\n",
    "        labels.append(row['label'])\n",
    "        filepaths.append(row['image_path'])\n",
    "\n",
    "    filepaths = pd.Series(filepaths, name='Filepath').astype(str)\n",
    "    labels = pd.Series(labels, name='Label')\n",
    "\n",
    "    images = pd.concat([filepaths, labels], axis=1)\n",
    "    # =========================\n",
    "\n",
    "    ## load data and  labels\n",
    "    # =========================\n",
    "    data2 = load_path(image_dir2, class_count)\n",
    "    labels = []\n",
    "    filepaths = []\n",
    "    for row in data2:\n",
    "        labels.append(row['label'])\n",
    "        filepaths.append(row['image_path'])\n",
    "\n",
    "    filepaths = pd.Series(filepaths, name='Filepath').astype(str)\n",
    "    labels = pd.Series(labels, name='Label')\n",
    "\n",
    "    images2 = pd.concat([filepaths, labels], axis=1)\n",
    "    # =========================\n",
    "\n",
    "    ## split image\n",
    "    # =========================\n",
    "    # train_df_front, val_df_front = train_test_split(images, train_size=0.8, shuffle=True, random_state=1, stratify=images['Label'])\n",
    "    # train_df_front, test_df_front = train_test_split(images, train_size=0.8, shuffle=True, random_state=1, stratify=images['Label'])\n",
    "    train_df_front = images.sample(frac=1, random_state=42)\n",
    "    test_df_front = images2\n",
    "    print(\"Training set label distribution:\\n\", train_df_front['Label'].value_counts(normalize=False))\n",
    "    print(\"Test set label distribution:\\n\", test_df_front['Label'].value_counts(normalize=False))\n",
    "    # =========================\n",
    "\n",
    "    preprocessing_function_chosen_front = tf.keras.applications.resnet50.preprocess_input\n",
    "    preprocessing_function_chosen_side = tf.keras.applications.efficientnet.preprocess_input\n",
    "\n",
    "\n",
    "    ## train model, k fold cross validation\n",
    "    # ==================================================\n",
    "    fold_no = 1\n",
    "    test_acc = []\n",
    "    test_f1 = []\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=1)\n",
    "    for train_index, val_index in kfold.split(train_df_front, train_df_front['Label']):\n",
    "        k_fold_train_front = train_df_front.iloc[train_index]\n",
    "        k_fold_val_front = train_df_front.iloc[val_index]\n",
    "\n",
    "        # front images\n",
    "        # =========================\n",
    "        train_generator_front = tf.keras.preprocessing.image.ImageDataGenerator(horizontal_flip=False,\n",
    "                                                                                preprocessing_function=preprocessing_function_chosen_front)\n",
    "        test_generator_front = tf.keras.preprocessing.image.ImageDataGenerator(preprocessing_function=preprocessing_function_chosen_front)\n",
    "\n",
    "        train_images_front = train_generator_front.flow_from_dataframe(\n",
    "            dataframe=k_fold_train_front,\n",
    "            x_col='Filepath',\n",
    "            y_col='Label',\n",
    "            target_size=(224, 224),\n",
    "            color_mode='rgb',\n",
    "            class_mode='categorical',\n",
    "            batch_size=64,\n",
    "            shuffle=False,\n",
    "            seed=42\n",
    "        )\n",
    "\n",
    "        val_images_front = train_generator_front.flow_from_dataframe(\n",
    "            dataframe=k_fold_val_front,\n",
    "            x_col='Filepath',\n",
    "            y_col='Label',\n",
    "            target_size=(224, 224),\n",
    "            color_mode='rgb',\n",
    "            class_mode='categorical',\n",
    "            batch_size=64,\n",
    "            shuffle=False,\n",
    "            seed=42\n",
    "        )\n",
    "\n",
    "        test_images_front = test_generator_front.flow_from_dataframe(\n",
    "            dataframe=test_df_front,\n",
    "            x_col='Filepath',\n",
    "            y_col='Label',\n",
    "            target_size=(224, 224),\n",
    "            color_mode='rgb',\n",
    "            class_mode='categorical',\n",
    "            batch_size=32,\n",
    "            shuffle=False\n",
    "        )\n",
    "        # =========================   \n",
    "\n",
    "        # side images\n",
    "        # =========================\n",
    "        train_df_side = train_df_front.copy()\n",
    "        test_df_side = test_df_front.copy()\n",
    "        train_df_side.loc[:, \"Filepath\"] = train_df_front[\"Filepath\"].str.replace(\"front\", \"side\")\n",
    "        test_df_side.loc[:, \"Filepath\"] = test_df_side[\"Filepath\"].str.replace(\"front\", \"side\")\n",
    "\n",
    "        k_fold_train_side = train_df_side.iloc[train_index]\n",
    "        k_fold_val_side = train_df_side.iloc[val_index]\n",
    "\n",
    "        train_generator_side = tf.keras.preprocessing.image.ImageDataGenerator(horizontal_flip=False,\n",
    "                                                                                preprocessing_function=preprocessing_function_chosen_side)\n",
    "        test_generator_side = tf.keras.preprocessing.image.ImageDataGenerator(preprocessing_function=preprocessing_function_chosen_side)\n",
    "\n",
    "        train_images_side = train_generator_side.flow_from_dataframe(\n",
    "            dataframe=k_fold_train_side,\n",
    "            x_col='Filepath',\n",
    "            y_col='Label',\n",
    "            target_size=(224, 224),\n",
    "            color_mode='rgb',\n",
    "            class_mode='categorical',\n",
    "            batch_size=64,\n",
    "            shuffle=False,\n",
    "            seed=42\n",
    "        )\n",
    "\n",
    "        val_images_side = train_generator_side.flow_from_dataframe(\n",
    "            dataframe=k_fold_val_side,\n",
    "            x_col='Filepath',\n",
    "            y_col='Label',\n",
    "            target_size=(224, 224),\n",
    "            color_mode='rgb',\n",
    "            class_mode='categorical',\n",
    "            batch_size=64,\n",
    "            shuffle=False,\n",
    "            seed=42\n",
    "        )\n",
    "\n",
    "        test_images_side = test_generator_side.flow_from_dataframe(\n",
    "            dataframe=test_df_side,\n",
    "            x_col='Filepath',\n",
    "            y_col='Label',\n",
    "            target_size=(224, 224),\n",
    "            color_mode='rgb',\n",
    "            class_mode='categorical',\n",
    "            batch_size=32,\n",
    "            shuffle=False\n",
    "        )\n",
    "        # ========================= \n",
    "        \n",
    "        # load model\n",
    "        # =========================\n",
    "        # input \n",
    "        input_front = Input(shape=(224, 224, 3), name=\"AP(Mortise)\")\n",
    "        input_side = Input(shape=(224, 224, 3), name=\"Lateral\")\n",
    "\n",
    "        # model\n",
    "        model_front = create_front_extract()\n",
    "        model_side = create_side_extract()\n",
    "\n",
    "        features_front = model_front(input_front)\n",
    "        features_side = model_side(input_side)\n",
    "\n",
    "        features_front_x = tf.keras.layers.Dense(128, activation='relu', name='AP_dense_128')(features_front)\n",
    "        features_front_x = tf.keras.layers.Dense(50, activation='relu', name='AP_dense_50')(features_front_x)\n",
    "\n",
    "        features_side_x = tf.keras.layers.Dense(128, activation='relu', name='Lateral_dense_128')(features_side)\n",
    "        features_side_x = tf.keras.layers.Dense(50, activation='relu', name='Lateral_dense_50')(features_side_x)\n",
    "\n",
    "        fused_features = Concatenate(name=\"feature_fusion\")([features_front_x, features_side_x])\n",
    "        # fused_features = tf.keras.layers.Dense(50, activation='relu', name='fusion_dense_50')(fused_features)\n",
    "        fused_features = Dropout(0.1)(fused_features)\n",
    "\n",
    "        final_output = Dense(class_count, activation='sigmoid', name='output_layer')(fused_features)\n",
    "        multi_view_model = None\n",
    "        multi_view_model = Model(\n",
    "            inputs=[input_front, input_side],\n",
    "            outputs=final_output\n",
    "        )\n",
    "        multi_view_model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        multi_view_model.summary()\n",
    "        # print(model.summary())\n",
    "        # =========================\n",
    "\n",
    "        train_generator = multi_input_generator(train_images_front, train_images_side)\n",
    "        val_generator = multi_input_generator(val_images_front, val_images_side)\n",
    "        \n",
    "        ## compile and evaluate\n",
    "        # =========================\n",
    "\n",
    "        print(\"-------Training_\" + concat_type + \"-------\")\n",
    "        multi_view_model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "        batch_size = 64\n",
    "        ## early stop \n",
    "        early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\n",
    "        multi_view_model.fit(train_generator, validation_data=val_generator, callbacks=[early_stopping], epochs=30,\n",
    "                                    steps_per_epoch= math.ceil(train_images_front.samples / batch_size), \n",
    "                                    validation_steps= math.ceil(val_images_front.samples / batch_size))\n",
    "        ## no early stop\n",
    "        # multi_view_model.fit(train_generator, validation_data=val_generator, epochs=30,\n",
    "        #                     steps_per_epoch= math.ceil(train_images_front.samples / batch_size), \n",
    "        #                     validation_steps= math.ceil(val_images_front.samples / batch_size))\n",
    "\n",
    "        # =========================\n",
    "\n",
    "        test_generator = multi_input_generator(test_images_front, test_images_side)\n",
    "        batch_size=32\n",
    "        pred = multi_view_model.predict(test_generator,  steps=math.ceil(test_images_front.samples / batch_size))\n",
    "        predicted_labels = np.argmax(pred, axis=1)\n",
    "\n",
    "        # =========================\n",
    "            \n",
    "        ## print results\n",
    "        # =========================\n",
    "        acc = accuracy_score(test_images_front.labels, predicted_labels)\n",
    "\n",
    "        test_acc.append(np.round(acc, 2))\n",
    "        f1 = f1_score(test_images_front.labels, predicted_labels, average='macro')\n",
    "        test_f1.append(np.round(f1, 2))\n",
    "        fold_no += 1\n",
    "        # =========================\n",
    "    # ==================================================\n",
    "        \n",
    "    ## print  mean results\n",
    "    # =========================\n",
    "    acc_mean  = np.round(np.mean(test_acc), 2)\n",
    "    acc_std = np.round(np.std(test_acc), 2)\n",
    "    f1_mean  = np.round(np.mean(test_f1), 2)\n",
    "    f1_std = np.round(np.std(test_f1), 2)\n",
    "    # print(f\"acc mean = {acc_mean}, std = {acc_std}\")\n",
    "    # print(test_acc)\n",
    "    # print(f\"f1  mean = {f1_mean}, std = {f1_std}\")\n",
    "    # print(test_f1)\n",
    "    # =========================\n",
    "\n",
    "    return {'acc_mean':acc_mean, 'acc_std':acc_std, 'test_acc':test_acc, 'f1_mean':f1_mean, 'f1_std':f1_std, 'test_f1':test_f1}\n",
    "\n",
    "# =========================\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "results = []\n",
    "results = train_cross_validation(image_dir=path,image_dir2=path2, class_count=3)\n",
    "\n",
    "\n",
    "print(f\"acc mean = {results['acc_mean']}, std = {results['acc_std']}, test_acc = {results['test_acc']}\")\n",
    "print(f\"f1  mean = {results['f1_mean']}, std = {results['f1_std']}, test_f1 = {results['test_f1']}\")\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set label distribution:\n",
      " 0    126\n",
      "2     87\n",
      "1     84\n",
      "Name: Label, dtype: int64\n",
      "Test set label distribution:\n",
      " 2    35\n",
      "0    34\n",
      "1    31\n",
      "Name: Label, dtype: int64\n",
      "Found 237 validated image filenames belonging to 3 classes.\n",
      "Found 60 validated image filenames belonging to 3 classes.\n",
      "Found 100 validated image filenames belonging to 3 classes.\n",
      "Found 237 validated image filenames belonging to 3 classes.\n",
      "Found 60 validated image filenames belonging to 3 classes.\n",
      "Found 100 validated image filenames belonging to 3 classes.\n",
      "Model: \"model_11\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "AP(Mortise) (InputLayer)        [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Lateral (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "resnet50 (Functional)           (None, 2048)         23587712    AP(Mortise)[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "efficientnetb0 (Functional)     (None, 1280)         4049571     Lateral[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "AP_dense_128 (Dense)            (None, 128)          262272      resnet50[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Lateral_dense_128 (Dense)       (None, 128)          163968      efficientnetb0[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "AP_dense_50 (Dense)             (None, 50)           6450        AP_dense_128[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Lateral_dense_50 (Dense)        (None, 50)           6450        Lateral_dense_128[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "feature_fusion (Concatenate)    (None, 100)          0           AP_dense_50[0][0]                \n",
      "                                                                 Lateral_dense_50[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 100)          0           feature_fusion[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "output_layer (Dense)            (None, 3)            303         dropout_11[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 28,076,726\n",
      "Trainable params: 439,443\n",
      "Non-trainable params: 27,637,283\n",
      "__________________________________________________________________________________________________\n",
      "-------Training_concat1_踢盲檢_測盲檢-------\n",
      "Epoch 1/30\n",
      "4/4 [==============================] - 6s 918ms/step - loss: 1.1118 - accuracy: 0.4515 - val_loss: 1.0090 - val_accuracy: 0.5500\n",
      "Epoch 2/30\n",
      "4/4 [==============================] - 2s 615ms/step - loss: 0.9647 - accuracy: 0.5781 - val_loss: 0.9286 - val_accuracy: 0.6000\n",
      "Epoch 3/30\n",
      "4/4 [==============================] - 2s 661ms/step - loss: 0.8726 - accuracy: 0.6667 - val_loss: 0.8678 - val_accuracy: 0.6000\n",
      "Epoch 4/30\n",
      "4/4 [==============================] - 2s 589ms/step - loss: 0.8263 - accuracy: 0.6920 - val_loss: 0.8158 - val_accuracy: 0.5667\n",
      "Epoch 5/30\n",
      "4/4 [==============================] - 2s 589ms/step - loss: 0.7564 - accuracy: 0.7131 - val_loss: 0.7708 - val_accuracy: 0.6833\n",
      "Epoch 6/30\n",
      "4/4 [==============================] - 2s 596ms/step - loss: 0.6981 - accuracy: 0.7764 - val_loss: 0.7363 - val_accuracy: 0.7167\n",
      "Epoch 7/30\n",
      "4/4 [==============================] - 2s 590ms/step - loss: 0.6576 - accuracy: 0.7932 - val_loss: 0.7035 - val_accuracy: 0.7500\n",
      "Epoch 8/30\n",
      "4/4 [==============================] - 2s 617ms/step - loss: 0.6210 - accuracy: 0.7890 - val_loss: 0.6763 - val_accuracy: 0.7167\n",
      "Epoch 9/30\n",
      "4/4 [==============================] - 2s 620ms/step - loss: 0.5864 - accuracy: 0.8143 - val_loss: 0.6545 - val_accuracy: 0.7167\n",
      "Epoch 10/30\n",
      "4/4 [==============================] - 2s 581ms/step - loss: 0.5371 - accuracy: 0.8228 - val_loss: 0.6340 - val_accuracy: 0.7000\n",
      "Epoch 11/30\n",
      "4/4 [==============================] - 2s 579ms/step - loss: 0.5261 - accuracy: 0.8481 - val_loss: 0.6155 - val_accuracy: 0.7500\n",
      "Epoch 12/30\n",
      "4/4 [==============================] - 2s 586ms/step - loss: 0.4753 - accuracy: 0.8776 - val_loss: 0.5989 - val_accuracy: 0.7500\n",
      "Epoch 13/30\n",
      "4/4 [==============================] - 2s 578ms/step - loss: 0.4735 - accuracy: 0.8312 - val_loss: 0.5856 - val_accuracy: 0.7500\n",
      "Epoch 14/30\n",
      "4/4 [==============================] - 2s 584ms/step - loss: 0.4490 - accuracy: 0.8565 - val_loss: 0.5724 - val_accuracy: 0.7500\n",
      "Epoch 15/30\n",
      "4/4 [==============================] - 2s 576ms/step - loss: 0.4284 - accuracy: 0.8776 - val_loss: 0.5624 - val_accuracy: 0.7333\n",
      "Epoch 16/30\n",
      "4/4 [==============================] - 2s 581ms/step - loss: 0.4096 - accuracy: 0.8819 - val_loss: 0.5537 - val_accuracy: 0.7167\n",
      "Epoch 17/30\n",
      "4/4 [==============================] - 2s 579ms/step - loss: 0.3862 - accuracy: 0.8945 - val_loss: 0.5445 - val_accuracy: 0.7167\n",
      "Found 237 validated image filenames belonging to 3 classes.\n",
      "Found 60 validated image filenames belonging to 3 classes.\n",
      "Found 100 validated image filenames belonging to 3 classes.\n",
      "Found 237 validated image filenames belonging to 3 classes.\n",
      "Found 60 validated image filenames belonging to 3 classes.\n",
      "Found 100 validated image filenames belonging to 3 classes.\n",
      "Model: \"model_12\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "AP(Mortise) (InputLayer)        [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Lateral (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "resnet50 (Functional)           (None, 2048)         23587712    AP(Mortise)[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "efficientnetb0 (Functional)     (None, 1280)         4049571     Lateral[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "AP_dense_128 (Dense)            (None, 128)          262272      resnet50[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Lateral_dense_128 (Dense)       (None, 128)          163968      efficientnetb0[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "AP_dense_50 (Dense)             (None, 50)           6450        AP_dense_128[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Lateral_dense_50 (Dense)        (None, 50)           6450        Lateral_dense_128[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "feature_fusion (Concatenate)    (None, 100)          0           AP_dense_50[0][0]                \n",
      "                                                                 Lateral_dense_50[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 100)          0           feature_fusion[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "output_layer (Dense)            (None, 3)            303         dropout_12[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 28,076,726\n",
      "Trainable params: 439,443\n",
      "Non-trainable params: 27,637,283\n",
      "__________________________________________________________________________________________________\n",
      "-------Training_concat1_踢盲檢_測盲檢-------\n",
      "Epoch 1/30\n",
      "4/4 [==============================] - 6s 957ms/step - loss: 1.0683 - accuracy: 0.4388 - val_loss: 0.9296 - val_accuracy: 0.5833\n",
      "Epoch 2/30\n",
      "4/4 [==============================] - 2s 599ms/step - loss: 0.9101 - accuracy: 0.5738 - val_loss: 0.8320 - val_accuracy: 0.6333\n",
      "Epoch 3/30\n",
      "4/4 [==============================] - 2s 660ms/step - loss: 0.7793 - accuracy: 0.7173 - val_loss: 0.7647 - val_accuracy: 0.6500\n",
      "Epoch 4/30\n",
      "4/4 [==============================] - 2s 594ms/step - loss: 0.7101 - accuracy: 0.7342 - val_loss: 0.7170 - val_accuracy: 0.6667\n",
      "Epoch 5/30\n",
      "4/4 [==============================] - 2s 577ms/step - loss: 0.6658 - accuracy: 0.7342 - val_loss: 0.6798 - val_accuracy: 0.6833\n",
      "Epoch 6/30\n",
      "4/4 [==============================] - 2s 582ms/step - loss: 0.6394 - accuracy: 0.7173 - val_loss: 0.6506 - val_accuracy: 0.6500\n",
      "Epoch 7/30\n",
      "4/4 [==============================] - 2s 585ms/step - loss: 0.5889 - accuracy: 0.7932 - val_loss: 0.6287 - val_accuracy: 0.6500\n",
      "Epoch 8/30\n",
      "4/4 [==============================] - 2s 590ms/step - loss: 0.5498 - accuracy: 0.7764 - val_loss: 0.6119 - val_accuracy: 0.6500\n",
      "Epoch 9/30\n",
      "4/4 [==============================] - 2s 583ms/step - loss: 0.5159 - accuracy: 0.8059 - val_loss: 0.6010 - val_accuracy: 0.6833\n",
      "Epoch 10/30\n",
      "4/4 [==============================] - 2s 588ms/step - loss: 0.4999 - accuracy: 0.7975 - val_loss: 0.5943 - val_accuracy: 0.6667\n",
      "Epoch 11/30\n",
      "4/4 [==============================] - 2s 582ms/step - loss: 0.4885 - accuracy: 0.8101 - val_loss: 0.5827 - val_accuracy: 0.6833\n",
      "Epoch 12/30\n",
      "4/4 [==============================] - 2s 582ms/step - loss: 0.4717 - accuracy: 0.8270 - val_loss: 0.5709 - val_accuracy: 0.7000\n",
      "Epoch 13/30\n",
      "4/4 [==============================] - 2s 585ms/step - loss: 0.4340 - accuracy: 0.8397 - val_loss: 0.5638 - val_accuracy: 0.7333\n",
      "Epoch 14/30\n",
      "4/4 [==============================] - 2s 583ms/step - loss: 0.4334 - accuracy: 0.8481 - val_loss: 0.5598 - val_accuracy: 0.7167\n",
      "Epoch 15/30\n",
      "4/4 [==============================] - 2s 586ms/step - loss: 0.3991 - accuracy: 0.8523 - val_loss: 0.5516 - val_accuracy: 0.7167\n",
      "Epoch 16/30\n",
      "4/4 [==============================] - 2s 585ms/step - loss: 0.4096 - accuracy: 0.8439 - val_loss: 0.5458 - val_accuracy: 0.7167\n",
      "Epoch 17/30\n",
      "4/4 [==============================] - 2s 588ms/step - loss: 0.3902 - accuracy: 0.8650 - val_loss: 0.5393 - val_accuracy: 0.7333\n",
      "Epoch 18/30\n",
      "4/4 [==============================] - 2s 587ms/step - loss: 0.3737 - accuracy: 0.8734 - val_loss: 0.5261 - val_accuracy: 0.7500\n",
      "Epoch 19/30\n",
      "4/4 [==============================] - 2s 577ms/step - loss: 0.3861 - accuracy: 0.8565 - val_loss: 0.5205 - val_accuracy: 0.7500\n",
      "Epoch 20/30\n",
      "4/4 [==============================] - 2s 577ms/step - loss: 0.3517 - accuracy: 0.8819 - val_loss: 0.5273 - val_accuracy: 0.7500\n",
      "Epoch 21/30\n",
      "4/4 [==============================] - 2s 577ms/step - loss: 0.3508 - accuracy: 0.8945 - val_loss: 0.5271 - val_accuracy: 0.7333\n",
      "Epoch 22/30\n",
      "4/4 [==============================] - 2s 581ms/step - loss: 0.3210 - accuracy: 0.9114 - val_loss: 0.5134 - val_accuracy: 0.7500\n",
      "Epoch 23/30\n",
      "4/4 [==============================] - 2s 574ms/step - loss: 0.3288 - accuracy: 0.8987 - val_loss: 0.5094 - val_accuracy: 0.7500\n",
      "Epoch 24/30\n",
      "4/4 [==============================] - 2s 581ms/step - loss: 0.3146 - accuracy: 0.9072 - val_loss: 0.5108 - val_accuracy: 0.7500\n",
      "Epoch 25/30\n",
      "4/4 [==============================] - 2s 574ms/step - loss: 0.2886 - accuracy: 0.9367 - val_loss: 0.5070 - val_accuracy: 0.7500\n",
      "Epoch 26/30\n",
      "4/4 [==============================] - 2s 582ms/step - loss: 0.2888 - accuracy: 0.9072 - val_loss: 0.5042 - val_accuracy: 0.7833\n",
      "Epoch 27/30\n",
      "4/4 [==============================] - 2s 585ms/step - loss: 0.2799 - accuracy: 0.8987 - val_loss: 0.4989 - val_accuracy: 0.7833\n",
      "Epoch 28/30\n",
      "4/4 [==============================] - 2s 579ms/step - loss: 0.2843 - accuracy: 0.9198 - val_loss: 0.4977 - val_accuracy: 0.7833\n",
      "Epoch 29/30\n",
      "4/4 [==============================] - 2s 584ms/step - loss: 0.2822 - accuracy: 0.9367 - val_loss: 0.4948 - val_accuracy: 0.7833\n",
      "Epoch 30/30\n",
      "4/4 [==============================] - 2s 583ms/step - loss: 0.2573 - accuracy: 0.9409 - val_loss: 0.4916 - val_accuracy: 0.8000\n",
      "Found 238 validated image filenames belonging to 3 classes.\n",
      "Found 59 validated image filenames belonging to 3 classes.\n",
      "Found 100 validated image filenames belonging to 3 classes.\n",
      "Found 238 validated image filenames belonging to 3 classes.\n",
      "Found 59 validated image filenames belonging to 3 classes.\n",
      "Found 100 validated image filenames belonging to 3 classes.\n",
      "Model: \"model_13\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "AP(Mortise) (InputLayer)        [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Lateral (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "resnet50 (Functional)           (None, 2048)         23587712    AP(Mortise)[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "efficientnetb0 (Functional)     (None, 1280)         4049571     Lateral[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "AP_dense_128 (Dense)            (None, 128)          262272      resnet50[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Lateral_dense_128 (Dense)       (None, 128)          163968      efficientnetb0[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "AP_dense_50 (Dense)             (None, 50)           6450        AP_dense_128[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Lateral_dense_50 (Dense)        (None, 50)           6450        Lateral_dense_128[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "feature_fusion (Concatenate)    (None, 100)          0           AP_dense_50[0][0]                \n",
      "                                                                 Lateral_dense_50[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 100)          0           feature_fusion[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "output_layer (Dense)            (None, 3)            303         dropout_13[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 28,076,726\n",
      "Trainable params: 439,443\n",
      "Non-trainable params: 27,637,283\n",
      "__________________________________________________________________________________________________\n",
      "-------Training_concat1_踢盲檢_測盲檢-------\n",
      "Epoch 1/30\n",
      "4/4 [==============================] - 6s 829ms/step - loss: 1.1659 - accuracy: 0.3109 - val_loss: 1.0140 - val_accuracy: 0.5593\n",
      "Epoch 2/30\n",
      "4/4 [==============================] - 2s 610ms/step - loss: 1.0121 - accuracy: 0.5000 - val_loss: 0.9351 - val_accuracy: 0.5593\n",
      "Epoch 3/30\n",
      "4/4 [==============================] - 2s 615ms/step - loss: 0.9266 - accuracy: 0.5882 - val_loss: 0.8665 - val_accuracy: 0.6441\n",
      "Epoch 4/30\n",
      "4/4 [==============================] - 2s 581ms/step - loss: 0.8519 - accuracy: 0.6429 - val_loss: 0.8064 - val_accuracy: 0.6441\n",
      "Epoch 5/30\n",
      "4/4 [==============================] - 2s 594ms/step - loss: 0.7859 - accuracy: 0.6050 - val_loss: 0.7519 - val_accuracy: 0.6780\n",
      "Epoch 6/30\n",
      "4/4 [==============================] - 2s 577ms/step - loss: 0.7269 - accuracy: 0.6891 - val_loss: 0.6999 - val_accuracy: 0.7288\n",
      "Epoch 7/30\n",
      "4/4 [==============================] - 2s 575ms/step - loss: 0.6733 - accuracy: 0.7353 - val_loss: 0.6576 - val_accuracy: 0.7458\n",
      "Epoch 8/30\n",
      "4/4 [==============================] - 2s 568ms/step - loss: 0.6357 - accuracy: 0.7815 - val_loss: 0.6250 - val_accuracy: 0.7288\n",
      "Epoch 9/30\n",
      "4/4 [==============================] - 2s 574ms/step - loss: 0.6019 - accuracy: 0.7647 - val_loss: 0.5977 - val_accuracy: 0.7627\n",
      "Epoch 10/30\n",
      "4/4 [==============================] - 2s 564ms/step - loss: 0.5899 - accuracy: 0.7647 - val_loss: 0.5738 - val_accuracy: 0.7627\n",
      "Epoch 11/30\n",
      "4/4 [==============================] - 2s 570ms/step - loss: 0.5642 - accuracy: 0.7689 - val_loss: 0.5535 - val_accuracy: 0.7458\n",
      "Epoch 12/30\n",
      "4/4 [==============================] - 2s 566ms/step - loss: 0.5388 - accuracy: 0.7731 - val_loss: 0.5361 - val_accuracy: 0.7627\n",
      "Epoch 13/30\n",
      "4/4 [==============================] - 2s 562ms/step - loss: 0.5219 - accuracy: 0.7899 - val_loss: 0.5237 - val_accuracy: 0.7458\n",
      "Epoch 14/30\n",
      "4/4 [==============================] - 2s 570ms/step - loss: 0.4787 - accuracy: 0.8529 - val_loss: 0.5119 - val_accuracy: 0.7627\n",
      "Epoch 15/30\n",
      "4/4 [==============================] - 2s 572ms/step - loss: 0.4592 - accuracy: 0.8361 - val_loss: 0.4999 - val_accuracy: 0.7966\n",
      "Epoch 16/30\n",
      "4/4 [==============================] - 2s 567ms/step - loss: 0.4576 - accuracy: 0.8151 - val_loss: 0.4879 - val_accuracy: 0.8136\n",
      "Epoch 17/30\n",
      "4/4 [==============================] - 2s 581ms/step - loss: 0.4413 - accuracy: 0.8487 - val_loss: 0.4792 - val_accuracy: 0.8475\n",
      "Epoch 18/30\n",
      "4/4 [==============================] - 2s 567ms/step - loss: 0.4340 - accuracy: 0.8529 - val_loss: 0.4716 - val_accuracy: 0.8305\n",
      "Epoch 19/30\n",
      "4/4 [==============================] - 2s 572ms/step - loss: 0.4204 - accuracy: 0.8613 - val_loss: 0.4621 - val_accuracy: 0.8475\n",
      "Epoch 20/30\n",
      "4/4 [==============================] - 2s 571ms/step - loss: 0.4098 - accuracy: 0.8655 - val_loss: 0.4545 - val_accuracy: 0.8644\n",
      "Epoch 21/30\n",
      "4/4 [==============================] - 2s 572ms/step - loss: 0.3752 - accuracy: 0.8950 - val_loss: 0.4482 - val_accuracy: 0.8305\n",
      "Epoch 22/30\n",
      "4/4 [==============================] - 2s 566ms/step - loss: 0.3643 - accuracy: 0.8866 - val_loss: 0.4406 - val_accuracy: 0.8305\n",
      "Epoch 23/30\n",
      "4/4 [==============================] - 2s 566ms/step - loss: 0.3615 - accuracy: 0.8866 - val_loss: 0.4356 - val_accuracy: 0.8475\n",
      "Epoch 24/30\n",
      "4/4 [==============================] - 2s 567ms/step - loss: 0.3613 - accuracy: 0.8739 - val_loss: 0.4311 - val_accuracy: 0.8475\n",
      "Epoch 25/30\n",
      "4/4 [==============================] - 2s 564ms/step - loss: 0.3718 - accuracy: 0.8697 - val_loss: 0.4245 - val_accuracy: 0.8475\n",
      "Epoch 26/30\n",
      "4/4 [==============================] - 2s 570ms/step - loss: 0.3309 - accuracy: 0.9118 - val_loss: 0.4203 - val_accuracy: 0.8475\n",
      "Epoch 27/30\n",
      "4/4 [==============================] - 2s 568ms/step - loss: 0.3386 - accuracy: 0.8824 - val_loss: 0.4171 - val_accuracy: 0.8475\n",
      "Epoch 28/30\n",
      "4/4 [==============================] - 2s 572ms/step - loss: 0.3244 - accuracy: 0.9034 - val_loss: 0.4154 - val_accuracy: 0.8475\n",
      "Epoch 29/30\n",
      "4/4 [==============================] - 2s 573ms/step - loss: 0.3036 - accuracy: 0.9328 - val_loss: 0.4124 - val_accuracy: 0.8305\n",
      "Epoch 30/30\n",
      "4/4 [==============================] - 2s 574ms/step - loss: 0.3109 - accuracy: 0.9328 - val_loss: 0.4101 - val_accuracy: 0.8475\n",
      "Found 238 validated image filenames belonging to 3 classes.\n",
      "Found 59 validated image filenames belonging to 3 classes.\n",
      "Found 100 validated image filenames belonging to 3 classes.\n",
      "Found 238 validated image filenames belonging to 3 classes.\n",
      "Found 59 validated image filenames belonging to 3 classes.\n",
      "Found 100 validated image filenames belonging to 3 classes.\n",
      "Model: \"model_14\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "AP(Mortise) (InputLayer)        [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Lateral (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "resnet50 (Functional)           (None, 2048)         23587712    AP(Mortise)[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "efficientnetb0 (Functional)     (None, 1280)         4049571     Lateral[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "AP_dense_128 (Dense)            (None, 128)          262272      resnet50[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Lateral_dense_128 (Dense)       (None, 128)          163968      efficientnetb0[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "AP_dense_50 (Dense)             (None, 50)           6450        AP_dense_128[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Lateral_dense_50 (Dense)        (None, 50)           6450        Lateral_dense_128[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "feature_fusion (Concatenate)    (None, 100)          0           AP_dense_50[0][0]                \n",
      "                                                                 Lateral_dense_50[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 100)          0           feature_fusion[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "output_layer (Dense)            (None, 3)            303         dropout_14[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 28,076,726\n",
      "Trainable params: 439,443\n",
      "Non-trainable params: 27,637,283\n",
      "__________________________________________________________________________________________________\n",
      "-------Training_concat1_踢盲檢_測盲檢-------\n",
      "Epoch 1/30\n",
      "4/4 [==============================] - 6s 816ms/step - loss: 1.2183 - accuracy: 0.4118 - val_loss: 1.0721 - val_accuracy: 0.4576\n",
      "Epoch 2/30\n",
      "4/4 [==============================] - 2s 587ms/step - loss: 1.0506 - accuracy: 0.4664 - val_loss: 0.9901 - val_accuracy: 0.5424\n",
      "Epoch 3/30\n",
      "4/4 [==============================] - 2s 652ms/step - loss: 0.9562 - accuracy: 0.5630 - val_loss: 0.9014 - val_accuracy: 0.6441\n",
      "Epoch 4/30\n",
      "4/4 [==============================] - 2s 608ms/step - loss: 0.8351 - accuracy: 0.6429 - val_loss: 0.8361 - val_accuracy: 0.6441\n",
      "Epoch 5/30\n",
      "4/4 [==============================] - 2s 578ms/step - loss: 0.7960 - accuracy: 0.6807 - val_loss: 0.7907 - val_accuracy: 0.6441\n",
      "Epoch 6/30\n",
      "4/4 [==============================] - 2s 569ms/step - loss: 0.7653 - accuracy: 0.6765 - val_loss: 0.7453 - val_accuracy: 0.6441\n",
      "Epoch 7/30\n",
      "4/4 [==============================] - 2s 578ms/step - loss: 0.6972 - accuracy: 0.7437 - val_loss: 0.7077 - val_accuracy: 0.7119\n",
      "Epoch 8/30\n",
      "4/4 [==============================] - 2s 575ms/step - loss: 0.6494 - accuracy: 0.7479 - val_loss: 0.6735 - val_accuracy: 0.6949\n",
      "Epoch 9/30\n",
      "4/4 [==============================] - 2s 577ms/step - loss: 0.5955 - accuracy: 0.7605 - val_loss: 0.6434 - val_accuracy: 0.6949\n",
      "Epoch 10/30\n",
      "4/4 [==============================] - 2s 573ms/step - loss: 0.5781 - accuracy: 0.7605 - val_loss: 0.6226 - val_accuracy: 0.6610\n",
      "Epoch 11/30\n",
      "4/4 [==============================] - 2s 574ms/step - loss: 0.5462 - accuracy: 0.7899 - val_loss: 0.6034 - val_accuracy: 0.6780\n",
      "Epoch 12/30\n",
      "4/4 [==============================] - 2s 579ms/step - loss: 0.5188 - accuracy: 0.8025 - val_loss: 0.5829 - val_accuracy: 0.7119\n",
      "Epoch 13/30\n",
      "4/4 [==============================] - 2s 578ms/step - loss: 0.4844 - accuracy: 0.8319 - val_loss: 0.5647 - val_accuracy: 0.6949\n",
      "Epoch 14/30\n",
      "4/4 [==============================] - 2s 576ms/step - loss: 0.4618 - accuracy: 0.8487 - val_loss: 0.5515 - val_accuracy: 0.6949\n",
      "Epoch 15/30\n",
      "4/4 [==============================] - 2s 579ms/step - loss: 0.4215 - accuracy: 0.8824 - val_loss: 0.5391 - val_accuracy: 0.7119\n",
      "Epoch 16/30\n",
      "4/4 [==============================] - 2s 577ms/step - loss: 0.4236 - accuracy: 0.8529 - val_loss: 0.5295 - val_accuracy: 0.7119\n",
      "Epoch 17/30\n",
      "4/4 [==============================] - 2s 576ms/step - loss: 0.4296 - accuracy: 0.8487 - val_loss: 0.5199 - val_accuracy: 0.7119\n",
      "Found 238 validated image filenames belonging to 3 classes.\n",
      "Found 59 validated image filenames belonging to 3 classes.\n",
      "Found 100 validated image filenames belonging to 3 classes.\n",
      "Found 238 validated image filenames belonging to 3 classes.\n",
      "Found 59 validated image filenames belonging to 3 classes.\n",
      "Found 100 validated image filenames belonging to 3 classes.\n",
      "Model: \"model_15\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "AP(Mortise) (InputLayer)        [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Lateral (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "resnet50 (Functional)           (None, 2048)         23587712    AP(Mortise)[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "efficientnetb0 (Functional)     (None, 1280)         4049571     Lateral[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "AP_dense_128 (Dense)            (None, 128)          262272      resnet50[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Lateral_dense_128 (Dense)       (None, 128)          163968      efficientnetb0[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "AP_dense_50 (Dense)             (None, 50)           6450        AP_dense_128[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Lateral_dense_50 (Dense)        (None, 50)           6450        Lateral_dense_128[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "feature_fusion (Concatenate)    (None, 100)          0           AP_dense_50[0][0]                \n",
      "                                                                 Lateral_dense_50[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 100)          0           feature_fusion[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "output_layer (Dense)            (None, 3)            303         dropout_15[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 28,076,726\n",
      "Trainable params: 439,443\n",
      "Non-trainable params: 27,637,283\n",
      "__________________________________________________________________________________________________\n",
      "-------Training_concat1_踢盲檢_測盲檢-------\n",
      "Epoch 1/30\n",
      "4/4 [==============================] - 6s 839ms/step - loss: 1.3344 - accuracy: 0.3025 - val_loss: 1.1171 - val_accuracy: 0.4068\n",
      "Epoch 2/30\n",
      "4/4 [==============================] - 2s 585ms/step - loss: 1.0589 - accuracy: 0.4916 - val_loss: 1.0113 - val_accuracy: 0.5085\n",
      "Epoch 3/30\n",
      "4/4 [==============================] - 2s 619ms/step - loss: 0.9674 - accuracy: 0.5462 - val_loss: 0.9305 - val_accuracy: 0.6271\n",
      "Epoch 4/30\n",
      "4/4 [==============================] - 2s 574ms/step - loss: 0.9193 - accuracy: 0.5882 - val_loss: 0.8490 - val_accuracy: 0.6441\n",
      "Epoch 5/30\n",
      "4/4 [==============================] - 2s 580ms/step - loss: 0.8052 - accuracy: 0.6681 - val_loss: 0.8044 - val_accuracy: 0.6102\n",
      "Epoch 6/30\n",
      "4/4 [==============================] - 2s 583ms/step - loss: 0.7686 - accuracy: 0.6807 - val_loss: 0.7715 - val_accuracy: 0.6271\n",
      "Epoch 7/30\n",
      "4/4 [==============================] - 2s 578ms/step - loss: 0.7043 - accuracy: 0.6891 - val_loss: 0.7277 - val_accuracy: 0.6780\n",
      "Epoch 8/30\n",
      "4/4 [==============================] - 2s 572ms/step - loss: 0.6526 - accuracy: 0.7521 - val_loss: 0.6962 - val_accuracy: 0.6780\n",
      "Epoch 9/30\n",
      "4/4 [==============================] - 2s 575ms/step - loss: 0.6016 - accuracy: 0.7647 - val_loss: 0.6749 - val_accuracy: 0.6610\n",
      "Epoch 10/30\n",
      "4/4 [==============================] - 2s 569ms/step - loss: 0.5709 - accuracy: 0.7899 - val_loss: 0.6552 - val_accuracy: 0.6780\n",
      "Epoch 11/30\n",
      "4/4 [==============================] - 2s 571ms/step - loss: 0.5394 - accuracy: 0.8067 - val_loss: 0.6381 - val_accuracy: 0.6949\n",
      "Epoch 12/30\n",
      "4/4 [==============================] - 2s 570ms/step - loss: 0.5316 - accuracy: 0.7941 - val_loss: 0.6262 - val_accuracy: 0.6780\n",
      "Epoch 13/30\n",
      "4/4 [==============================] - 2s 573ms/step - loss: 0.5068 - accuracy: 0.8151 - val_loss: 0.6157 - val_accuracy: 0.6780\n",
      "Epoch 14/30\n",
      "4/4 [==============================] - 2s 575ms/step - loss: 0.4764 - accuracy: 0.8235 - val_loss: 0.6096 - val_accuracy: 0.6949\n",
      "Epoch 15/30\n",
      "4/4 [==============================] - 2s 571ms/step - loss: 0.4522 - accuracy: 0.8655 - val_loss: 0.6059 - val_accuracy: 0.6780\n",
      "Epoch 16/30\n",
      "4/4 [==============================] - 2s 571ms/step - loss: 0.4542 - accuracy: 0.8235 - val_loss: 0.5998 - val_accuracy: 0.6949\n",
      "Epoch 17/30\n",
      "4/4 [==============================] - 2s 577ms/step - loss: 0.4115 - accuracy: 0.8571 - val_loss: 0.5959 - val_accuracy: 0.7119\n",
      "Epoch 18/30\n",
      "4/4 [==============================] - 2s 574ms/step - loss: 0.4146 - accuracy: 0.8613 - val_loss: 0.5950 - val_accuracy: 0.6949\n",
      "Epoch 19/30\n",
      "4/4 [==============================] - 2s 569ms/step - loss: 0.4103 - accuracy: 0.8571 - val_loss: 0.5939 - val_accuracy: 0.7119\n",
      "Epoch 20/30\n",
      "4/4 [==============================] - 2s 568ms/step - loss: 0.3794 - accuracy: 0.8613 - val_loss: 0.5886 - val_accuracy: 0.7119\n",
      "Epoch 21/30\n",
      "4/4 [==============================] - 2s 573ms/step - loss: 0.3616 - accuracy: 0.9034 - val_loss: 0.5864 - val_accuracy: 0.6949\n",
      "Epoch 22/30\n",
      "4/4 [==============================] - 2s 573ms/step - loss: 0.3530 - accuracy: 0.8866 - val_loss: 0.5865 - val_accuracy: 0.6949\n",
      "Epoch 23/30\n",
      "4/4 [==============================] - 2s 573ms/step - loss: 0.3501 - accuracy: 0.8782 - val_loss: 0.5885 - val_accuracy: 0.6949\n",
      "Epoch 24/30\n",
      "4/4 [==============================] - 2s 567ms/step - loss: 0.3319 - accuracy: 0.9118 - val_loss: 0.5897 - val_accuracy: 0.6949\n",
      "Epoch 25/30\n",
      "4/4 [==============================] - 2s 572ms/step - loss: 0.3184 - accuracy: 0.9160 - val_loss: 0.5823 - val_accuracy: 0.6949\n",
      "Epoch 26/30\n",
      "4/4 [==============================] - 2s 569ms/step - loss: 0.3230 - accuracy: 0.9118 - val_loss: 0.5780 - val_accuracy: 0.7119\n",
      "Epoch 27/30\n",
      "4/4 [==============================] - 2s 566ms/step - loss: 0.3068 - accuracy: 0.9160 - val_loss: 0.5794 - val_accuracy: 0.6949\n",
      "acc mean = 0.71, std = 0.02, test_acc = [0.72, 0.74, 0.7, 0.67, 0.73]\n",
      "f1  mean = 0.69, std = 0.04, test_f1 = [0.71, 0.73, 0.68, 0.63, 0.72]\n"
     ]
    }
   ],
   "source": [
    "# import\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path\n",
    "# import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import os\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from tensorflow.keras.layers import Input, Dense, Concatenate, Dropout\n",
    "import math\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "## label\n",
    "# =========================\n",
    "def class_2_type(root):\n",
    "    label = \"\"\n",
    "    if \"正常\" in root:\n",
    "        label = \"0\"\n",
    "    else:\n",
    "        label = \"1\"\n",
    "    return label\n",
    "\n",
    "def class_3_type(root):\n",
    "    label = \"\"\n",
    "    if \"正常\" in root:\n",
    "        label = \"0\"\n",
    "    elif \"雙踝\" in root:\n",
    "        label = \"1\"\n",
    "    elif \"三踝\" in root:\n",
    "        label = \"2\"\n",
    "    return label\n",
    "# =========================\n",
    "\n",
    "\n",
    "def load_path(path, class_count):\n",
    "    dataset = []\n",
    "    class_type = ''\n",
    "    if class_count == 2:\n",
    "        class_type = class_2_type\n",
    "    elif class_count == 3:\n",
    "        class_type = class_3_type  \n",
    "\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            label = class_type(root)\n",
    "            # if label != \"\":\n",
    "            dataset.append(\n",
    "                            {   \n",
    "                                'uuid': root.split(\"\\\\\")[-1],\n",
    "                                'label': label,\n",
    "                                'image_path': os.path.join(root, file)\n",
    "                            }\n",
    "                        )\n",
    "\n",
    "    return dataset\n",
    "\n",
    "def create_front_extract():\n",
    "    pretrained_model_chosen = tf.keras.applications.resnet50.ResNet50\n",
    "    pretrained_model = pretrained_model_chosen(\n",
    "        input_shape=(224, 224, 3),\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        pooling='avg')\n",
    "    pretrained_model.trainable = False\n",
    "    return pretrained_model\n",
    "\n",
    "def create_side_extract():\n",
    "    pretrained_model_chosen = tf.keras.applications.efficientnet.EfficientNetB0\n",
    "    pretrained_model = pretrained_model_chosen(\n",
    "        input_shape=(224, 224, 3),\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        pooling='avg')\n",
    "    pretrained_model.trainable = False\n",
    "    return pretrained_model\n",
    "\n",
    "def multi_input_generator(front_gen, side_gen):\n",
    "    while True:\n",
    "        front_batch, y1 = next(front_gen)\n",
    "        side_batch, y2 = next(side_gen)\n",
    "        assert (y1 == y2).all(), \"Label mismatch!\"  # 確保標籤一致\n",
    "        yield ([front_batch, side_batch], y1)\n",
    "\n",
    "\n",
    "# def train_cross_validation(image_dir, n_splits=5, class_count=2, maru_part=None,  chosen_model='resnet50'):\n",
    "def train_cross_validation(image_dir, image_dir2, n_splits=5, class_count=2):\n",
    "\n",
    "\n",
    "    ## load data and  labels\n",
    "    # =========================\n",
    "    labels = []\n",
    "    filepaths = []\n",
    "    data = load_path(image_dir, class_count)\n",
    "    for row in data:\n",
    "        labels.append(row['label'])\n",
    "        filepaths.append(row['image_path'])\n",
    "\n",
    "    filepaths = pd.Series(filepaths, name='Filepath').astype(str)\n",
    "    labels = pd.Series(labels, name='Label')\n",
    "\n",
    "    images = pd.concat([filepaths, labels], axis=1)\n",
    "    # =========================\n",
    "\n",
    "    ## load data and  labels\n",
    "    # =========================\n",
    "    data2 = load_path(image_dir2, class_count)\n",
    "    labels = []\n",
    "    filepaths = []\n",
    "    for row in data2:\n",
    "        labels.append(row['label'])\n",
    "        filepaths.append(row['image_path'])\n",
    "\n",
    "    filepaths = pd.Series(filepaths, name='Filepath').astype(str)\n",
    "    labels = pd.Series(labels, name='Label')\n",
    "\n",
    "    images2 = pd.concat([filepaths, labels], axis=1)\n",
    "    # =========================\n",
    "\n",
    "    ## split image\n",
    "    # =========================\n",
    "    # train_df_front, val_df_front = train_test_split(images, train_size=0.8, shuffle=True, random_state=1, stratify=images['Label'])\n",
    "    # train_df_front, test_df_front = train_test_split(images, train_size=0.8, shuffle=True, random_state=1, stratify=images['Label'])\n",
    "    train_df_front = images.sample(frac=1, random_state=42)\n",
    "    test_df_front = images2\n",
    "    print(\"Training set label distribution:\\n\", train_df_front['Label'].value_counts(normalize=False))\n",
    "    print(\"Test set label distribution:\\n\", test_df_front['Label'].value_counts(normalize=False))\n",
    "    # =========================\n",
    "\n",
    "    preprocessing_function_chosen_front = tf.keras.applications.resnet50.preprocess_input\n",
    "    preprocessing_function_chosen_side = tf.keras.applications.efficientnet.preprocess_input\n",
    "\n",
    "\n",
    "    ## train model, k fold cross validation\n",
    "    # ==================================================\n",
    "    fold_no = 1\n",
    "    test_acc = []\n",
    "    test_f1 = []\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=1)\n",
    "    for train_index, val_index in kfold.split(train_df_front, train_df_front['Label']):\n",
    "        k_fold_train_front = train_df_front.iloc[train_index]\n",
    "        k_fold_val_front = train_df_front.iloc[val_index]\n",
    "\n",
    "        # front images\n",
    "        # =========================\n",
    "        train_generator_front = tf.keras.preprocessing.image.ImageDataGenerator(horizontal_flip=False,\n",
    "                                                                                preprocessing_function=preprocessing_function_chosen_front)\n",
    "        test_generator_front = tf.keras.preprocessing.image.ImageDataGenerator(preprocessing_function=preprocessing_function_chosen_front)\n",
    "\n",
    "        train_images_front = train_generator_front.flow_from_dataframe(\n",
    "            dataframe=k_fold_train_front,\n",
    "            x_col='Filepath',\n",
    "            y_col='Label',\n",
    "            target_size=(224, 224),\n",
    "            color_mode='rgb',\n",
    "            class_mode='categorical',\n",
    "            batch_size=64,\n",
    "            shuffle=False,\n",
    "            seed=42\n",
    "        )\n",
    "\n",
    "        val_images_front = train_generator_front.flow_from_dataframe(\n",
    "            dataframe=k_fold_val_front,\n",
    "            x_col='Filepath',\n",
    "            y_col='Label',\n",
    "            target_size=(224, 224),\n",
    "            color_mode='rgb',\n",
    "            class_mode='categorical',\n",
    "            batch_size=64,\n",
    "            shuffle=False,\n",
    "            seed=42\n",
    "        )\n",
    "\n",
    "        test_images_front = test_generator_front.flow_from_dataframe(\n",
    "            dataframe=test_df_front,\n",
    "            x_col='Filepath',\n",
    "            y_col='Label',\n",
    "            target_size=(224, 224),\n",
    "            color_mode='rgb',\n",
    "            class_mode='categorical',\n",
    "            batch_size=32,\n",
    "            shuffle=False\n",
    "        )\n",
    "        # =========================   \n",
    "\n",
    "        # side images\n",
    "        # =========================\n",
    "        train_df_side = train_df_front.copy()\n",
    "        test_df_side = test_df_front.copy()\n",
    "        train_df_side.loc[:, \"Filepath\"] = train_df_front[\"Filepath\"].str.replace(\"front\", \"side\")\n",
    "        test_df_side.loc[:, \"Filepath\"] = test_df_side[\"Filepath\"].str.replace(\"front\", \"side\")\n",
    "\n",
    "        k_fold_train_side = train_df_side.iloc[train_index]\n",
    "        k_fold_val_side = train_df_side.iloc[val_index]\n",
    "\n",
    "        train_generator_side = tf.keras.preprocessing.image.ImageDataGenerator(horizontal_flip=False,\n",
    "                                                                                preprocessing_function=preprocessing_function_chosen_side)\n",
    "        test_generator_side = tf.keras.preprocessing.image.ImageDataGenerator(preprocessing_function=preprocessing_function_chosen_side)\n",
    "\n",
    "        train_images_side = train_generator_side.flow_from_dataframe(\n",
    "            dataframe=k_fold_train_side,\n",
    "            x_col='Filepath',\n",
    "            y_col='Label',\n",
    "            target_size=(224, 224),\n",
    "            color_mode='rgb',\n",
    "            class_mode='categorical',\n",
    "            batch_size=64,\n",
    "            shuffle=False,\n",
    "            seed=42\n",
    "        )\n",
    "\n",
    "        val_images_side = train_generator_side.flow_from_dataframe(\n",
    "            dataframe=k_fold_val_side,\n",
    "            x_col='Filepath',\n",
    "            y_col='Label',\n",
    "            target_size=(224, 224),\n",
    "            color_mode='rgb',\n",
    "            class_mode='categorical',\n",
    "            batch_size=64,\n",
    "            shuffle=False,\n",
    "            seed=42\n",
    "        )\n",
    "\n",
    "        test_images_side = test_generator_side.flow_from_dataframe(\n",
    "            dataframe=test_df_side,\n",
    "            x_col='Filepath',\n",
    "            y_col='Label',\n",
    "            target_size=(224, 224),\n",
    "            color_mode='rgb',\n",
    "            class_mode='categorical',\n",
    "            batch_size=32,\n",
    "            shuffle=False\n",
    "        )\n",
    "        # ========================= \n",
    "        \n",
    "        # load model\n",
    "        # =========================\n",
    "        # input \n",
    "        input_front = Input(shape=(224, 224, 3), name=\"AP(Mortise)\")\n",
    "        input_side = Input(shape=(224, 224, 3), name=\"Lateral\")\n",
    "\n",
    "        # model\n",
    "        model_front = create_front_extract()\n",
    "        model_side = create_side_extract()\n",
    "\n",
    "        features_front = model_front(input_front)\n",
    "        features_side = model_side(input_side)\n",
    "\n",
    "        features_front_x = tf.keras.layers.Dense(128, activation='relu', name='AP_dense_128')(features_front)\n",
    "        features_front_x = tf.keras.layers.Dense(50, activation='relu', name='AP_dense_50')(features_front_x)\n",
    "\n",
    "        features_side_x = tf.keras.layers.Dense(128, activation='relu', name='Lateral_dense_128')(features_side)\n",
    "        features_side_x = tf.keras.layers.Dense(50, activation='relu', name='Lateral_dense_50')(features_side_x)\n",
    "\n",
    "        fused_features = Concatenate(name=\"feature_fusion\")([features_front_x, features_side_x])\n",
    "        # fused_features = tf.keras.layers.Dense(50, activation='relu', name='fusion_dense_50')(fused_features)\n",
    "        fused_features = Dropout(0.1)(fused_features)\n",
    "\n",
    "        final_output = Dense(class_count, activation='sigmoid', name='output_layer')(fused_features)\n",
    "        multi_view_model = None\n",
    "        multi_view_model = Model(\n",
    "            inputs=[input_front, input_side],\n",
    "            outputs=final_output\n",
    "        )\n",
    "        multi_view_model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        multi_view_model.summary()\n",
    "        # print(model.summary())\n",
    "        # =========================\n",
    "\n",
    "        train_generator = multi_input_generator(train_images_front, train_images_side)\n",
    "        val_generator = multi_input_generator(val_images_front, val_images_side)\n",
    "        \n",
    "        ## compile and evaluate\n",
    "        # =========================\n",
    "\n",
    "        print(\"-------Training_\" + concat_type + \"-------\")\n",
    "        multi_view_model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "        batch_size = 64\n",
    "        ## early stop \n",
    "        early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)\n",
    "        multi_view_model.fit(train_generator, validation_data=val_generator, callbacks=[early_stopping], epochs=30,\n",
    "                                    steps_per_epoch= math.ceil(train_images_front.samples / batch_size), \n",
    "                                    validation_steps= math.ceil(val_images_front.samples / batch_size))\n",
    "        ## no early stop\n",
    "        # multi_view_model.fit(train_generator, validation_data=val_generator, epochs=30,\n",
    "        #                     steps_per_epoch= math.ceil(train_images_front.samples / batch_size), \n",
    "        #                     validation_steps= math.ceil(val_images_front.samples / batch_size))\n",
    "\n",
    "        # =========================\n",
    "\n",
    "        test_generator = multi_input_generator(test_images_front, test_images_side)\n",
    "        batch_size=32\n",
    "        pred = multi_view_model.predict(test_generator,  steps=math.ceil(test_images_front.samples / batch_size))\n",
    "        predicted_labels = np.argmax(pred, axis=1)\n",
    "\n",
    "        # =========================\n",
    "            \n",
    "        ## print results\n",
    "        # =========================\n",
    "        acc = accuracy_score(test_images_front.labels, predicted_labels)\n",
    "\n",
    "        test_acc.append(np.round(acc, 2))\n",
    "        f1 = f1_score(test_images_front.labels, predicted_labels, average='macro')\n",
    "        test_f1.append(np.round(f1, 2))\n",
    "        fold_no += 1\n",
    "        # =========================\n",
    "    # ==================================================\n",
    "        \n",
    "    ## print  mean results\n",
    "    # =========================\n",
    "    acc_mean  = np.round(np.mean(test_acc), 2)\n",
    "    acc_std = np.round(np.std(test_acc), 2)\n",
    "    f1_mean  = np.round(np.mean(test_f1), 2)\n",
    "    f1_std = np.round(np.std(test_f1), 2)\n",
    "    # print(f\"acc mean = {acc_mean}, std = {acc_std}\")\n",
    "    # print(test_acc)\n",
    "    # print(f\"f1  mean = {f1_mean}, std = {f1_std}\")\n",
    "    # print(test_f1)\n",
    "    # =========================\n",
    "\n",
    "    return {'acc_mean':acc_mean, 'acc_std':acc_std, 'test_acc':test_acc, 'f1_mean':f1_mean, 'f1_std':f1_std, 'test_f1':test_f1}\n",
    "\n",
    "# =========================\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "results = []\n",
    "results = train_cross_validation(image_dir=path,image_dir2=path2, class_count=3)\n",
    "\n",
    "\n",
    "print(f\"acc mean = {results['acc_mean']}, std = {results['acc_std']}, test_acc = {results['test_acc']}\")\n",
    "print(f\"f1  mean = {results['f1_mean']}, std = {results['f1_std']}, test_f1 = {results['test_f1']}\")\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bone_20240719",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
