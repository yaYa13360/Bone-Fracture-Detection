{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, f1_score, precision_score, recall_score\n",
    "import os\n",
    "import math\n",
    "# label\n",
    "# =========================\n",
    "def class_2_type(root):\n",
    "    label = \"\"\n",
    "    if \"正常\" in root:\n",
    "        label = \"0\"\n",
    "    else:\n",
    "        label = \"1\"\n",
    "    return label\n",
    "\n",
    "def class_3_type(root):\n",
    "    label = \"\"\n",
    "    if \"正常\" in root:\n",
    "        label = \"0\"\n",
    "    elif \"雙踝\" in root:\n",
    "        label = \"1\"\n",
    "    elif \"三踝\" in root:\n",
    "        label = \"2\"\n",
    "    return label\n",
    "# =========================\n",
    "\n",
    "def load_path(path, class_count):\n",
    "    dataset = []\n",
    "    class_type = ''\n",
    "    if class_count == 2:\n",
    "        class_type = class_2_type\n",
    "    elif class_count == 3:\n",
    "        class_type = class_3_type   \n",
    "\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            label = class_type(root)\n",
    "            if label != \"\":\n",
    "                dataset.append(\n",
    "                                {   \n",
    "                                    'uuid': root.split(\"\\\\\")[-1],\n",
    "                                    'label': label,\n",
    "                                    'image_path': os.path.join(root, file)\n",
    "                                }\n",
    "                            )\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "def plot_img(image_path):\n",
    "    print(image_path)\n",
    "    # image = cv2.imread(image_path)\n",
    "    # image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # OpenCV 讀取的圖像是 BGR 需要轉為 RGB\n",
    "    image1 = cv2.imdecode(np.fromfile(image_path, dtype=np.uint8), cv2.IMREAD_COLOR)\n",
    "    image2 = cv2.imdecode(np.fromfile(image_path.replace(\"front\", \"side\"), dtype=np.uint8), cv2.IMREAD_COLOR)\n",
    "\n",
    "\n",
    "\n",
    "    # **顯示圖片**\n",
    "    plt.figure(figsize=(8, 5))  # 設定圖片大小\n",
    "\n",
    "    # 顯示第一張圖（front）\n",
    "    plt.subplot(1, 2, 1)  # (行數, 列數, 當前索引)\n",
    "    plt.imshow(image1)\n",
    "    plt.title(\"AP(Mortise) View\")\n",
    "    plt.axis(\"off\")  # 隱藏座標軸\n",
    "\n",
    "    # 顯示第二張圖（side）\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(image2)\n",
    "    plt.title(\"Lateral View\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.suptitle(image_path.split(\"\\\\\")[-1])\n",
    "\n",
    "    plt.show()  # 顯示圖片\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 參數設置\n",
    "image_dir = \"E:\\\\data_bone\\\\11-a+b_swift_cut_正確_V2_踢盲檢\\\\front\"\n",
    "concat_type = \"concat1_踢盲檢\"\n",
    "class_count = 3\n",
    "save_cam_path = \"D://reaserch//Bone-Fracture-Detection//concat//2-concat1//20250410_cam//\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load data and  labels\n",
    "# =========================\n",
    "data = load_path(image_dir, class_count)\n",
    "labels = []\n",
    "filepaths = []\n",
    "for row in data:\n",
    "    labels.append(row['label'])\n",
    "    filepaths.append(row['image_path'])\n",
    "\n",
    "filepaths = pd.Series(filepaths, name='Filepath').astype(str)\n",
    "labels = pd.Series(labels, name='Label')\n",
    "\n",
    "images = pd.concat([filepaths, labels], axis=1)\n",
    "# =========================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set label distribution:\n",
      " 0    101\n",
      "2     69\n",
      "1     67\n",
      "Name: Label, dtype: int64\n",
      "Test set label distribution:\n",
      " 0    25\n",
      "2    18\n",
      "1    17\n",
      "Name: Label, dtype: int64\n",
      "Found 190 validated image filenames belonging to 3 classes.\n",
      "Found 47 validated image filenames belonging to 3 classes.\n",
      "Found 60 validated image filenames belonging to 3 classes.\n",
      "Found 190 validated image filenames belonging to 3 classes.\n",
      "Found 47 validated image filenames belonging to 3 classes.\n",
      "Found 60 validated image filenames belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "## split image\n",
    "# =========================\n",
    "train_df_front, test_df_front = train_test_split(images, train_size=0.8, shuffle=True, random_state=1, stratify=images['Label'])\n",
    "print(\"Training set label distribution:\\n\", train_df_front['Label'].value_counts(normalize=False))\n",
    "print(\"Test set label distribution:\\n\", test_df_front['Label'].value_counts(normalize=False))\n",
    "# =========================\n",
    "\n",
    "preprocessing_function_chosen_front = tf.keras.applications.resnet50.preprocess_input\n",
    "preprocessing_function_chosen_side = tf.keras.applications.efficientnet.preprocess_input\n",
    "\n",
    "# front images\n",
    "# =========================\n",
    "train_generator_front = tf.keras.preprocessing.image.ImageDataGenerator(horizontal_flip=False,\n",
    "                                                                    preprocessing_function=preprocessing_function_chosen_front,\n",
    "                                                                    validation_split=0.2)\n",
    "test_generator_front = tf.keras.preprocessing.image.ImageDataGenerator(preprocessing_function=preprocessing_function_chosen_front)\n",
    "\n",
    "train_images_front = train_generator_front.flow_from_dataframe(\n",
    "    dataframe=train_df_front,\n",
    "    x_col='Filepath',\n",
    "    y_col='Label',\n",
    "    target_size=(224, 224),\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=64,\n",
    "    shuffle=False,\n",
    "    seed=42,\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "val_images_front = train_generator_front.flow_from_dataframe(\n",
    "    dataframe=train_df_front,\n",
    "    x_col='Filepath',\n",
    "    y_col='Label',\n",
    "    target_size=(224, 224),\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=64,\n",
    "    seed=42,\n",
    "    shuffle=False,\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "test_images_front = test_generator_front.flow_from_dataframe(\n",
    "    dataframe=test_df_front,\n",
    "    x_col='Filepath',\n",
    "    y_col='Label',\n",
    "    target_size=(224, 224),\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")\n",
    "# =========================\n",
    "\n",
    "\n",
    "# side images\n",
    "# =========================\n",
    "train_df_side = train_df_front.copy()\n",
    "test_df_side = test_df_front.copy()\n",
    "train_df_side.loc[:, \"Filepath\"] = train_df_front[\"Filepath\"].str.replace(\"front\", \"side\")\n",
    "test_df_side.loc[:, \"Filepath\"] = test_df_side[\"Filepath\"].str.replace(\"front\", \"side\")\n",
    "\n",
    "train_generator_side = tf.keras.preprocessing.image.ImageDataGenerator(horizontal_flip=False,\n",
    "                                                                    preprocessing_function=preprocessing_function_chosen_side,\n",
    "                                                                    validation_split=0.2)\n",
    "test_generator_side = tf.keras.preprocessing.image.ImageDataGenerator(preprocessing_function=preprocessing_function_chosen_side)\n",
    "\n",
    "train_images_side = train_generator_side.flow_from_dataframe(\n",
    "    dataframe=train_df_side,\n",
    "    x_col='Filepath',\n",
    "    y_col='Label',\n",
    "    target_size=(224, 224),\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=64,\n",
    "    shuffle=False,\n",
    "    seed=42,\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "val_images_side = train_generator_side.flow_from_dataframe(\n",
    "    dataframe=train_df_side,\n",
    "    x_col='Filepath',\n",
    "    y_col='Label',\n",
    "    target_size=(224, 224),\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=64,\n",
    "    shuffle=False,\n",
    "    seed=42,\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "test_images_side = test_generator_side.flow_from_dataframe(\n",
    "    dataframe=test_df_side,\n",
    "    x_col='Filepath',\n",
    "    y_col='Label',\n",
    "    target_size=(224, 224),\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")\n",
    "# =========================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_121\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "AP(Mortise) (InputLayer)        [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Lateral (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "resnet50 (Functional)           (None, 2048)         23587712    AP(Mortise)[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "efficientnetb0 (Functional)     (None, 1280)         4049571     Lateral[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "AP_dense_128 (Dense)            (None, 128)          262272      resnet50[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Lateral_dense_128 (Dense)       (None, 128)          163968      efficientnetb0[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "AP_dense_50 (Dense)             (None, 50)           6450        AP_dense_128[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Lateral_dense_50 (Dense)        (None, 50)           6450        Lateral_dense_128[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "feature_fusion (Concatenate)    (None, 100)          0           AP_dense_50[0][0]                \n",
      "                                                                 Lateral_dense_50[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 100)          0           feature_fusion[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "output_layer (Dense)            (None, 3)            303         dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 28,076,726\n",
      "Trainable params: 439,443\n",
      "Non-trainable params: 27,637,283\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Concatenate, Dropout\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "\n",
    "\n",
    "\n",
    "def create_front_extract():\n",
    "    pretrained_model_chosen = tf.keras.applications.resnet50.ResNet50\n",
    "    pretrained_model = pretrained_model_chosen(\n",
    "        input_shape=(224, 224, 3),\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        pooling='avg')\n",
    "    pretrained_model.trainable = False\n",
    "    return pretrained_model\n",
    "\n",
    "def create_side_extract():\n",
    "    pretrained_model_chosen = tf.keras.applications.efficientnet.EfficientNetB0\n",
    "    pretrained_model = pretrained_model_chosen(\n",
    "        input_shape=(224, 224, 3),\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        pooling='avg')\n",
    "    pretrained_model.trainable = False\n",
    "    return pretrained_model\n",
    "\n",
    "# input \n",
    "input_front = Input(shape=(224, 224, 3), name=\"AP(Mortise)\")\n",
    "input_side = Input(shape=(224, 224, 3), name=\"Lateral\")\n",
    "\n",
    "# model\n",
    "model_front = create_front_extract()\n",
    "model_side = create_side_extract()\n",
    "\n",
    "features_front = model_front(input_front)\n",
    "features_side = model_side(input_side)\n",
    "\n",
    "features_front_x = tf.keras.layers.Dense(128, activation='relu', name='AP_dense_128')(features_front)\n",
    "features_front_x = tf.keras.layers.Dense(50, activation='relu', name='AP_dense_50')(features_front_x)\n",
    "\n",
    "features_side_x = tf.keras.layers.Dense(128, activation='relu', name='Lateral_dense_128')(features_side)\n",
    "features_side_x = tf.keras.layers.Dense(50, activation='relu', name='Lateral_dense_50')(features_side_x)\n",
    "\n",
    "fused_features = Concatenate(name=\"feature_fusion\")([features_front_x, features_side_x])\n",
    "# fused_features = tf.keras.layers.Dense(50, activation='relu', name='fusion_dense_50')(fused_features)\n",
    "fused_features = Dropout(0.1)(fused_features)\n",
    "\n",
    "final_output = Dense(class_count, activation='sigmoid', name='output_layer')(fused_features)\n",
    "multi_view_model = None\n",
    "multi_view_model = Model(\n",
    "    inputs=[input_front, input_side],\n",
    "    outputs=final_output\n",
    ")\n",
    "multi_view_model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "multi_view_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_input_generator(front_gen, side_gen):\n",
    "    while True:\n",
    "        front_batch, y1 = next(front_gen)\n",
    "        side_batch, y2 = next(side_gen)\n",
    "        assert (y1 == y2).all(), \"Label mismatch!\"  # 確保標籤一致\n",
    "        yield ([front_batch, side_batch], y1)\n",
    "\n",
    "train_generator = multi_input_generator(train_images_front, train_images_side)\n",
    "val_generator = multi_input_generator(val_images_front, val_images_side)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------Training _concat1_踢盲檢-------\n",
      "Epoch 1/30\n",
      "3/3 [==============================] - 6s 1s/step - loss: 1.4734 - accuracy: 0.3105 - val_loss: 1.3401 - val_accuracy: 0.3191\n",
      "Epoch 2/30\n",
      "3/3 [==============================] - 1s 625ms/step - loss: 1.2058 - accuracy: 0.3316 - val_loss: 1.1236 - val_accuracy: 0.4043\n",
      "Epoch 3/30\n",
      "3/3 [==============================] - 1s 612ms/step - loss: 1.0843 - accuracy: 0.4053 - val_loss: 1.0256 - val_accuracy: 0.4894\n",
      "Epoch 4/30\n",
      "3/3 [==============================] - 1s 613ms/step - loss: 1.0275 - accuracy: 0.4632 - val_loss: 0.9575 - val_accuracy: 0.5319\n",
      "Epoch 5/30\n",
      "3/3 [==============================] - 1s 624ms/step - loss: 0.9451 - accuracy: 0.5368 - val_loss: 0.8964 - val_accuracy: 0.6596\n",
      "Epoch 6/30\n",
      "3/3 [==============================] - 1s 618ms/step - loss: 0.8756 - accuracy: 0.6316 - val_loss: 0.8556 - val_accuracy: 0.7447\n",
      "Epoch 7/30\n",
      "3/3 [==============================] - 1s 623ms/step - loss: 0.8492 - accuracy: 0.6895 - val_loss: 0.8139 - val_accuracy: 0.7447\n",
      "Epoch 8/30\n",
      "3/3 [==============================] - 1s 621ms/step - loss: 0.7857 - accuracy: 0.7316 - val_loss: 0.7550 - val_accuracy: 0.8298\n",
      "Epoch 9/30\n",
      "3/3 [==============================] - 1s 621ms/step - loss: 0.7117 - accuracy: 0.7737 - val_loss: 0.6975 - val_accuracy: 0.8298\n",
      "Epoch 10/30\n",
      "3/3 [==============================] - 1s 615ms/step - loss: 0.6698 - accuracy: 0.7789 - val_loss: 0.6565 - val_accuracy: 0.8085\n",
      "Epoch 11/30\n",
      "3/3 [==============================] - 1s 611ms/step - loss: 0.6298 - accuracy: 0.8000 - val_loss: 0.6243 - val_accuracy: 0.8511\n",
      "Epoch 12/30\n",
      "3/3 [==============================] - 1s 608ms/step - loss: 0.6011 - accuracy: 0.7895 - val_loss: 0.5979 - val_accuracy: 0.8511\n",
      "Epoch 13/30\n",
      "3/3 [==============================] - 1s 616ms/step - loss: 0.6040 - accuracy: 0.8000 - val_loss: 0.5764 - val_accuracy: 0.8298\n",
      "Epoch 14/30\n",
      "3/3 [==============================] - 1s 611ms/step - loss: 0.5551 - accuracy: 0.8211 - val_loss: 0.5573 - val_accuracy: 0.8085\n",
      "Epoch 15/30\n",
      "3/3 [==============================] - 1s 613ms/step - loss: 0.5219 - accuracy: 0.8158 - val_loss: 0.5430 - val_accuracy: 0.8085\n",
      "Epoch 16/30\n",
      "3/3 [==============================] - 1s 610ms/step - loss: 0.5093 - accuracy: 0.8316 - val_loss: 0.5328 - val_accuracy: 0.8085\n",
      "Epoch 17/30\n",
      "3/3 [==============================] - 1s 617ms/step - loss: 0.5019 - accuracy: 0.8421 - val_loss: 0.5229 - val_accuracy: 0.7872\n",
      "Epoch 18/30\n",
      "3/3 [==============================] - 1s 622ms/step - loss: 0.4622 - accuracy: 0.8579 - val_loss: 0.5135 - val_accuracy: 0.7872\n",
      "Epoch 19/30\n",
      "3/3 [==============================] - 1s 615ms/step - loss: 0.4594 - accuracy: 0.8526 - val_loss: 0.5058 - val_accuracy: 0.7872\n",
      "Epoch 20/30\n",
      "3/3 [==============================] - 1s 618ms/step - loss: 0.4281 - accuracy: 0.8684 - val_loss: 0.4998 - val_accuracy: 0.7872\n",
      "Epoch 21/30\n",
      "3/3 [==============================] - 1s 618ms/step - loss: 0.4354 - accuracy: 0.8684 - val_loss: 0.4951 - val_accuracy: 0.7660\n",
      "Epoch 22/30\n",
      "3/3 [==============================] - 1s 615ms/step - loss: 0.4046 - accuracy: 0.8684 - val_loss: 0.4904 - val_accuracy: 0.7660\n",
      "Epoch 23/30\n",
      "3/3 [==============================] - 1s 623ms/step - loss: 0.3968 - accuracy: 0.8895 - val_loss: 0.4843 - val_accuracy: 0.7660\n",
      "Epoch 24/30\n",
      "3/3 [==============================] - 1s 631ms/step - loss: 0.3931 - accuracy: 0.9053 - val_loss: 0.4783 - val_accuracy: 0.7872\n",
      "Epoch 25/30\n",
      "3/3 [==============================] - 1s 626ms/step - loss: 0.3563 - accuracy: 0.9368 - val_loss: 0.4732 - val_accuracy: 0.7660\n",
      "Epoch 26/30\n",
      "3/3 [==============================] - 1s 622ms/step - loss: 0.3526 - accuracy: 0.9211 - val_loss: 0.4705 - val_accuracy: 0.7660\n",
      "Epoch 27/30\n",
      "3/3 [==============================] - 1s 624ms/step - loss: 0.3514 - accuracy: 0.9211 - val_loss: 0.4673 - val_accuracy: 0.7660\n",
      "Epoch 28/30\n",
      "3/3 [==============================] - 1s 628ms/step - loss: 0.3491 - accuracy: 0.9105 - val_loss: 0.4654 - val_accuracy: 0.7660\n",
      "Epoch 29/30\n",
      "3/3 [==============================] - 1s 624ms/step - loss: 0.3555 - accuracy: 0.9105 - val_loss: 0.4636 - val_accuracy: 0.7660\n",
      "Epoch 30/30\n",
      "3/3 [==============================] - 1s 632ms/step - loss: 0.3144 - accuracy: 0.9316 - val_loss: 0.4601 - val_accuracy: 0.7660\n"
     ]
    }
   ],
   "source": [
    "## compile and evaluate\n",
    "# =========================\n",
    "\n",
    "print(\"-------Training \" + \"_\" + concat_type + \"-------\")\n",
    "batch_size = 64\n",
    "## early stop \n",
    "# early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)\n",
    "# multi_view_model.fit(train_generator, validation_data=val_generator, callbacks=[early_stopping], epochs=30,\n",
    "#                     steps_per_epoch= math.ceil(train_images_front.samples / batch_size), \n",
    "#                     validation_steps= math.ceil(val_images_front.samples / batch_size))\n",
    "## no early stop\n",
    "history = multi_view_model.fit(train_generator, validation_data=val_generator, epochs=30,\n",
    "                            steps_per_epoch= math.ceil(train_images_front.samples / batch_size), \n",
    "                            validation_steps= math.ceil(val_images_front.samples / batch_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\bone_20240719\\lib\\site-packages\\keras\\utils\\generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## save model to this path\n",
    "# =========================\n",
    "multi_view_model.save(\"./weights/\"+concat_type+\"_\" + \"_frac.h5\")\n",
    "# =========================\n",
    "\n",
    "\n",
    "## print results\n",
    "# =========================\n",
    "test_generator = multi_input_generator(test_images_front, test_images_side)\n",
    "\n",
    "batch_size=32\n",
    "pred = multi_view_model.predict(test_generator,  steps=math.ceil(test_images_front.samples / batch_size))\n",
    "predicted_labels = np.argmax(pred, axis=1)\n",
    "# =========================\n",
    "\n",
    "\n",
    "\n",
    "# create plots for accuracy and save it\n",
    "# =========================\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "figAcc = plt.gcf()\n",
    "my_file = os.path.join(\"./plots/\"+concat_type+\"_Accuracy.jpeg\")\n",
    "figAcc.savefig(my_file)\n",
    "plt.clf()\n",
    "# =========================\n",
    "\n",
    "\n",
    "## create plots for loss and save it\n",
    "# =========================\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "figAcc = plt.gcf()\n",
    "my_file = os.path.join(\"./plots/\"+concat_type+\"_\"+\"_Loss.jpeg\")\n",
    "figAcc.savefig(my_file)\n",
    "plt.clf()\n",
    "# =========================\n",
    "\n",
    "\n",
    "## plot confusion matrix\n",
    "# =========================\n",
    "if class_count == 2:\n",
    "    display_labels = [0, 1]\n",
    "elif class_count == 3:\n",
    "    display_labels = [0, 1, 2]\n",
    "elif class_count == 4:\n",
    "    display_labels = [0, 1, 2, 3]\n",
    "\n",
    "\n",
    "cm = confusion_matrix(test_images_front.labels, predicted_labels)\n",
    "cm_display = ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = display_labels)\n",
    "cm_display.plot()\n",
    "plt.title('Confusion Matrix')\n",
    "figAcc = plt.gcf()\n",
    "my_file = os.path.join(\"./plots/\"+concat_type+\"_\"+\"_Confusion Matrix.jpeg\")\n",
    "figAcc.savefig(my_file)\n",
    "plt.clf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "def make_heatmap(img_array_list, model, pred_index=None):    \n",
    "    front_intermediate_model = tf.keras.Model(\n",
    "        inputs=model.get_layer(\"resnet50\").input,\n",
    "        outputs=model.get_layer(\"resnet50\").get_layer(\"conv5_block3_out\").output\n",
    "    )\n",
    "\n",
    "    side_intermediate_model = tf.keras.Model(\n",
    "        inputs=model.get_layer(\"efficientnetb0\").input,\n",
    "        outputs=model.get_layer(\"efficientnetb0\").get_layer(\"top_conv\").output\n",
    "    )\n",
    "\n",
    "    fornt_output = side_intermediate_model(img_array_list[0])\n",
    "    side_output = front_intermediate_model(img_array_list[1])\n",
    "\n",
    "    last_conv_layer_outputs = [fornt_output, side_output]\n",
    "    heatmaps=[]\n",
    "    for conv_output in last_conv_layer_outputs:\n",
    "        conv_output = conv_output[0]\n",
    "        heatmap = np.mean(conv_output, axis=-1)\n",
    "\n",
    "        heatmap = np.maximum(heatmap, 0)\n",
    "        heatmap /= np.max(heatmap)\n",
    "        heatmaps.append(heatmap)\n",
    "    return heatmaps\n",
    "\n",
    "def save_and_display_heatmap(img_path, heatmap, alpha=0.4):\n",
    "    img = tf.keras.utils.load_img(img_path)\n",
    "    img = tf.keras.utils.img_to_array(img)\n",
    "\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "\n",
    "    jet = cm.get_cmap(\"jet\")\n",
    "\n",
    "    jet_colors = jet(np.arange(256))[:, :3]\n",
    "    jet_heatmap = jet_colors[heatmap]\n",
    "\n",
    "    jet_heatmap = tf.keras.utils.array_to_img(jet_heatmap)\n",
    "    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n",
    "    jet_heatmap = tf.keras.utils.img_to_array(jet_heatmap)\n",
    "\n",
    "    superimposed_img = jet_heatmap * alpha + img\n",
    "    superimposed_img = tf.keras.utils.array_to_img(superimposed_img)\n",
    "    return superimposed_img\n",
    "\n",
    "def plot_heatmap_all_branches(image_path, model, save_cam):\n",
    "\n",
    "\n",
    "    # model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "    # 載入和處理每個圖像\n",
    "    image_paths=[image_path, image_path.replace(\"front\", \"side\")]\n",
    "    img_array1 = tf.keras.preprocessing.image.img_to_array(image.load_img(image_paths[0], target_size=(224, 224, 3)))\n",
    "    img_array2 = tf.keras.preprocessing.image.img_to_array(image.load_img(image_paths[1], target_size=(224, 224, 3)))\n",
    "    # 擴展維度以匹配模型輸入要求\n",
    "    img_array1 = np.expand_dims(img_array1, axis=0)\n",
    "    img_array2 = np.expand_dims(img_array2, axis=0)\n",
    "\n",
    "    img_arrays = [img_array1, img_array2]\n",
    "\n",
    "    heatmaps = make_heatmap(img_arrays, model)\n",
    "    # 顯示所有的熱圖\n",
    "    plt.figure(figsize=(5, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(save_and_display_heatmap(image_paths[0], heatmaps[0]))\n",
    "    plt.title(\"AP(Mortise)\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(save_and_display_heatmap(image_paths[1], heatmaps[1]))\n",
    "    plt.title(\"Lateral\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    # 顯示標題\n",
    "    plt.suptitle(image_path.split('\\\\')[-1])\n",
    "    plt.savefig(save_cam)\n",
    "    plt.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0_0, count=24 :\n",
      "[0, 1, 2, 6, 7, 11, 12, 13, 14, 15, 16, 21, 24, 25, 26, 33, 36, 37, 38, 51, 53, 55, 56, 59]\n",
      "\n",
      "1_1, count=9 :\n",
      "[4, 8, 9, 22, 23, 30, 50, 52, 54]\n",
      "\n",
      "2_2, count=13 :\n",
      "[3, 5, 18, 27, 32, 34, 41, 42, 43, 44, 47, 48, 49]\n",
      "\n",
      "1_2, count=6 :\n",
      "[35, 39, 40, 46, 57, 58]\n",
      "\n",
      "2_1, count=4 :\n",
      "[10, 17, 19, 45]\n",
      "\n",
      "0_1, count=0 :\n",
      "[]\n",
      "\n",
      "1_0, count=2 :\n",
      "[28, 31]\n",
      "\n",
      "2_0, count=1 :\n",
      "[29]\n",
      "\n",
      "0_2, count=1 :\n",
      "[20]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "def clear_directory(directory_path):\n",
    "    if os.path.exists(directory_path):\n",
    "        for filename in os.listdir(directory_path):\n",
    "            file_path = os.path.join(directory_path, filename)\n",
    "            if os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)\n",
    "            else:\n",
    "                os.remove(file_path) \n",
    "\n",
    "combinations = [(0, 0), (1, 1), (2, 2), (1, 2), (2, 1), (0, 1), (1, 0), (2, 0), (0, 2)]\n",
    "list1 = list(test_df_front['Label'].reset_index(drop=True).astype(int))\n",
    "# pred\n",
    "list2 = list(predicted_labels)\n",
    "for val1, val2 in combinations:\n",
    "    target_path = save_cam_path + str(val1) + \"_\" + str(val2)+\"//\"\n",
    "    clear_directory(target_path)\n",
    "    indices = [i for i, (v1, v2) in enumerate(zip(list1, list2)) if v1 == val1 and v2 == val2]\n",
    "    print(str(val1) + \"_\" + str(val2)+\", count=\"+str(len(indices))+\" :\")\n",
    "    print(indices)\n",
    "    print()\n",
    "\n",
    "    # 遍历匹配的索引\n",
    "    for i in indices:\n",
    "        tmp = test_df_front.reset_index(drop=True).iloc[i]['Filepath']\n",
    "        plot_heatmap_all_branches(tmp, multi_view_model, target_path+str(i))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7666666666666667"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_images_front.labels, predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chosen_model = \"./weights/concat1__frac.h5\"\n",
    "\n",
    "\n",
    "# for i in range(len(wrong1)):\n",
    "#     # front\n",
    "#     im_front = test_df_front.reset_index(drop=True).iloc[i]['Filepath']\n",
    "#     temp_img = image.load_img(im_front, target_size=(224, 224))\n",
    "#     x = image.img_to_array(temp_img)\n",
    "#     x = np.expand_dims(x, axis=0)\n",
    "#     images_front = np.vstack([x])\n",
    "#     # side\n",
    "#     im_side = test_df_front.reset_index(drop=True).iloc[i]['Filepath']\n",
    "#     temp_img = image.load_img(im_side, target_size=(224, 224))\n",
    "#     x = image.img_to_array(temp_img)\n",
    "#     x = np.expand_dims(x, axis=0)\n",
    "#     images_side = np.vstack([x])\n",
    "\n",
    "#     heatmap = make_heatmap(images_front, images_side, tf.keras.models.load_model(chosen_model))\n",
    "#     print(f\"image path={im}\")\n",
    "#     save_and_display_heatmap(im, heatmap)\n",
    "#     print(\"##################################################################################\")\n",
    "# ############################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bone_20240719",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
